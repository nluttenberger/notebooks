{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95b3f49d-c07e-4b2e-be55-2c51791f7e55",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [],
   "source": [
    "import io\n",
    "import os\n",
    "import sys\n",
    "import re\n",
    "import math\n",
    "from xml.etree import ElementTree as ET\n",
    "import urllib.parse\n",
    "from urllib.parse import urlsplit\n",
    "from urllib.request import pathname2url\n",
    "#import urllib.pathname2url\n",
    "import json\n",
    "import codecs\n",
    "import subprocess\n",
    "import networkx as nx\n",
    "from networkx.algorithms import bipartite\n",
    "#!{sys.executable} -m pip install pyarrow\n",
    "import pyarrow\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "from scipy.stats import entropy\n",
    "from collections import Counter\n",
    "import locale\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import uuid\n",
    "from time import *\n",
    "locale.setlocale(locale.LC_ALL, 'de-DE.utf-8')\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "993a8267-8ece-40e3-82e7-a82c555df554",
   "metadata": {},
   "source": [
    "#### fruschtique CulinaryCollection class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d4387baa-4242-4832-80fd-f22a2a452adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CulinaryCollection:\n",
    "    \n",
    "    def __init__(self, graphLab_path=None, descript_fn=None, igdtCat_path=None, working_dir=None):\n",
    "        \n",
    "        def subcoll_rcp (f_names):\n",
    "            rcp_list = []\n",
    "            for fn_rcp in f_names:\n",
    "                with open(fn_rcp, 'r', encoding='utf-8') as f:\n",
    "                    rcp_in = ET.parse(f)\n",
    "                    rcp_root = rcp_in.getroot()\n",
    "                    rcp_name = rcp_root.find('fr:recipeName', ns).text\n",
    "                    rcp_list.append(rcp_name)\n",
    "            return rcp_list\n",
    "        \n",
    "        # check for missing parameters\n",
    "        if graphLab_path == None:\n",
    "            print ('Specify path to graphLab.')\n",
    "            return None\n",
    "        if descript_fn == None:\n",
    "            print ('Specify descriptor filename.')\n",
    "            return None\n",
    "        if igdtCat_path == None:\n",
    "            print ('Specify path to ingredients catalogue.')\n",
    "            return None\n",
    "        if working_dir == None:\n",
    "            print ('Specify working directory.')\n",
    "            return None\n",
    "        \n",
    "        # set namespaces\n",
    "        ns = {'fr': 'http://fruschtique.de/ns/recipe', 'fe': 'http://fruschtique.de/ns/fe'}\n",
    "        # set object variables\n",
    "        self.graphLab_path = graphLab_path\n",
    "        self.descript_fn   = descript_fn\n",
    "        self.igdtCat_path  = igdtCat_path\n",
    "        self.working_dir   = working_dir\n",
    "\n",
    "        # read descriptor file\n",
    "        descriptor = graphLab_path + descript_fn\n",
    "        with open(descriptor, 'r', encoding='utf-8') as d:\n",
    "            descript = ET.parse(d)\n",
    "            self.d_root = descript.getroot()\n",
    "            self.exp_name = self.d_root.find('fe:experimentName', ns).text\n",
    "        print (self.exp_name)\n",
    "\n",
    "        # read ingredients catalogue   \n",
    "        with open(igdtCat_path, encoding='utf-8') as file:\n",
    "            self.cat            = json.load(file)\n",
    "            self.catIngredients = self.cat.get('ingredients')\n",
    "            self.catClasses     = self.cat.get('classes')\n",
    "            self.noRefIgts      = self.cat.get('noRefIgts')\n",
    "        \n",
    "        # read list of recipes in collection\n",
    "        file_in = graphLab_path + self.d_root.find('fe:experimentPath', ns).text + 'catalogue.xml'\n",
    "        with open(file_in, 'r', encoding='utf-8') as f:\n",
    "            list_in = ET.parse(f)\n",
    "            root_in = list_in.getroot()\n",
    "        self.in_files = [urllib.parse.unquote(doc.get(\"href\")[8:], encoding=\"utf-8\") for doc in root_in.findall('doc')]\n",
    "\n",
    "        # check for subcollection directories\n",
    "        common = os.path.commonpath(self.in_files)\n",
    "        os.chdir (common)\n",
    "        sub_paths = [p for p in os.listdir() if os.path.isdir(p)]\n",
    "        if len(sub_paths) == 2:\n",
    "            self.subCollLtrs = sub_paths\n",
    "        elif len(sub_paths) == 1 or len(sub_paths) > 2:\n",
    "            print ('Wrong number of subcollection dir_paths.')\n",
    "            return None\n",
    "        elif len(sub_paths) == 0:\n",
    "            self.subCollLtrs = None\n",
    "            \n",
    "        # check for subcollections\n",
    "        if self.d_root.find('fe:A-collection', ns) != None and self.d_root.find('fe:B-collection', ns) != None:\n",
    "            self.collType = 'double'\n",
    "            coll_A = self.d_root.find('fe:A-collection', ns)\n",
    "            author_A = coll_A.find('fe:A-author', ns).text\n",
    "            collName_A = coll_A.find('fe:A-name', ns).text\n",
    "            if self.subCollLtrs[0] != None:\n",
    "                collDir_A = self.subCollLtrs[0]\n",
    "            else:\n",
    "                print ('No directory for subcollection A.')\n",
    "                return None\n",
    "            coll_B = self.d_root.find('fe:B-collection', ns)\n",
    "            author_B = coll_B.find('fe:B-author', ns).text\n",
    "            collName_B = coll_B.find('fe:B-name', ns).text\n",
    "            if self.subCollLtrs[1] != None:\n",
    "                collDir_B = self.subCollLtrs[1]\n",
    "            else:\n",
    "                print ('No directory for subcollection B.')\n",
    "                return None\n",
    "        else:\n",
    "            self.collType = 'single'\n",
    "        \n",
    "        # get metadata from descriptor\n",
    "        title = self.d_root.find('fe:fullTitle', ns).text\n",
    "        \n",
    "        # collect recipe names and related ingredients\n",
    "        self.full_rcp_list = []\n",
    "        for fn_rcp in self.in_files:\n",
    "            with open(fn_rcp, 'r', encoding='utf-8') as f:\n",
    "                rcp_in = ET.parse(f)\n",
    "                rcp_root = rcp_in.getroot()\n",
    "                rcp_name = rcp_root.find('fr:recipeName', ns).text\n",
    "                igdts = []\n",
    "                igdts_elem = rcp_root.findall('.//fr:igdtName',ns)\n",
    "                xx = [(igt.get(\"ref\"),igt.text.lower()) for igt in igdts_elem]\n",
    "                for (ref, igt_name) in xx:\n",
    "                    if ref == None:\n",
    "                        raise Exception(f\"Missing reference to ingredients catalogue for {igt_name.upper()} in recipe {rcp_name.upper()}\")\n",
    "                        return\n",
    "                    elif ref == '':\n",
    "                        found = False\n",
    "                        for noRef in self.noRefIgts:\n",
    "                            if noRef in igt_name:\n",
    "                                found = True\n",
    "                                break\n",
    "                        if found == False: \n",
    "                            raise Exception(f\"Null reference to ingredients catalogue for {igt_name.upper()} in recipe {rcp_name.upper()}\")\n",
    "                            return\n",
    "                    else:\n",
    "                        igdts.append(ref) \n",
    "                igdts = list(set(igdts))                                \n",
    "                rcp = {'recipeName' : rcp_name, 'ingredients' : igdts}\n",
    "                self.full_rcp_list.append(rcp)\n",
    "                    \n",
    "        # get subcollection files and prepare collection entry for coll_data.json\n",
    "        meta = dict(title=title,collType=self.collType)\n",
    "        if self.collType == 'double':\n",
    "            f_names_A = [fn for fn in self.in_files if os.path.basename(os.path.dirname(fn)) == self.subCollLtrs[0]]\n",
    "            f_names_B = [fn for fn in self.in_files if os.path.basename(os.path.dirname(fn)) == self.subCollLtrs[1]]        \n",
    "            # create recipe and subcollection lists\n",
    "            sub_coll_rcp_A = subcoll_rcp (f_names_A)\n",
    "            sub_coll_rcp_B = subcoll_rcp (f_names_B)       \n",
    "            rcp_dict = {'meta':meta, 'collections':{sub_paths[0]:{'name':collName_A, 'author':author_A,'recipes':sub_coll_rcp_A}, \\\n",
    "                                                    sub_paths[1]:{'name':collName_B, 'author':author_B,'recipes':sub_coll_rcp_B}}, \\\n",
    "                                                    'recipes': self.full_rcp_list}    \n",
    "        elif self.collType == 'single':\n",
    "            rcp_dict = dict(meta=meta, recipes=self.full_rcp_list)\n",
    "        else:\n",
    "            print ('Unknown error.')\n",
    "            return\n",
    "        \n",
    "        # write rcp_dict to coll_data.json\n",
    "        file_out = self.working_dir + 'coll_data.json'\n",
    "        with open(file_out, \"w\", encoding='utf-8') as f:\n",
    "            json.dump(rcp_dict, f, ensure_ascii=False)\n",
    "            \n",
    "        # read coll_data.json  \n",
    "        with open(file_out, 'r', encoding='utf-8') as file:\n",
    "            self.coll = json.load(file) \n",
    "        self.recipes     = [rcp for rcp in self.coll.get('recipes')]\n",
    "        self.ingredients = list(set(igt for rcp in self.recipes for igt in rcp.get('ingredients')))\n",
    "        \n",
    "        #create the inverted index as dict\n",
    "        self.index = dict()\n",
    "        for igt in self.catIngredients.items():\n",
    "            x = dict()\n",
    "            k = igt[0]\n",
    "            x = {k:k}\n",
    "            self.index.update(x)\n",
    "            y = dict()\n",
    "            for syn in igt[1].get('synonyms'):\n",
    "                y = {syn:k}\n",
    "                self.index.update(y)     \n",
    "        return\n",
    "            \n",
    "    def __str__(self):\n",
    "        if self.collType == 'single':\n",
    "            print_str = f\"Collection with {len(self.recipes)} recipes with {len(self.ingredients)} distinct ingredients\\nsupported by an ingredients catalog with {len(self.catIngredients)} entries in {len(self.catClasses)} classes\\n\"\n",
    "        elif self.collType == 'double':\n",
    "            print_str = f\"Collection with {len(self.recipes)} recipes in {len(self.subCollLtrs)} subcollections with {len(self.ingredients)} distinct ingredients\\nsupported by an ingredients catalog with {len(self.catIngredients)} entries in {len(self.catClasses)} classes\\n\"\n",
    "        else:\n",
    "            print ('Unknown error.')\n",
    "            return None\n",
    "        return print_str\n",
    "    \n",
    "    def infoSubcolls (self):\n",
    "        if self.collType == 'double':\n",
    "            xx = [{'letter':k, 'name':self.coll.get('collections').get(k,v).get('name'), \\\n",
    "                  'author':self.coll.get('collections').get(k,v).get('author'),'rcpCount':len(self.coll.get('collections').get(k,v).get('recipes'))} \\\n",
    "                  for (k,v) in self.coll.get('collections').items()]\n",
    "            return xx\n",
    "        else:\n",
    "            print ('No subcollections in this collection.')\n",
    "            return None\n",
    "        \n",
    "    def recipesList (self,coll=None):\n",
    "        if self.collType == 'single':\n",
    "            return self.recipes\n",
    "        elif self.collType == 'double' and coll in self.subCollLtrs:\n",
    "            return self.coll.get('collections').get(coll).get('recipes')\n",
    "        else:\n",
    "            return None\n",
    "        \n",
    "    def ingredientsList (self,coll=None):\n",
    "        if self.collType == 'single':\n",
    "            return self.ingredients\n",
    "        elif self.collType == 'double' and coll in self.subCollLtrs:\n",
    "            xx = [rcp for rcp in self.coll.get('collections').get(coll).get('recipes')]\n",
    "            yy = [igt for rcp in self.coll.get(\"recipes\") if rcp.get('recipeName') in xx for igt in rcp.get('ingredients')]\n",
    "            zz = list(set(yy))\n",
    "            zz.sort(key=locale.strxfrm)\n",
    "            return zz\n",
    "        else:\n",
    "            return None\n",
    "                \n",
    "    def catalogList (self, select=None):\n",
    "        xx = list (self.catClasses.keys())\n",
    "        if select == None:\n",
    "            return [igt for igt in self.cat]\n",
    "        elif type(select) is str and select in xx:\n",
    "            return [igt for igt in self.cat.get('ingredients') if self.cat.get('ingredients').get(igt).get('i-class') == select]\n",
    "        elif type(select) is list:\n",
    "            return [self.catIngredients.get(s) for s in select]\n",
    "        \n",
    "    def cosine_sim (self):\n",
    "        \n",
    "        def co_sim (a,b):\n",
    "            return dot(a, b)/(norm(a)*norm(b))\n",
    "        \n",
    "        def vec (occ_d=None):\n",
    "            d = {}\n",
    "            for i in self.ingredients:\n",
    "                d[i] = 0\n",
    "            for k,v in occ_d.items():\n",
    "                d[k] = v        \n",
    "            vector = dict(sorted(d.items()))\n",
    "            return list(vector.values())\n",
    "        \n",
    "        if len(self.subCollLtrs) != 2:\n",
    "            print (\"Two subcollections are needed to compute cosine similarity!\")\n",
    "            return None\n",
    "        rcp_A  = self.recipesList(self.subCollLtrs[0])\n",
    "        rcp_B  = self.recipesList(self.subCollLtrs[1])\n",
    "        occ_dict_A = Counter([igt for rcp in self.recipes if rcp.get('recipeName') in rcp_A for igt in rcp.get('ingredients')])\n",
    "        occ_dict_B = Counter([igt for rcp in self.recipes if rcp.get('recipeName') in rcp_B for igt in rcp.get('ingredients')])\n",
    "        vec_A     = vec(occ_dict_A)\n",
    "        vec_B     = vec(occ_dict_B)\n",
    "        sim_total = co_sim(vec_A, vec_B)\n",
    "        res = {'total':sim_total}\n",
    "        for c in list(self.catClasses.keys()):\n",
    "            occ_dict_A_class = Counter([igt for rcp in self.coll.get(\"recipes\") if rcp.get('recipeName') in rcp_A for igt in rcp.get('ingredients') if self.catIngredients.get(igt).get('i-class') == c])\n",
    "            if sum(occ_dict_A_class.values()) != 0:\n",
    "                occ_dict_B_class = Counter([igt for rcp in self.coll.get(\"recipes\") if rcp.get('recipeName') in rcp_B for igt in rcp.get('ingredients') if self.catIngredients.get(igt).get('i-class') == c])\n",
    "                if sum(occ_dict_B_class.values()) != 0:\n",
    "                    vec_A_class = vec(occ_dict_A_class)\n",
    "                    vec_B_class = vec(occ_dict_B_class)\n",
    "                    sim_class   = co_sim(vec_A_class, vec_B_class)\n",
    "                    res.update({c:sim_class}) \n",
    "        return res\n",
    "    \n",
    "    def entropy(self):\n",
    "        if self.collType == 'single':\n",
    "            p = list(Counter([igt for rcp in self.coll.get(\"recipes\") for igt in rcp.get('ingredients')]).values())\n",
    "            return {'entropy':entropy(p, base=2)}\n",
    "        elif self.collType == 'double':\n",
    "            rcp_A  = self.recipesList(self.subCollLtrs[0])\n",
    "            rcp_B  = self.recipesList(self.subCollLtrs[1])\n",
    "            p_A = list(Counter([igt for rcp in self.coll.get(\"recipes\") if rcp.get('recipeName') in rcp_A for igt in rcp.get('ingredients')]).values())\n",
    "            p_B = list(Counter([igt for rcp in self.coll.get(\"recipes\") if rcp.get('recipeName') in rcp_B for igt in rcp.get('ingredients')]).values())\n",
    "            return {'entropy_A':entropy(p_A, base=2), 'entropy_B':entropy(p_B, base=2)}\n",
    "        else:\n",
    "            print ('Unknown error.')\n",
    "            return None\n",
    "        \n",
    "    def toGraph (self, coll=None):\n",
    "        \n",
    "        def igtGraph (i2r):\n",
    "            B = nx.Graph(from_coll=coll,created_by='fruschtique CulinaryCollection')\n",
    "            X = nx.Graph(from_coll=coll,created_by='fruschtique CulinaryCollection')\n",
    "            top = [rcp.get('recipeName') for rcp in i2r]\n",
    "            bottom = list(set([igt for rcp in i2r for igt in rcp.get('ingredients')]))\n",
    "            e_list = []\n",
    "            for rcp in i2r:\n",
    "                name = rcp.get('recipeName')\n",
    "                for igt in rcp.get('ingredients'):\n",
    "                    e_list.append((name,igt))\n",
    "            B.add_nodes_from(top, bipartite=0)\n",
    "            B.add_nodes_from(bottom, bipartite=1)\n",
    "            B.add_edges_from(e_list)\n",
    "            X = bipartite.weighted_projected_graph(B, bottom)\n",
    "            attr_dict = {igt: {'i-name':self.catIngredients[igt].get('i-name'),'i-class':self.catIngredients[igt].get('i-class')} for igt in bottom}\n",
    "            occ_list = [igt for rcp in i2r for igt in rcp.get('ingredients')]\n",
    "            self.occ_dict = Counter(occ_list)\n",
    "            occ_attr = {k:{'occ':self.occ_dict.get(k)} for k in self.occ_dict.keys()}\n",
    "            nx.set_node_attributes(X, attr_dict)\n",
    "            nx.set_node_attributes(X, occ_attr)\n",
    "            e_attr = {}\n",
    "            for e in list(X.edges(data=True)):\n",
    "                x = [e[0],e[1]]\n",
    "                x.sort(key=locale.strxfrm)\n",
    "                id = str(x[0]) + '--' + str(x[1])\n",
    "                xx = (e[0],e[1])\n",
    "                e_attr[xx] = {'id':id}\n",
    "            nx.set_edge_attributes(X, e_attr)\n",
    "            return X\n",
    "        \n",
    "        # single subcollection\n",
    "        if type(coll) is str:\n",
    "            if len(coll) != 1:\n",
    "                print('Use a single character for subcollection specification.')\n",
    "                return None\n",
    "            elif self.collType == 'double' and not(coll in self.subCollLtrs):\n",
    "                print (f\"The subcollection {coll} is not contained in this collection.\")\n",
    "                return None\n",
    "            elif self.collType == 'double':\n",
    "                # create graph from single subcollection\n",
    "                xx = [rcp for rcp in self.coll.get('collections').get(coll).get('recipes')]\n",
    "                i2r = [rcp for rcp in self.coll.get(\"recipes\") if rcp.get('recipeName') in xx]\n",
    "                G1 = igtGraph(i2r)\n",
    "                # add sub attribute to nodes\n",
    "                sub_dict = {nd:{'sub':coll} for nd in list(G1.nodes())}\n",
    "                nx.set_node_attributes(G1,sub_dict)\n",
    "                # add sub attribute to edges \n",
    "                sub_dict = {ed:{'sub':coll} for ed in list(G1.edges())}\n",
    "                nx.set_edge_attributes(G1,sub_dict)\n",
    "                return G1\n",
    "        # two subcollections\n",
    "        elif type(coll) is list:\n",
    "            if len(coll) > 2:\n",
    "                print('Two subcollections is maximum for graph creation.')\n",
    "                return None\n",
    "            elif not(coll[0] in self.subCollLtrs):\n",
    "                print (f\"The subcollection {coll[0]} is not contained in this collection.\")\n",
    "                return None\n",
    "            elif not(coll[1] in self.subCollLtrs):\n",
    "                print (f\"The subcollection {coll[1]} is not contained in this collection.\")\n",
    "                return None\n",
    "            else:\n",
    "                i2r = [rcp for rcp in self.coll.get(\"recipes\")]\n",
    "                GG = igtGraph(i2r)\n",
    "                Aingredients = self.ingredientsList('A')\n",
    "                Bingredients = self.ingredientsList('B')\n",
    "                ABingredients = Aingredients.intersection(Bingredients)\n",
    "                Aingredients_pure = Aingredients.difference(ABingredients)\n",
    "                Bingredients_pure = Bingredients.difference(ABingredients)\n",
    "                Asub_dict = {igt: {'sub':'A'} for igt in Aingredients_pure}\n",
    "                Bsub_dict = {igt: {'sub':'B'} for igt in Bingredients_pure}\n",
    "                ABsub_dict = {igt: {'sub':'AB'} for igt in ABingredients}\n",
    "                sub_dict = {**Asub_dict, **Bsub_dict, **ABsub_dict}\n",
    "                nx.set_node_attributes(GG, sub_dict)\n",
    "                A_attr   = {(e[0],e[1]):{'sub': 'A'}   for e in list(GG.edges(data=True)) if (e[0] in Aingredients_pure and e[1] in Aingredients_pure)}\n",
    "                AAB_attr = {(e[0],e[1]):{'sub': 'AAB'} for e in list(GG.edges(data=True)) if (e[0] in Aingredients_pure and e[1] in ABingredients) or (e[0] in ABingredients and e[1] in Aingredients_pure)}\n",
    "                B_attr   = {(e[0],e[1]):{'sub': 'B'}   for e in list(GG.edges(data=True)) if (e[0] in Bingredients_pure and e[1] in Bingredients_pure)}\n",
    "                BAB_attr = {(e[0],e[1]):{'sub': 'BAB'} for e in list(GG.edges(data=True)) if (e[0] in Bingredients_pure and e[1] in ABingredients) or (e[0] in ABingredients and e[1] in Bingredients_pure)}\n",
    "                AB_attr  = {(e[0],e[1]):{'sub': 'AB'}  for e in list(GG.edges(data=True)) if e[0] in ABingredients and e[1] in ABingredients}\n",
    "                e_attr = {**A_attr,**AAB_attr,**B_attr,**BAB_attr,**AB_attr}\n",
    "                nx.set_edge_attributes(GG, e_attr)\n",
    "                return GG\n",
    "        # no subcollections\n",
    "        elif coll == None:\n",
    "            # create graph from single subcollection\n",
    "                i2r = [rcp for rcp in self.coll.get('recipes')]\n",
    "                G1 = igtGraph(i2r)\n",
    "                # add sub attribute to nodes\n",
    "                sub_dict = {nd:{'sub':'A'} for nd in list(G1.nodes())}\n",
    "                nx.set_node_attributes(G1,sub_dict)\n",
    "                # add sub attribute to edges \n",
    "                sub_dict = {ed:{'sub':'A'} for ed in list(G1.edges())}\n",
    "                nx.set_edge_attributes(G1,sub_dict)\n",
    "                return G1\n",
    "        else:\n",
    "            print ('Unknown error.')\n",
    "\n",
    "    def nodeSets(self,graph=None,coll=None):\n",
    "        if graph == None:\n",
    "            print ('Specify graph.')\n",
    "            return None\n",
    "        elif coll == None:\n",
    "            return graph.nodes(data=True)\n",
    "        elif type(coll) is str:\n",
    "            if len(coll) != 1:\n",
    "                print('Use a single character for subcollection specification.')\n",
    "                return None\n",
    "            elif not(coll in self.subCollLtrs):\n",
    "                print(f\"Subcollection {coll} does not exist.\")\n",
    "                return None\n",
    "            else:\n",
    "                Anodes = set ([n for (n,attr) in graph.nodes(data=True) if attr.get('sub') == coll])\n",
    "                return list(Anodes)\n",
    "        elif type(coll) is list:\n",
    "            if len(coll) > 2:\n",
    "                print('Two subcollections is maximum for node set generation.')\n",
    "                return None\n",
    "            elif not(coll[0] in self.subCollLtrs):\n",
    "                print (f\"The subcollection {coll[0]} is not contained in this collection.\")\n",
    "                return None\n",
    "            elif not(coll[1] in self.subCollLtrs):\n",
    "                print (f\"The subcollection {coll[1]} is not contained in this collection.\")\n",
    "                return None\n",
    "            else:\n",
    "                xx = f\"{coll[0]}{coll[1]}\"\n",
    "                ABnodes = [n for (n,attr) in graph.nodes(data=True) if attr.get('sub') == xx]\n",
    "                return ABnodes\n",
    "        else:\n",
    "            return None\n",
    "    \n",
    "    def edgeSets(self,graph=None,coll=None):         \n",
    "        if graph == None:\n",
    "            print ('Specify graph.')\n",
    "            return None\n",
    "        elif coll == None:\n",
    "            return graph.edges(data=True)\n",
    "        if type(coll) is str:\n",
    "            if len(coll) != 1:\n",
    "                print('Use a single character for subcollection specification.')\n",
    "                return None\n",
    "            elif not(coll in self.subCollLtrs):\n",
    "                print(f\"Subcollection {coll} does not exist.\")\n",
    "                return None\n",
    "            else:\n",
    "                n_A  = [n for n,attr in graph.nodes(data=True) if attr.get('sub') == coll]\n",
    "                A_e_pure  = [e for e in graph.edges(data=True) if e[0] in n_A and e[1] in n_A]\n",
    "                return A_e_pure  \n",
    "        elif type(coll) is list:\n",
    "            if len(coll) > 2:\n",
    "                print('Two subcollections is maximum for edge set generation.')\n",
    "                return None\n",
    "            elif not(coll[0] in self.subCollLtrs):\n",
    "                print (f\"The subcollection {coll[0]} is not contained in this collection.\")\n",
    "                return None\n",
    "            elif not(coll[1] in self.subCollLtrs):\n",
    "                print (f\"The subcollection {coll[1]} is not contained in this collection.\")\n",
    "                return None\n",
    "            else:\n",
    "                n_A  = [n for n,attr in graph.nodes(data=True) if attr.get('sub') == coll[0]]\n",
    "                n_B  = [n for n,attr in graph.nodes(data=True) if attr.get('sub') == coll[1]]\n",
    "                n_AB = [n for n,attr in graph.nodes(data=True) if attr.get('sub') == f\"{coll[0]}{coll[1]}\"]\n",
    "                A_edges        = [e for e in graph.edges(data=True) if e[0] in n_A and e[1] in n_A]\n",
    "                B_edges        = [e for e in graph.edges(data=True) if e[0] in n_B and e[1] in n_B]\n",
    "                AAB_edges      = [e for e in graph.edges(data=True) if (e[0] in n_A and e[1] in n_AB) or (e[1] in n_A and e[0] in n_AB)]\n",
    "                BAB_edges      = [e for e in graph.edges(data=True) if (e[0] in n_B and e[1] in n_AB) or (e[1] in n_B and e[0] in n_AB)]\n",
    "                AB_edges = [e for e in graph.edges(data=True) if e[0] in n_AB and e[1] in n_AB]\n",
    "                return {'A_edges' : A_edges, 'B_edges' : B_edges, 'AAB_edges' : AAB_edges, 'BAB_edges' : BAB_edges, 'AB_edges' : AB_edges}\n",
    "        else:\n",
    "            return None\n",
    "    \n",
    "    def Krack(self, graph=None, select=None):\n",
    "\n",
    "        def Krack (EL,IL):\n",
    "            return (EL-IL)/(EL+IL)\n",
    "        \n",
    "        # parameter checking\n",
    "        if graph == None:\n",
    "            print ('Specify graph.')\n",
    "            return None\n",
    "        if select == None:\n",
    "            print ('Specify selection.')\n",
    "            return None\n",
    "        elif type(select) is str:\n",
    "            if len(select) != 1:\n",
    "                print('Use a single character for selection specification.')\n",
    "                return None\n",
    "            elif select not in self.subCollLtrs:\n",
    "                print('Selected subcollection does not exist.')\n",
    "                return None\n",
    "            else:\n",
    "                EL_A = len(self.edgeSets(graph,['A','B']).get('A_e_mixed'))\n",
    "                IL_A = len(self.edgeSets(graph,['A','B']).get('A_e_pure'))\n",
    "                EL_B = len(self.edgeSets(graph,['A','B']).get('B_e_mixed'))\n",
    "                IL_B = len(self.edgeSets(graph,['A','B']).get('B_e_pure'))                \n",
    "                return {'Krack_A' : Krack(EL_A,IL_A), 'Krack_B' : Krack(EL_B,IL_B)}\n",
    "        elif type(select) is list:\n",
    "            for igdt in select:\n",
    "                if igdt not in self.ingredients:\n",
    "                    print(f\"'{igdt}' not in ingredients catalogue.\")\n",
    "                    return None\n",
    "                    break\n",
    "            collector = {}\n",
    "            xx = self.nodeSets(graph,'A')\n",
    "            yy = self.nodeSets(graph,['A','B'])\n",
    "            for igdt in select:\n",
    "                IL_i = len([neigh for neigh in nx.neighbors(graph,igdt) if neigh in xx])\n",
    "                EL_i = len([neigh for neigh in nx.neighbors(graph,igdt) if neigh in yy])\n",
    "                collector[igdt] = Krack(EL_i,IL_i)\n",
    "            return collector\n",
    "        else:\n",
    "            return None\n",
    "        \n",
    "    def toDot(self,graph,path,fn):\n",
    "        dot = 'graph {\\ngraph[rankdir=\"LR\", outputorder=\"edgesfirst\"]\\nnode[fontname=\"Arial\", fontsize=120, shape=circle, style=filled, fixedsize=shape];\\n'\n",
    "        for u,v,att in G.edges(data=True):\n",
    "            x = [u,v]\n",
    "            x.sort(key=locale.strxfrm)\n",
    "            u = x[0]\n",
    "            v = x[1]\n",
    "            dot += u+' -- '+v+' [penwidth='+str(att.get('weight'))\n",
    "            dot += ', id='+'\"'+u+\"--\"+v+'\"'\n",
    "            if att.get('weight') > 1:\n",
    "                dot += ', color=Red]\\n'\n",
    "            else:\n",
    "                dot += ']\\n'\n",
    "        for u,att in graph.nodes(data=True):\n",
    "            dot += u+' [width=' + str(1+3*math.sqrt(att.get('occ'))) + ', label=' + str(att.get('i-name')) + ', class=' + str(att.get('i-class')) + ']\\n'\n",
    "        dot += '}'\n",
    "        os.chdir(path)\n",
    "        with codecs.open(fn, 'w', encoding = 'utf8') as file:\n",
    "            file.write(dot)\n",
    "        return\n",
    "    \n",
    "    def toGEXF(self,graph,path,fn):       \n",
    "        ns = {\"gr\": \"http://www.gexf.net/1.2draft\"}\n",
    "        root = ET.Element('gr:gexf', attrib={\"xmlns:gr\":\"http://www.gexf.net/1.2\", \"xmlns:viz\":\"http://www.gexf.net/1.2/viz\", \\\n",
    "        \"xmlns:xsi\":\"http://www.w3.org/2001/XMLSchema-instance\", \"xsi:schemaLocation\":\"http://www.gexf.net/1.2 https://gexf.net/1.2/gexf.xsd\", \\\n",
    "        \"version\":\"1.2\"})\n",
    "        meta = ET.SubElement(root,\"gr:meta\",attrib={\"lastmodifieddate\":\"2023-09-15\"})\n",
    "        creator = ET.SubElement(meta, \"gr:creator\")\n",
    "        creator.text = \"Norbert Luttenberger\"\n",
    "        description = ET.SubElement(meta, \"gr:description\")\n",
    "        description.text = \"fruschtique Ingredient Graph in gexf notation\"\n",
    "        g_graph = ET.SubElement(root,\"gr:graph\",attrib={\"defaultedgetype\":\"undirected\"})\n",
    "        attributes = ET.SubElement(g_graph, \"gr:attributes\", attrib={\"class\":\"node\"})\n",
    "        attribute_0 = ET.SubElement(attributes, \"gr:attribute\", attrib={\"id\":\"0\",\"title\":\"occ\",\"type\":\"float\"})\n",
    "        attribute_1 = ET.SubElement(attributes, \"gr:attribute\", attrib={\"id\":\"1\",\"title\":\"i-class\",\"type\":\"string\"})        \n",
    "        nodes = ET.SubElement(g_graph, \"gr:nodes\") \n",
    "        for n,attr in graph.nodes(data=True):\n",
    "            node = ET.SubElement(nodes, \"gr:node\", attrib={\"id\":n, \"label\":self.catIngredients.get(n).get(\"i-name\")})\n",
    "            att_values = ET.SubElement(node,\"gr:attvalues\")\n",
    "            att_value  = ET.SubElement(att_values,\"gr:attvalue\", attrib={\"for\":\"0\",\"value\":str(attr.get(\"occ\"))})\n",
    "            att_value  = ET.SubElement(att_values,\"gr:attvalue\", attrib={\"for\":\"1\",\"value\":str(attr.get(\"i-class\"))})\n",
    "        edges = ET.SubElement(g_graph, \"gr:edges\")\n",
    "        for n1,n2,attr in graph.edges(data=True):\n",
    "            edge = ET.SubElement(edges, \"gr:edge\", attrib={\"id\":attr.get(\"id\"), \"source\":n1, \"target\":n2, \"weight\":str(attr.get(\"weight\"))})\n",
    "        tree = ET.ElementTree(root)\n",
    "        ET.indent(tree)\n",
    "        os.chdir(path)\n",
    "        tree.write(fn, encoding='UTF-8', xml_declaration='<?xml version=\"1.0\" encoding=\"UTF-8\"?>')\n",
    "        return\n",
    "    \n",
    "    def toCSV(self,graph,path,fn):\n",
    "        os.chdir(path)\n",
    "        basename, extension = os.path.splitext(fn)\n",
    "        nodes_fn = basename + '_nodes.csv'\n",
    "        with codecs.open(nodes_fn, 'w', encoding = 'utf8') as file:\n",
    "            file.write('n,i-name,i-class,occ,sub\\n')\n",
    "            for (n,attr) in graph.nodes(data=True):\n",
    "                file.write(f\"{n},{attr.get('i-name')},{attr.get('i-class')},{attr.get('occ')},{attr.get('sub')}\\n\")\n",
    "        # get edges dict      \n",
    "        e_dict = self.edgeSets(graph,['A', 'B'])              \n",
    "        edges_fn = basename + '_edges.csv'     \n",
    "        with codecs.open(edges_fn, 'w', encoding = 'utf8') as file:\n",
    "            file.write('n1,n2,id,weight,sub\\n')\n",
    "            file.write('A_e_pure\\n')\n",
    "            for (n1,n2,attr) in e_dict.get('A_e_pure'):\n",
    "                file.write(f\"{n1},{n2},{attr.get('id')},{attr.get('weight')},{attr.get('sub')}\\n\")\n",
    "            file.write('A_e_mixed\\n')\n",
    "            for (n1,n2,attr) in e_dict.get('A_e_mixed'):\n",
    "                file.write(f\"{n1},{n2},{attr.get('id')},{attr.get('weight')},{attr.get('sub')}\\n\")\n",
    "            file.write('B_e_pure\\n')\n",
    "            for (n1,n2,attr) in e_dict.get('B_e_pure'):\n",
    "                file.write(f\"{n1},{n2},{attr.get('id')},{attr.get('weight')},{attr.get('sub')}\\n\") \n",
    "            file.write('B_e_mixed\\n')\n",
    "            for (n1,n2,attr) in e_dict.get('B_e_mixed'):\n",
    "                file.write(f\"{n1},{n2},{attr.get('id')},{attr.get('weight')},{attr.get('sub')}\\n\")\n",
    "            file.write('AB_e_intersect\\n')\n",
    "            for (n1,n2,attr) in e_dict.get('AB_e_intersect'):\n",
    "                file.write(f\"{n1},{n2},{attr.get('id')},{attr.get('weight')},{attr.get('sub')}\\n\")\n",
    "        return\n",
    "    \n",
    "    def SVGMakerInit(self,graph=None,working=None):\n",
    "        \"\"\"Initialize the SVG Maker of the fruschtique Culinary Collection Class.\n",
    "\n",
    "        1 -- Create dot file for collection from graph.\n",
    "        2 -- Call sfdp subprocess and create svg file for collection. \n",
    "        3 -- Create pandas representation for graph nodes and edges.\n",
    "        \"\"\"\n",
    "\n",
    "        # 1 -- dot file\n",
    "        outfile = f\"{os.path.join(working,self.exp_name)}.dot\"\n",
    "        self.toDot(graph,working,f\"{outfile}\")\n",
    "\n",
    "        # 2 -- svg file\n",
    "        infile  = f\"{os.path.join(working,outfile)}\"\n",
    "        subprocess.run (['sfdp', str(infile), '-o' + str(self.exp_name) + '.svg', '-Goverlap=prism', '-Tsvg'])\n",
    "\n",
    "        # 3 -- pandas representation\n",
    "        # columns for nodes:\n",
    "        #   id               ingredient/node id\n",
    "        #   sub              subcollection indicator (A, B, AB, or None)\n",
    "        #   occ              ingredient occurrence in collection\n",
    "        #   class            ingrendient class\n",
    "        #   cx_fd            x coordinate for node center, fd stands for force-directed layout\n",
    "        #   cy_fd            y coordinate for node center, fd stands for force-directed layout\n",
    "        #   rx_fd            x radius, fd stands for force-directed layout\n",
    "        #   ry_fd            y radius, fd stands for force-directed layout\n",
    "        # columns for edges:\n",
    "        #   id               edge id, coded by <start-id>--<end-id>, where start-id alphabetically < end-id\n",
    "        #   start_id         id of start node\n",
    "        #   end_id           id of end node\n",
    "        #   weight\n",
    "        #   start_x_fd       x coordinate for start point, fd stands for force-directed layout\n",
    "        #   start_y_fd       y coordinate for start point, fd stands for force-directed layout\n",
    "        #   end_x_fd         x coordinate for end point, fd stands for force-directed layout\n",
    "        #   end_y_fd         y coordinate for end point, fd stands for force-directed layout\n",
    "        #   start_x_node     x coordinate for start at node center\n",
    "        #   start_y_node     y coordinate for start at node center\n",
    "        #   end_x_node       x coordinate for end at node center\n",
    "        #   end_y_node       y coordinate for end at node center\n",
    "\n",
    "        # read graphics file just created\n",
    "        with open(str(self.exp_name) + '.svg', 'r', encoding='utf-8') as s:\n",
    "            ss = ET.parse(s)\n",
    "        svg_in = ss.getroot()\n",
    "        ns = {'svg': 'http://www.w3.org/2000/svg'}\n",
    "        self.transform = svg_in.find('svg:g[@id=\"graph0\"]',ns).get('transform')\n",
    "        self.viewbox   = svg_in.get('viewBox')\n",
    "        \n",
    "        # nodes\n",
    "        t0 = process_time()\n",
    "        node_coords = {node.find(\"svg:title\", ns).text: (node.find(\"svg:ellipse\", ns).attrib['cx'], \\\n",
    "                                                         node.find(\"svg:ellipse\", ns).attrib['cy'], \\\n",
    "                                                         node.find(\"svg:ellipse\", ns).attrib['rx'], \\\n",
    "                                                         node.find(\"svg:ellipse\", ns).attrib['ry']  \\\n",
    "                                                        ) for node in svg_in.findall(\".//svg:g[@class='node']\", ns)}\n",
    "        text_coords = {node.find(\"svg:title\", ns).text: (node.find(\"svg:text\", ns).attrib['x'], \\\n",
    "                                                         node.find(\"svg:text\", ns).attrib['y']  \\\n",
    "                                                        ) for node in svg_in.findall(\".//svg:g[@class='node']\", ns)}\n",
    "        self.nds = pd.DataFrame({ \n",
    "                        'sub'  : [att.get('sub') for i,att in graph.nodes(data=True)], \\\n",
    "                        'occ'  : [self.occ_dict.get(k) for k in graph.nodes()], \\\n",
    "                        'name' : [att.get('i-name') for i,att in graph.nodes(data=True)], \\\n",
    "                        'class': [self.cat.get('ingredients').get(k).get('i-class') for k in graph.nodes()], \\\n",
    "                        'cx_fd': [node_coords.get(k)[0] for k in graph.nodes()], \\\n",
    "                        'cy_fd': [node_coords.get(k)[1] for k in graph.nodes()], \\\n",
    "                        'rx_fd': [node_coords.get(k)[2] for k in graph.nodes()], \\\n",
    "                        'ry_fd': [node_coords.get(k)[3] for k in graph.nodes()], \\\n",
    "                        'txt_x': [text_coords.get(k)[0] for k in graph.nodes()], \\\n",
    "                        'txt_y': [text_coords.get(k)[1] for k in graph.nodes()]  \\\n",
    "                        }, \\\n",
    "                        index = graph.nodes() \\\n",
    "                        )\n",
    "        t1 = process_time()\n",
    "        print ('runtime for nodes: ', t1-t0)\n",
    "        # edges\n",
    "        t0 = process_time()\n",
    "        path_coords = [svg_in.find(f\".//svg:g[@id='{attr.get('id')}']/svg:path\", ns).attrib['d'] for u,v,attr in graph.edges(data=True)]\n",
    "        self.eds = pd.DataFrame({\n",
    "            'start_id'    : [u for u,v,attr in graph.edges(data=True)], \\\n",
    "            'end_id'      : [v for u,v,attr in graph.edges(data=True)], \\\n",
    "            'sub'         : [attr.get('sub')    for u,v,attr in graph.edges(data=True)], \\\n",
    "            'weight'      : [attr.get('weight') for u,v,attr in graph.edges(data=True)], \\\n",
    "            'start_x_fd'  : [coords.split(',')[0][1:]           for coords in path_coords], \\\n",
    "            'start_y_fd'  : [coords.split(',')[1].split('C')[0] for coords in path_coords], \\\n",
    "            'end_x_fd'    : [coords.split(' ')[2].split(',')[0] for coords in path_coords], \\\n",
    "            'end_y_fd'    : [coords.split(' ')[2].split(',')[1] for coords in path_coords], \\\n",
    "            'start_x_node': [node_coords[u][0]                  for u,v,attr in graph.edges(data=True)], \\\n",
    "            'start_y_node': [node_coords[u][1]                  for u,v,attr in graph.edges(data=True)], \\\n",
    "            'end_x_node'  : [node_coords[v][0]                  for u,v,attr in graph.edges(data=True)], \\\n",
    "            'end_y_node'  : [node_coords[v][1]                  for u,v,attr in graph.edges(data=True)]  \\\n",
    "        }, index = [attr.get('id') for u,v,attr in graph.edges(data=True)])\n",
    "        t1 = process_time()\n",
    "        print ('runtime for edges: ', t1-t0)\n",
    "        return\n",
    "    \n",
    "    def previewSVG(self,graph=None,scale=1.0):\n",
    "        if graph == None:\n",
    "            print ('Specify graph.')\n",
    "            return None\n",
    "        # create dot file for sfdp\n",
    "        self.toDot(graph, self.working_dir, 'dotdot.dot')\n",
    "        # run sfdp to create grafics file\n",
    "        subprocess.run (['sfdp', self.working_dir + 'dotdot.dot', '-o' + self.working_dir + 'svgGraph-poor.svg', '-Goverlap=prism', '-Tsvg'])\n",
    "        # read grafics file just created\n",
    "        os.chdir(self.working_dir)\n",
    "        with open('svgGraph-poor.svg', 'r', encoding='utf-8') as f:\n",
    "            svg_in = ET.parse(f)\n",
    "            root_in = svg_in.getroot()\n",
    "        ns = {'svg': 'http://www.w3.org/2000/svg'}\n",
    "        # compute font size and transform parameter\n",
    "        nodes = root_in.findall('svg:g/svg:g[@class=\"node\"]',ns)\n",
    "        xx = [rx for rx in self.nds['rx_fd']]\n",
    "        font_size = scale*math.ceil(float(max(xx))/12)\n",
    "        transform = root_in.find('svg:g[@id=\"graph0\"]',ns).get('transform')\n",
    "        # create html head section\n",
    "        preview = ET.Element('html')\n",
    "        head  = ET.SubElement(preview, 'head')\n",
    "        # node styling css\n",
    "        style = ET.SubElement(head, 'style')\n",
    "        style.text = \\\n",
    "        ' .i-alc   {fill: #7087ED; stroke: #7087ED; background-color: #7087ED}' +\\\n",
    "        ' .i-carb  {fill: #C8A98B; stroke: #C8A98B; background-color: #C8A98B}' +\\\n",
    "        ' .i-condi {fill: #D58680; stroke: #D58680; background-color: #D58680}' +\\\n",
    "        ' .i-egg   {fill: #70A287; stroke: #70A287; background-color: #70A287}' +\\\n",
    "        ' .i-etc   {fill: #9AA6BF; stroke: #9AA6BF; background-color: #9AA6BF}' +\\\n",
    "        ' .i-fat   {fill: #81CDD8; stroke: #81CDD8; background-color: #81CDD8}' +\\\n",
    "        ' .i-fish  {fill: #ffdab9; stroke: #ffdab9; background-color: #ffdab9}' +\\\n",
    "        ' .i-fruit {fill: #7FDD46; stroke: #7FDD46; background-color: #7FDD46}' +\\\n",
    "        ' .i-herb  {fill: #95A84E; stroke: #95A84E; background-color: #95A84E}' +\\\n",
    "        ' .i-meat  {fill: #EE5874; stroke: #EE5874; background-color: #EE5874}' +\\\n",
    "        ' .i-milk  {fill: #6EA2DC; stroke: #6EA2DC; background-color: #6EA2DC}' +\\\n",
    "        ' .i-nuts  {fill: #D09E44; stroke: #D09E44; background-color: #D09E44}' +\\\n",
    "        ' .i-onion {fill: #60C667; stroke: #60C667; background-color: #60C667}' +\\\n",
    "        ' .i-spice {fill: #FF7F50; stroke: #FF7F50; background-color: #FF7F50}' +\\\n",
    "        ' .i-sweet {fill: #CDE1A6; stroke: #CDE1A6; background-color: #CDE1A6}' +\\\n",
    "        ' .i-veg   {fill: #65DDB7; stroke: #65DDB7; background-color: #65DDB7}'\n",
    "        # js functions for buttons\n",
    "        script = ET.SubElement(head, 'script')\n",
    "        script.text = \\\n",
    "        'function show_A()    {' +\\\n",
    "        'let g0 = document.getElementById(\"graph0\");' +\\\n",
    "        'let g1 = g0.cloneNode(false);' +\\\n",
    "        'g0.remove();' +\\\n",
    "        'const n = document.createElementNS(\"http://www.w3.org/2000/svg\",\"use\");' +\\\n",
    "        'n.setAttribute(\"href\",\"#A_nodes\");' +\\\n",
    "        'g1.appendChild (n);' +\\\n",
    "        'let svg = document.getElementsByTagName(\"svg\")[0];' +\\\n",
    "        'svg.appendChild(g1);' +\\\n",
    "        '};' +\\\n",
    "        'function show_B()    {' +\\\n",
    "        'let g0 = document.getElementById(\"graph0\");' +\\\n",
    "        'let g1 = g0.cloneNode(false);' +\\\n",
    "        'g0.remove();' +\\\n",
    "        'const n = document.createElementNS(\"http://www.w3.org/2000/svg\",\"use\");' +\\\n",
    "        'n.setAttribute(\"href\",\"#B_nodes\");' +\\\n",
    "        'g1.appendChild (n);' +\\\n",
    "        'let svg = document.getElementsByTagName(\"svg\")[0];' +\\\n",
    "        'svg.appendChild(g1);' +\\\n",
    "        '};' +\\\n",
    "        'function show_AB()   {' +\\\n",
    "        'let g0 = document.getElementById(\"graph0\");' +\\\n",
    "        'let g1 = g0.cloneNode(false);' +\\\n",
    "        'g0.remove();' +\\\n",
    "        'const n = document.createElementNS(\"http://www.w3.org/2000/svg\",\"use\");' +\\\n",
    "        'n.setAttribute(\"href\",\"#AB_nodes\");' +\\\n",
    "        'g1.appendChild (n);' +\\\n",
    "        'let svg = document.getElementsByTagName(\"svg\")[0];' +\\\n",
    "        'svg.appendChild(g1);' +\\\n",
    "        '};' +\\\n",
    "        'function show_full() {' +\\\n",
    "        'let g0 = document.getElementById(\"graph0\");' +\\\n",
    "        'let g1 = g0.cloneNode(false);' +\\\n",
    "        'g0.remove();' +\\\n",
    "        'const nA = document.createElementNS(\"http://www.w3.org/2000/svg\",\"use\");' +\\\n",
    "        'nA.setAttribute(\"href\",\"#A_nodes\");' +\\\n",
    "        'g1.appendChild (nA);' +\\\n",
    "        'const nB = document.createElementNS(\"http://www.w3.org/2000/svg\",\"use\");' +\\\n",
    "        'nB.setAttribute(\"href\",\"#B_nodes\");' +\\\n",
    "        'g1.appendChild (nB);' +\\\n",
    "        'const nAB = document.createElementNS(\"http://www.w3.org/2000/svg\",\"use\");' +\\\n",
    "        'nAB.setAttribute(\"href\",\"#AB_nodes\");' +\\\n",
    "        'g1.appendChild (nAB);' +\\\n",
    "        'let svg = document.getElementsByTagName(\"svg\")[0];' +\\\n",
    "        'svg.appendChild(g1);' +\\\n",
    "        '};' \n",
    "        # create button area in HTML body\n",
    "        body  = ET.SubElement(preview, 'body')\n",
    "        div_attr   = {'style':'width:auto;height:120px;'}\n",
    "        div_form   = ET.SubElement(body,'div', attrib=div_attr)\n",
    "        buttonA_attr = {'id':'btn_graph_A', 'type':'button','onclick':'show_A()', 'style':f\"cursor:pointer;font-size:24px; margin:24px; padding:12px\"}\n",
    "        buttonA      = ET.SubElement(div_form, 'button', attrib=buttonA_attr)\n",
    "        buttonA.text = 'subgraph A'\n",
    "        buttonB_attr = {'id':'btn_graph_B', 'type':'button','onclick':'show_B()', 'style':f\"cursor:pointer;font-size:24px; margin:24px; padding:12px\"}\n",
    "        buttonB      = ET.SubElement(div_form, 'button', attrib=buttonB_attr)\n",
    "        buttonB.text = 'subgraph B'\n",
    "        buttonAB_attr = {'id':'btn_graph_AB', 'type':'button','onclick':'show_AB()', 'style':f\"cursor:pointer;font-size:24px; margin:24px; padding:12px\"}\n",
    "        buttonAB      = ET.SubElement(div_form, 'button', attrib=buttonAB_attr)\n",
    "        buttonAB.text = 'subgraph A ∩ B'\n",
    "        buttonfull_attr = {'id':'btn_graph_full', 'type':'button','onclick':'show_full()', 'style':f\"cursor:pointer;font-size:24px; margin:24px; padding:12px\"}\n",
    "        buttonAB      = ET.SubElement(div_form, 'button', attrib=buttonfull_attr)\n",
    "        buttonAB.text = 'full graph'\n",
    "        # create SVG div\n",
    "        div   = ET.SubElement(body,'div')\n",
    "        svg_out_attr = {'xmlns':'http://www.w3.org/2000/svg', 'xmlns:xlink':'http://www.w3.org/1999/xlink', 'version':'1.1', 'viewBox':root_in.get('viewBox')}\n",
    "        svg_out = ET.SubElement(div, 'svg', attrib=svg_out_attr)\n",
    "        # create SVG defs for graph nodes\n",
    "        defs = ET.SubElement(svg_out,'defs')\n",
    "        nodes_A = ET.SubElement(defs, 'g', id='A_nodes')\n",
    "        nodes_B = ET.SubElement(defs, 'g', id='B_nodes')\n",
    "        nodes_AB = ET.SubElement(defs, 'g', id='AB_nodes')\n",
    "        nodes    = ET.SubElement(defs, 'g', id='nodes')\n",
    "        for n in graph.nodes():\n",
    "            sub = self.nds.at[n,'sub']\n",
    "            if   sub ==  'A' : def_el = nodes_A\n",
    "            elif sub ==  'B' : def_el = nodes_B\n",
    "            elif sub == 'AB' : def_el = nodes_AB\n",
    "            else: def_el = None\n",
    "            node_attr   = {'class':'node', 'id':n, 'data-sub':sub, 'style':'cursor: pointer;'}\n",
    "            node        = ET.SubElement(def_el, 'g', attrib=node_attr)\n",
    "            title       = ET.SubElement(node, 'title')\n",
    "            title.text  = f\"#occ: {self.nds.at[n,'occ']}\"\n",
    "            ellip_class = f\"i-{self.nds.at[n,'class']}\"            \n",
    "            ellip_attr  = {'class':ellip_class, 'cx':self.nds.at[n,'cx_fd'], 'cy':self.nds.at[n,'cy_fd'], 'rx':self.nds.at[n,'rx_fd'], 'ry':self.nds.at[n,'ry_fd']}\n",
    "            ET.SubElement(node, 'ellipse', attrib=ellip_attr)\n",
    "            text_attr   = {'x':self.nds.at[n,'txt_x'], 'y':self.nds.at[n,'txt_y'], 'style':f\"text-anchor: middle; font-family: Arial; font-size: {font_size}px;\"}\n",
    "            text        = ET.SubElement(node, 'text', attrib=text_attr)\n",
    "            text.text   = self.nds.at[n,'name'] \n",
    "        # create SVG main graph\n",
    "        graph0_attr = {'transform':transform, 'id':'graph0'}\n",
    "        graph0 = ET.SubElement(svg_out,'g', attrib=graph0_attr)\n",
    "        use_attr = {'href':'#A_nodes'}\n",
    "        ET.SubElement(graph0,'use', use_attr)\n",
    "        use_attr = {'href':'#B_nodes'}\n",
    "        ET.SubElement(graph0,'use', use_attr)\n",
    "        use_attr = {'href':'#AB_nodes'}\n",
    "        ET.SubElement(graph0,'use', use_attr)\n",
    "        # write HTML to file\n",
    "        tree = ET.ElementTree(preview)\n",
    "        ET.indent(tree)\n",
    "        tree.write(self.working_dir + 'preview.html')\n",
    "        return\n",
    "    \n",
    "    def makeSVG(self,graph=None,rcpName=None,occ_growing=None,wgt_growing=None,ix=None,fontsize=None):\n",
    "        \"\"\"\n",
    "        make SVG for graph, use occ_growing and wgt_growing\n",
    "        \"\"\"\n",
    "        #ns = {'fr': 'http://fruschtique.de/ns/recipe', 'fe': 'http://fruschtique.de/ns/fe', 'fc': 'http://fruschtique.de/ns/igt-catalog'}\n",
    "        # svg header\n",
    "        w  = self.viewbox.split()[2]\n",
    "        h  = self.viewbox.split()[3]\n",
    "        svg_out_attr = {'xmlns':'http://www.w3.org/2000/svg', 'xmlns:xlink':'http://www.w3.org/1999/xlink', 'version':'1.1', 'viewbox':self.viewbox, \\\n",
    "                        'preserveAspectRatio':'xMidYMid meet', 'zoomAndPan':'magnify', 'contentScriptType':'text/ecmascript', 'contentStyleType':'text/css', 'width':w, 'height':h}\n",
    "        svg_out = ET.Element('svg', attrib=svg_out_attr)\n",
    "        style = ET.SubElement(svg_out, 'style')\n",
    "        style.text = \\\n",
    "            ' .i-alc   {fill: #7087ED; stroke: #7087ED; background-color: #7087ED}' +\\\n",
    "            ' .i-carb  {fill: #C8A98B; stroke: #C8A98B; background-color: #C8A98B}' +\\\n",
    "            ' .i-condi {fill: #D58680; stroke: #D58680; background-color: #D58680}' +\\\n",
    "            ' .i-egg   {fill: #70A287; stroke: #70A287; background-color: #70A287}' +\\\n",
    "            ' .i-etc   {fill: #9AA6BF; stroke: #9AA6BF; background-color: #9AA6BF}' +\\\n",
    "            ' .i-fat   {fill: #81CDD8; stroke: #81CDD8; background-color: #81CDD8}' +\\\n",
    "            ' .i-fish  {fill: #ffdab9; stroke: #ffdab9; background-color: #ffdab9}' +\\\n",
    "            ' .i-fruit {fill: #7FDD46; stroke: #7FDD46; background-color: #7FDD46}' +\\\n",
    "            ' .i-herb  {fill: #95A84E; stroke: #95A84E; background-color: #95A84E}' +\\\n",
    "            ' .i-meat  {fill: #EE5874; stroke: #EE5874; background-color: #EE5874}' +\\\n",
    "            ' .i-milk  {fill: #6EA2DC; stroke: #6EA2DC; background-color: #6EA2DC}' +\\\n",
    "            ' .i-nuts  {fill: #D09E44; stroke: #D09E44; background-color: #D09E44}' +\\\n",
    "            ' .i-onion {fill: #60C667; stroke: #60C667; background-color: #60C667}' +\\\n",
    "            ' .i-spice {fill: #FF7F50; stroke: #FF7F50; background-color: #FF7F50}' +\\\n",
    "            ' .i-sweet {fill: #CDE1A6; stroke: #CDE1A6; background-color: #CDE1A6}' +\\\n",
    "            ' .i-veg   {fill: #65DDB7; stroke: #65DDB7; background-color: #65DDB7}'\n",
    "        # svg graph\n",
    "        g0_node_attr = {'id':'graph0', 'transform':self.transform}\n",
    "        g0_node = ET.SubElement(svg_out,'g',attrib=g0_node_attr)    \n",
    "        rcp_g_attr = {'id':f\"rr-{ix}\"}\n",
    "        rcp_g      = ET.SubElement(g0_node,'g',attrib=rcp_g_attr)\n",
    "        name_field = ET.SubElement(rcp_g,'g')\n",
    "        nf_back_attr = {'x':str(float(w)/2), 'y':str(400.0 - float(h)), 'width':str(float(w)/2), 'height':str(float(h)/24), 'fill':'white', 'stroke':'white', 'stroke-width':'1', 'fill-opacity':'1', 'stroke-opacity':'1'}\n",
    "        nf_back      = ET.SubElement(name_field, 'rect', nf_back_attr) \n",
    "        nf_text_attr = {'x':str(240.0), 'y':str(600.0 - float(h)), 'style':f\"text-anchor: start; font-family: Arial; font-size: {1.5*fontsize}px;\"}\n",
    "        nf_text      = ET.SubElement(name_field, 'text', nf_text_attr)\n",
    "        nf_text.text = f\"{ix:02d} {rcpName}\"\n",
    "        # recipe graph edges\n",
    "        for u,v,att in graph.edges(data=True):\n",
    "            ed_id       = att.get('id')\n",
    "            edge_attr   = {'class':'edge', 'id':ed_id, 'style':'cursor: pointer;'}\n",
    "            edge        = ET.SubElement(rcp_g, 'g', attrib=edge_attr)\n",
    "            start_x     = self.eds.at[ed_id,'start_x_node']\n",
    "            start_y     = self.eds.at[ed_id,'start_y_node']\n",
    "            end_x       = self.eds.at[ed_id,'end_x_node']\n",
    "            end_y       = self.eds.at[ed_id,'end_y_node']\n",
    "            pt_coor     = f\"M{start_x},{start_y}L{end_x},{end_y}\"\n",
    "            xx = wgt_growing.get(ed_id)\n",
    "            if xx == 1:\n",
    "                path_attr   = {'fill':'none', 'stroke': 'black', 'd':pt_coor}\n",
    "            elif xx == 2: \n",
    "                path_attr   = {'fill':'none', 'stroke': 'black', 'stroke-width':'2', 'd':pt_coor}\n",
    "            elif xx > 2: \n",
    "                path_attr   = {'fill':'none', 'stroke': 'red', 'stroke-width':'2', 'd':pt_coor}\n",
    "            else: \n",
    "                path_attr   = {'fill':'none', 'stroke': 'black', 'd':pt_coor}\n",
    "            path        = ET.SubElement(edge,'path',path_attr)\n",
    "        # recipe graph nodes\n",
    "        for n in graph.nodes():\n",
    "            node_attr   = {'class':'node', 'id':n, 'data-sub':self.nds.at[n,'sub'], 'style':'cursor: pointer;'}\n",
    "            node        = ET.SubElement(rcp_g, 'g', attrib=node_attr)\n",
    "            title       = ET.SubElement(node, 'title')\n",
    "            title.text  = f\"#occ: {occ_growing.get(n)}\"\n",
    "            ellip_class = f\"i-{self.nds.at[n,'class']}\" \n",
    "            x           = 36*(1 + 3*math.sqrt(occ_growing.get(n)))\n",
    "            rx          = str(round(x*2, 0)/2)\n",
    "            ry          = rx              \n",
    "            ellip_attr  = {'class':ellip_class, 'cx':self.nds.at[n,'cx_fd'], 'cy':self.nds.at[n,'cy_fd'], 'rx':rx, 'ry':ry}\n",
    "            ET.SubElement(node, 'ellipse', attrib=ellip_attr)\n",
    "            text_attr   = {'x':self.nds.at[n,'txt_x'], 'y':self.nds.at[n,'txt_y'], 'style':f\"text-anchor: middle; font-family: Arial; font-size: {fontsize}px;\"}\n",
    "            text        = ET.SubElement(node, 'text', attrib=text_attr)\n",
    "            text.text   = self.nds.at[n,'name'] \n",
    "        # return svg\n",
    "        return svg_out\n",
    "    \n",
    "    def createSVGSequence(self,rcpNames=None,targetDir=None):\n",
    "        \"\"\"\n",
    "        generate svg per recipe graph in order as given by rcpNames list\n",
    "        collect resulting svg files in directory\n",
    "        node coordinates to be taken from ingredient graph svg\n",
    "        edge coordinates to be taken from start and end node coordinates\n",
    "        provide occ_growing and weight_growing to SVGMaker\n",
    "        \"\"\"\n",
    "        # init\n",
    "        K  = nx.Graph()                                  # empty recipe graph (complete graph)\n",
    "        ix = 1                                           # sequence number\n",
    "        xx = [rx for rx in self.nds['rx_fd']]\n",
    "        font_size = math.ceil(float(max(xx))/10)\n",
    "        occ_growing = {idx:0 for idx in self.nds.index}  # init occ_growing\n",
    "        wgt_growing = {idx:0 for idx in self.eds.index}          \n",
    "        # loop over recipes in collection for creating recipe graphs\n",
    "        for rcpName in rcpNames:                         # collect ingredients for recipe graph\n",
    "            occ_list = []\n",
    "            rcp_igt_set = set()\n",
    "            xx = [rcp.get('ingredients') for rcp in self.full_rcp_list if rcp.get('recipeName') == rcpName]\n",
    "            for ingredient in xx[0]:\n",
    "                rcp_igt_set.add(ingredient)\n",
    "            occ_list.extend(list(rcp_igt_set))\n",
    "            K = nx.complete_graph(rcp_igt_set)           # build recipe graph\n",
    "            for k in rcp_igt_set:\n",
    "                occ_growing[k] += 1              \n",
    "            # add attributes to edges of G\n",
    "                # edge id\n",
    "            e_attr = {}\n",
    "            for e in list(K.edges(data=True)):\n",
    "                x = [e[0],e[1]]\n",
    "                x.sort(key=locale.strxfrm)\n",
    "                id = str(x[0]) + '--' + str(x[1])\n",
    "                xx = (e[0],e[1])\n",
    "                e_attr[xx] = {'id':id}\n",
    "            nx.set_edge_attributes(K, e_attr)\n",
    "            for k in list(nx.get_edge_attributes(K,'id').values()):\n",
    "                wgt_growing[k] += 1\n",
    "            # save to file\n",
    "            build = self.makeSVG(K,rcpName,occ_growing,wgt_growing,ix,font_size)\n",
    "            tree = ET.ElementTree(build)\n",
    "            ET.indent(tree)\n",
    "            fn = f\"{ix:03d} {rcpName}.svg\"\n",
    "            file_path = f\"{os.path.join(targetDir,fn)}\"\n",
    "            tree.write(file_path)\n",
    "            ix += 1\n",
    "        return\n",
    "\n",
    "    def sortByContrib2IG(self, rcpNames=None):\n",
    "        \"\"\"\n",
    "        sort recipes by contribution of distinct ingredients to full graph, descending\n",
    "        \"\"\"\n",
    "        # function for sorting subset of Pandas dataframe\n",
    "        def sort_sub(df, i1, i2, by_col):\n",
    "            a = df.iloc[i1:i2].copy()\n",
    "            a.sort_values(by=by_col, inplace=True, ascending=False, ignore_index=True)\n",
    "            df.iloc[i1:i2] = a\n",
    "            return df\n",
    "        # collect ingredients lists\n",
    "        igt_sets = []\n",
    "        for rcpName in rcpNames:    \n",
    "            igt_set = [set(rcp.get('ingredients')) for rcp in self.full_rcp_list if rcp.get('recipeName') == rcpName]\n",
    "            igt_sets.extend(igt_set)\n",
    "        count = [len(igt_set) for igt_set in igt_sets]\n",
    "        # create Pandas dataframe for recipes and their ingredients\n",
    "        collection_df = pd.DataFrame({'number':range(1,len(rcpNames)+1), 'rcp_names': rcpNames, 'rcp_ingredients': igt_sets, 'count_igt': count})\n",
    "        #print (collection_df)\n",
    "        # first: recipe with max number of ingredients\n",
    "        collection_df.sort_values(by='count_igt', inplace=True, ascending=False, ignore_index=True)\n",
    "        #print (collection_df)\n",
    "        # init dataframe before sorting\n",
    "        collection_df['union'] = [set() for i in range(len(rcpNames))]\n",
    "        collection_df['union_len'] = 0\n",
    "        collection_df.at[0,'union'] = collection_df.at[0,'rcp_ingredients']\n",
    "        collection_df.at[0,'union_len'] = len(collection_df.at[0,'union'])\n",
    "        # sort dataframe by union length\n",
    "        for ix in range(1,len(rcpNames)):   \n",
    "            for ix2 in range (ix,len(rcpNames)):\n",
    "                coll = collection_df.at[ix2,'rcp_ingredients'].union(collection_df.at[ix-1,'union'])\n",
    "                collection_df.at[ix2,'union']     = coll\n",
    "                collection_df.at[ix2,'union_len'] = len(coll)\n",
    "            sort_sub(collection_df,ix,len(rcpNames),'union_len')\n",
    "        #print (collection_df)\n",
    "        print (list(collection_df['rcp_names']))\n",
    "        return list(collection_df['rcp_names'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62ac6f58",
   "metadata": {},
   "source": [
    "#### fruschtique API functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9c15d00f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Helper functions\n",
    "\n",
    "index = dict()\n",
    "noRefIgts = []\n",
    "    \n",
    "# find longest matching ID for given ingredient name\n",
    "def getIgtID (given, index):\n",
    "    match = 0\n",
    "    xxid = None\n",
    "    for k,v in index.items():\n",
    "        if k in given.lower():\n",
    "            if len(k) > match:\n",
    "                match = len(k)\n",
    "                xxid = v\n",
    "    return xxid\n",
    "\n",
    "# write ingredient ID into recipe\n",
    "def write2XML(rcp,ns,igt,id):\n",
    "    el = rcp.findall(f'.//fr:igdtName[.=\"{igt}\"]', ns)\n",
    "    for x in el:\n",
    "        x.set('ref',id)\n",
    "        print\n",
    "    return el\n",
    "\n",
    "# read ingredients catalogue and create ingredients index\n",
    "def createIgdtIndex (igdtCat):\n",
    "    global index, noRefIgts\n",
    "    with open(igdtCat, encoding='utf-8') as file:\n",
    "        cat            = json.load(file)\n",
    "        catIngredients = cat.get('ingredients')\n",
    "        #catClasses     = cat.get('classes')\n",
    "        noRefIgts      = cat.get('noRefIgts')\n",
    "        index = dict()\n",
    "        for igt in catIngredients.items():\n",
    "            x = dict()\n",
    "            k = igt[0]\n",
    "            x = {k:k}\n",
    "            index.update(x)\n",
    "            y = dict()\n",
    "            for syn in igt[1].get('synonyms'):\n",
    "                y = {syn:k}\n",
    "                index.update(y)\n",
    "        return\n",
    "\n",
    "# create refs, write them into recipe, and return results list\n",
    "def writeRefs2rcp (loc,rcpName,ns):\n",
    "    global index, noRefIgts\n",
    "    fp = os.path.join(loc,rcpName)\n",
    "    with open(fp, 'r', encoding='utf-8') as f:\n",
    "        rcp_in = ET.parse(f)\n",
    "        rcp_root = rcp_in.getroot()\n",
    "    allGiven = [entry.text.replace('\"','') for entry in rcp_root.findall('.//fr:igdtName', ns)]\n",
    "    suc = 0\n",
    "    noSuc = []\n",
    "    for ig in allGiven:\n",
    "        match = getIgtID(ig, index)\n",
    "        if match == None:\n",
    "            noSuc.append(ig)\n",
    "        else:\n",
    "            suc += 1\n",
    "            write2XML(rcp_root,ns,ig,match) \n",
    "    for xx in noSuc:\n",
    "        for x in noRefIgts:\n",
    "            if x in xx:\n",
    "                suc += 1\n",
    "    tree = ET.ElementTree(rcp_root)\n",
    "    ET.indent(tree)\n",
    "    tree.write(fp)\n",
    "    return {'total':len(allGiven), 'success':suc, 'fail':[], 'recipe name':rcpName}\n",
    "\n",
    "### API functions for creating references to ingredients catalogue\n",
    "\n",
    "def createRefs4Recipe(loc=None,rcpName=None,igdtCat=None):\n",
    "    global index, noRefIgts\n",
    "    createIgdtIndex(igdtCat)\n",
    "    ns = {'fr': 'http://fruschtique.de/ns/recipe'}\n",
    "    return \n",
    "\n",
    "def createRefs4Coll(loc=None,igdtCat=None):\n",
    "    # loop over recipes in loc directory\n",
    "    # call to createRefs4Recipe per recipe\n",
    "    # write modified recipes back to loc directory\n",
    "    global index, noRefIgts\n",
    "    createIgdtIndex(igdtCat)\n",
    "    ns = {'fr': 'http://fruschtique.de/ns/recipe'}\n",
    "    results = []\n",
    "    for rcp in os.listdir(loc):\n",
    "        result = writeRefs2rcp (loc,rcp,ns)\n",
    "        results.append (result)\n",
    "    return results\n",
    "\n",
    "### API scraper functions \n",
    "\n",
    "def scrapeCK (loc=None, url=None, extended_name=None, synList=None):\n",
    "\n",
    "    # when reading from file:\n",
    "    #with open(url, 'r') as f:\n",
    "    #    root = BeautifulSoup(f, 'html.parser')\n",
    "\n",
    "    # when reading from web\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200: \n",
    "        root = BeautifulSoup(response.text, 'html.parser')\n",
    "    else:\n",
    "        return -1\n",
    "    \n",
    "    name = extended_name \n",
    "    instruct = root.select(\"small+div.ds-box\")[0].get_text(separator = '\\n',strip=True)\n",
    "    # find ingredient tables\n",
    "    hidden = root.find('div', {'amp-access':'rolesMap.ROLE_ENTITLEMENT_PLUS_RECIPES'})\n",
    "    if hidden == None:\n",
    "        igdt_tables = root.select('.ingredients')\n",
    "    else:\n",
    "        igdt_tables = root.select('div[amp-access=\"rolesMap.ROLE_ENTITLEMENT_PLUS_RECIPES\"] > .ingredients')\n",
    "\n",
    "    igt_list_text = ''\n",
    "    for idx in range(0,len(igdt_tables)):\n",
    "        igt_list_text += igdt_tables[idx].get_text()\n",
    "    #print (f\"Found {len(igdt_tables)} ingredient tables.\")\n",
    "    for syn in synList:\n",
    "        if (syn in name.lower()) or (syn in igt_list_text.lower()) or (syn in instruct.lower()):\n",
    "            break\n",
    "        else:\n",
    "            return 0\n",
    "    _id  = f'ck-{uuid.uuid4()}'\n",
    "    \n",
    "    fr = 'http://fruschtique.de/ns/recipe'\n",
    "    ET.register_namespace('fr', fr)\n",
    "    xsi = 'http://www.w3.org/2001/XMLSchema-instance'\n",
    "    recipe = ET.Element('fr:recipe', attrib={'xmlns:fr' : fr, 'xmlns:xsi': xsi, 'xsi:schemaLocation': fr + ' file:///c:/Users/nlutt/Documents/Websites/tools/recipe.xsd', 'rcpID': _id})\n",
    "    meta = ET.SubElement(recipe, 'fr:meta')\n",
    "    ET.SubElement(meta, 'fr:book').text = ''\n",
    "    ET.SubElement(meta, 'fr:chapter').text = ''\n",
    "    ET.SubElement(recipe, 'fr:recipeName').text = extended_name\n",
    "    ET.SubElement(recipe, 'fr:recipeKeywords')\n",
    "    ET.SubElement(recipe, 'fr:recipeIntro')\n",
    "    recipe_ingredients = ET.SubElement(recipe, 'fr:recipeIngredients')\n",
    "    igdt_list = ET.SubElement(recipe_ingredients, 'fr:igdtList')\n",
    "    ET.SubElement(igdt_list, 'fr:igdtListName')\n",
    "    for idx in range(0, len(igdt_tables)):\n",
    "        #print (f\" table {idx}\")\n",
    "        igt_list_rows = igdt_tables[idx].select('tbody tr')\n",
    "        for i in range(0, len(igt_list_rows)):\n",
    "            #print (f\" row {i}\")\n",
    "            igdt_list_line = ET.SubElement(igdt_list, 'fr:igdtListLine')\n",
    "            x = igt_list_rows[i].select('td')[0].get_text().replace('\"','')\n",
    "            xx = \" \".join(x.split())\n",
    "            ET.SubElement(igdt_list_line, 'fr:igdtQuantity').text = xx\n",
    "            y = igt_list_rows[i].select('td')[1].get_text().replace('\"','')\n",
    "            yy = \" \".join(y.split())\n",
    "            #print (yy)\n",
    "            ET.SubElement(igdt_list_line, 'fr:igdtName', attrib={'ref':''}).text = yy\n",
    "\n",
    "    instructions = ET.SubElement(recipe, 'fr:recipeInstructions')\n",
    "    instruction = ET.SubElement (instructions,'fr:instruction')\n",
    "    ET.SubElement(instruction,'fr:instrStepName')\n",
    "    ET.SubElement(instruction,'fr:instrStepText').text = instruct\n",
    "    ET.SubElement(recipe, 'fr:recipeSideDish')\n",
    "    ET.SubElement(recipe, 'fr:recipeOrigin')\n",
    "    ET.SubElement(recipe, 'fr:recipeSeeAlso')\n",
    "    ET.SubElement(recipe, 'fr:recipeLicense')\n",
    "    xml_rcp = ET.ElementTree(recipe)\n",
    "    return xml_rcp\n",
    "\n",
    "def parse_search_result_page(url=None):\n",
    "    response = requests.get(url)\n",
    "    body = response.text\n",
    "    xx = response.status_code\n",
    "    #print (xx)\n",
    "    if xx != 200:\n",
    "        return -1\n",
    "    root = BeautifulSoup(body, 'html.parser')\n",
    "    rcpList = []\n",
    "    nameList = []\n",
    "    for el in root.select('.recipe-list>.ds-recipe-card'):\n",
    "        rcp_name = el.get('data-vars-recipe-title').replace('\"','').replace('/','').replace('  ',' ').replace(' - ','-')\n",
    "        #print (rcp_name)\n",
    "        x_url = el.find('a').get('href')\n",
    "        rcp_url = x_url.split('#')[0]\n",
    "        #print (rcp_url)\n",
    "        if rcp_name is not None:\n",
    "            rcpList.append((rcp_name,rcp_url))\n",
    "            nameList.append (rcp_name)\n",
    "    return rcpList, nameList\n",
    "\n",
    "def scrapeCKbyKey(loc=None, culinaryKey=None, igdtCat=None):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    # create complete recipe list\n",
    "    totalRcpList = []\n",
    "    ctrList = []\n",
    "    i1 = 0\n",
    "    while True:\n",
    "        url = f'https://www.chefkoch.de/rs/s{i1}/{culinaryKey}/Rezepte.html'\n",
    "        xx = parse_search_result_page(url)\n",
    "        if xx != -1:\n",
    "            totalRcpList.extend(xx[0])\n",
    "            ctrList.extend(xx[1])\n",
    "            i1 += 1\n",
    "        else:\n",
    "            break\n",
    "    print ('CK search results: ', len(totalRcpList))  \n",
    "\n",
    "    ctr = dict(Counter(ctrList))\n",
    "    #print (ctr)\n",
    "\n",
    "    # provide list of synonyms for culinary key\n",
    "    with open('C:/Users/nlutt/myPyPro/second/data/igt_cat.json', encoding='utf-8') as file:\n",
    "        cat            = json.load(file)\n",
    "        catIngredients = cat.get('ingredients')\n",
    "    _id = ''\n",
    "    for k,v in catIngredients.items():\n",
    "        #print (k)\n",
    "        if v.get('i-name') == culinaryKey:\n",
    "            _id = k\n",
    "            break\n",
    "    if _id == '':\n",
    "        print (f\"{culinaryKey} not in ingredients catalogue!\")\n",
    "        return\n",
    "            \n",
    "    synList = [catIngredients.get(_id).get('i-name').lower()]\n",
    "    for syn in catIngredients.get(_id).get('synonyms'):\n",
    "        synList.append(syn)\n",
    "    #print (synList)\n",
    "    # scrape CK recipes and write to XML files\n",
    "    i = 0\n",
    "    for rcp in totalRcpList:\n",
    "        rcpName = rcp[0].replace('\"','').replace('/','').replace('  ',' ').replace(' - ','-')\n",
    "        url = rcp[1]\n",
    "        name_counter = ctr.get(rcpName)\n",
    "        if name_counter > 1:\n",
    "            extension = str(name_counter).zfill(3)\n",
    "            extended_fn = f\"{rcpName} {extension}.xml\"\n",
    "            extended_rcpName = f\"{rcpName} {extension}\"\n",
    "            ctr.update({rcpName:name_counter - 1})\n",
    "        else:\n",
    "            extended_fn = f\"{rcpName}.xml\" \n",
    "            extended_rcpName = rcpName\n",
    "        xml_rcp = scrapeCK (loc,url,extended_rcpName,synList)\n",
    "        if xml_rcp == 0:\n",
    "            print (rcpName)\n",
    "        elif xml_rcp == -1: \n",
    "            print ('Done!')\n",
    "            break\n",
    "        else: \n",
    "            i += 1\n",
    "            print (i)  \n",
    "            file_path = f\"{os.path.join(loc,extended_fn)}\"\n",
    "            xml_rcp.write(file_path, xml_declaration=True, encoding='utf-8', method='xml') \n",
    "    print ('Done!')\n",
    "    return\n",
    "\n",
    "def makeSampleSpace(sourceDir=None, graphlabDir=None, sampleSpaceName=None, cb=None, meta=None):\n",
    "    \"\"\"\n",
    "    1 Create folder for new sample space\n",
    "    2 Create XML-coded catalog of recipes in sourcedir\n",
    "    3 create XML-coded descriptor for collection \n",
    "    \"\"\"\n",
    "    # new sample space\n",
    "    newSpace = os.path.join(graphlabDir,'sampleSpaces',sampleSpaceName)\n",
    "    if not os.path.exists(newSpace):\n",
    "        os.makedirs(newSpace)\n",
    "    newGraphsDir = os.path.join(newSpace,'graphs')\n",
    "    if not os.path.exists(newGraphsDir):   \n",
    "        os.makedirs(newGraphsDir)\n",
    "    # catalogue of files in collection\n",
    "    sourceFiles = [os.path.join(sourceDir,f) for f in os.listdir(sourceDir) if os.path.isfile(os.path.join(sourceDir, f))]\n",
    "    collection = ET.Element('collection')\n",
    "    for f in sourceFiles:\n",
    "        x = urllib.parse.urljoin('file:', pathname2url(f))\n",
    "        doc = ET.SubElement(collection,'doc',attrib={'href':x})\n",
    "    cata = ET.ElementTree(collection)\n",
    "    ET.indent(cata)\n",
    "    cata.write(os.path.join(newSpace,'catalogue.xml'), xml_declaration=True, encoding='utf-8', method='xml')\n",
    "    # create descriptor\n",
    "    fe = 'http://fruschtique.de/ns/fe'\n",
    "    ET.register_namespace('fe', fe)\n",
    "    xsi = 'http://www.w3.org/2001/XMLSchema-instance' \n",
    "    experiment = ET.Element('fe:experiment', attrib={'xmlns:fe' : fe, 'xmlns:xsi': xsi, 'xsi:schemaLocation': fe + ' file:///c:/users/nlutt/documents/websites/graphlab/tools/experiment.xsd'})\n",
    "    fullTitle = ET.SubElement(experiment,'fe:fullTitle')\n",
    "    fullTitle.text = f\"{sampleSpaceName}\"\n",
    "    cookbook = ET.SubElement(experiment,'fe:cookbook')\n",
    "    cookbook.text = cb\n",
    "    experimentPath = ET.SubElement(experiment,'fe:experimentPath')\n",
    "    experimentPath.text = f'sampleSpaces/{sampleSpaceName}/'\n",
    "    winExperimentPath = ET.SubElement(experiment,'fe:win-experimentPath')\n",
    "    winExperimentPath.text = f\"{os.path.join('sampleSpaces',sampleSpaceName)}\\\\\"\n",
    "    experimentName = ET.SubElement(experiment,'fe:experimentName')\n",
    "    experimentName.text = f\"{sampleSpaceName}\"\n",
    "    ET.SubElement(experiment,'fe:experimentDescription')\n",
    "    useIngredientReplacements = ET.SubElement(experiment,'fe:useIngredientReplacements')\n",
    "    useIngredientReplacements.text = 'no'\n",
    "    descriptor = ET.ElementTree(experiment)\n",
    "    ET.indent(descriptor)\n",
    "    descriptor.write(os.path.join(graphlabDir,f'currentDescriptor {sampleSpaceName}.xml'), xml_declaration=True, encoding='utf-8', method='xml')\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a3b9483-a847-4a39-9313-14bbb99e32c2",
   "metadata": {},
   "source": [
    "#### Sample application programm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "934a87d0-ca1e-46e5-8daf-2c760afbb281",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grünkohl\n",
      "---\n",
      "---\n",
      "runtime for nodes:  0.015625\n",
      "runtime for edges:  20.015625\n"
     ]
    }
   ],
   "source": [
    "#xx = createRefs4Coll  ('c:/Users/nlutt/Documents/Websites/ckCollections/recipes_xml/04 Grünkohl', \\\n",
    "#                         'C:/Users/nlutt/myPyPro/second/data/igt_cat.json')\n",
    "makeSampleSpace('C:/Users/nlutt/Documents/Websites/ckCollections/recipes_xml/04 Grünkohl', 'C:/Users/nlutt/Documents/Websites/graphLab', 'Grünkohl', 'C:/Users/nlutt/Documents/Websites/ckCollections/recipes_xml', 'any')\n",
    "HD_YO = CulinaryCollection('C:/Users/nlutt/Documents/Websites/graphLab/',\n",
    "                           'currentDescriptor Grünkohl.xml',\n",
    "                           'C:/Users/nlutt/myPyPro/second/data/igt_cat.json',\n",
    "                           'C:/Users/nlutt/myPyPro/second/data/')\n",
    "#print (HD_YO)\n",
    "#print (HD_YO.infoSubcolls())\n",
    "#print ('Anz. Rezepte: ', len(HD_YO.recipesList()))\n",
    "#print ('Anz. Rezepte in subcoll A: ', len(HD_YO.recipesList('A')))\n",
    "#print ('Anz. Rezepte in subcoll B: ', len(HD_YO.recipesList('B')))\n",
    "#print (HD_YO.recipesList())\n",
    "#print ('---')\n",
    "#print ('Anz. Zutaten: ', len(HD_YO.ingredientsList()))\n",
    "#print ('Anz. Zutaten in subcoll A: ', len(HD_YO.ingredientsList('A')))\n",
    "#print ('Anz. Zutaten in subcoll B: ', len(HD_YO.ingredientsList('B')))\n",
    "print ('---')\n",
    "#print ('Anz. Zutaten in class veg: ', len(HD_YO.catalogList('veg')))\n",
    "#print ('ei, brot in ingredients cat: ', HD_YO.catalogList(['ei','brot']))\n",
    "#sims = HD_YO.cosine_sim()\n",
    "#for k, v in sims.items():\n",
    "#    print(\"{:<8} {:<15}\".format(k, v))\n",
    "#print (f'Entropy A: {HD_YO.entropy().get(\"entropy_A\")}\\nEntropy B: {HD_YO.entropy().get(\"entropy_B\")}')\n",
    "#print (HD_YO.entropy())\n",
    "\n",
    "G = HD_YO.toGraph()\n",
    "#print ('G', G)\n",
    "#print ('---')\n",
    "\n",
    "#for e in G.edges(data=True):\n",
    "#    print (e)\n",
    "#print ('---')\n",
    "#HD_YO.toCSV  (G, 'C:/Users/nlutt/myPyPro/second/data/', 'HD_YO.csv')\n",
    "#HD_YO.toGEXF(G, 'C:/Users/nlutt/myPyPro/second/data/', 'HD_YO.gexf')\n",
    "\n",
    "#print (f\"node set A    : {len(HD_YO.nodeSets(G,'A'))}\")\n",
    "#print (f\"node set B    : {len(HD_YO.nodeSets(G,'B'))}\")\n",
    "#print (f\"node set AB   : {len(HD_YO.nodeSets(G, ['A','B']))}\")\n",
    "#print ('---')\n",
    "\n",
    "#print ('edge set A    :', len(HD_YO.edgeSets(G,'A')))\n",
    "#print ('edge set B    :', len(HD_YO.edgeSets(G,'B')))\n",
    "#print ('edge set B   :', len(HD_YO.edgeSets(G,['A','B']).get('B_edges')))\n",
    "#print ('edge set AB  :', len(HD_YO.edgeSets(G,['A','B']).get('AB_edges')))\n",
    "#print ('edge set AAB :', len(HD_YO.edgeSets(G,['A','B']).get('AAB_edges')))\n",
    "#print ('edge set BAB :', len(HD_YO.edgeSets(G,['A','B']).get('BAB_edges')))\n",
    "print ('---')\n",
    "#print ('Krack A: ', HD_YO.Krack(G, 'A').get('Krack_A'))\n",
    "#print ('Krack ingredients: ', HD_YO.Krack(G, ['ei','butter']))\n",
    "\n",
    "# SVG functions\n",
    "\n",
    "HD_YO.SVGMakerInit(G,'C:/Users/nlutt/myPyPro/second/data/')\n",
    "HD_YO.previewSVG(G,2)\n",
    "#rcp_list = HD_YO.sortByContrib2IG(HD_YO.recipesList('B'))\n",
    "#HD_YO.createSVGSequence(rcp_list,'C:/Users/nlutt/myPyPro/second/data/rcp_seq_YO')\n",
    "\n",
    "# Scraper functions\n",
    "\n",
    "#print (createRefs4Recipe ('C:/Users/nlutt/Documents/Websites/kochbuch/recipes_xml/07 Vegetarisch/', \\\n",
    "#                          'Mung Dal mit Spinat.xml','C:/Users/nlutt/myPyPro/second/data/igt_cat.json'))\n",
    "#xx = createRefs4Coll  ('c:/Users/nlutt/Documents/Websites/ckCollections/recipes_xml/04 Grünkohl', \\\n",
    "#                         'C:/Users/nlutt/myPyPro/second/data/igt_cat.json')\n",
    "#for x in xx:\n",
    "#    print (str(x.get('total')).rjust(5), str(x.get('success')).rjust(5), str(x.get('fail')).rjust(100), x.get('recipe name'))\n",
    "#scrapeCKbyKey ('c:/Users/nlutt/Documents/Websites/ckCollections/recipes_xml/04 Grünkohl', 'Grünkohl', 'C:/Users/nlutt/myPyPro/second/data/igt_cat.json')\n",
    "#scrapeCK ('C:/Users/nlutt/myPyPro/second/data/Grünkohl', \"https://www.chefkoch.de/rezepte/4201661676632120/Wan-Tan-mit-Gruenkohl-und-Kochwurst.html?ck_source=search-recipe&ck_element=recipe_search_list\", \"Wan-Tan-mit-Grünkohl-und-Kochwurst\", 'Grühnkohl')\n",
    "#synList = ['grünkohl']\n",
    "#scrapeCK ('C:/Users/nlutt/myPyPro/second/data/Grünkohl', \"https://www.chefkoch.de/rezepte/4201661676632120/Wan-Tan-mit-Gruenkohl-und-Kochwurst.html\", \"Wan-Tan-mit-Grünkohl-und-Kochwurst\", synList)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f6995a4",
   "metadata": {},
   "source": [
    "#### Playground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98dbfd52",
   "metadata": {},
   "outputs": [],
   "source": [
    "        self.nds = pd.DataFrame({ \n",
    "                        'sub'  : [att.get('sub') for i,att in graph.nodes(data=True)], \\\n",
    "                        'occ'  : [self.occ_dict.get(k) for k in graph.nodes()], \\\n",
    "                        'name' : [att.get('i-name') for i,att in graph.nodes(data=True)], \\\n",
    "                        'class': [self.cat.get('ingredients').get(k).get('i-class') for k in graph.nodes()], \\\n",
    "                        'cx_fd': [svg_in.find(f\".//svg:title[.='{k}']/../svg:ellipse\", ns).attrib['cx'] for k in graph.nodes()], \\\n",
    "                        'cy_fd': [svg_in.find(f\".//svg:title[.='{k}']/../svg:ellipse\", ns).attrib['cy'] for k in graph.nodes()], \\\n",
    "                        'rx_fd': [svg_in.find(f\".//svg:title[.='{k}']/../svg:ellipse\", ns).attrib['rx'] for k in graph.nodes()], \\\n",
    "                        'ry_fd': [svg_in.find(f\".//svg:title[.='{k}']/../svg:ellipse\", ns).attrib['ry'] for k in graph.nodes()], \\\n",
    "                        'txt_x': [svg_in.find(f\".//svg:title[.='{k}']/../svg:text\", ns).attrib['x'] for k in graph.nodes()], \\\n",
    "                        'txt_y': [svg_in.find(f\".//svg:title[.='{k}']/../svg:text\", ns).attrib['y'] for k in graph.nodes()]  \\\n",
    "                        }, \\\n",
    "                        index = graph.nodes() \\\n",
    "                        )\n",
    "        # edges\n",
    "        self.eds = pd.DataFrame({\n",
    "                        'start_id'    : [u for u,v,attr in graph.edges(data=True)], \\\n",
    "                        'end_id'      : [v for u,v,attr in graph.edges(data=True)], \\\n",
    "                        'sub'         : [attr.get('sub')    for u,v,attr in graph.edges(data=True)], \\\n",
    "                        'weight'      : [attr.get('weight') for u,v,attr in graph.edges(data=True)], \\\n",
    "                        'start_x_fd'  : [svg_in.find(f\".//svg:g[@id='{attr.get('id')}']/svg:path\", ns).attrib['d'].split(',')[0][1:]           for u,v,attr in graph.edges(data=True)], \\\n",
    "                        'start_y_fd'  : [svg_in.find(f\".//svg:g[@id='{attr.get('id')}']/svg:path\", ns).attrib['d'].split(',')[1].split('C')[0] for u,v,attr in graph.edges(data=True)], \\\n",
    "                        'end_x_fd'    : [svg_in.find(f\".//svg:g[@id='{attr.get('id')}']/svg:path\", ns).attrib['d'].split(' ')[2].split(',')[0] for u,v,attr in graph.edges(data=True)], \\\n",
    "                        'end_y_fd'    : [svg_in.find(f\".//svg:g[@id='{attr.get('id')}']/svg:path\", ns).attrib['d'].split(' ')[2].split(',')[1] for u,v,attr in graph.edges(data=True)], \\\n",
    "                        'start_x_node': [svg_in.find(f\".//svg:title[.='{u}']/../svg:ellipse\", ns).attrib['cx'] for u,v,attr in graph.edges(data=True)], \\\n",
    "                        'start_y_node': [svg_in.find(f\".//svg:title[.='{u}']/../svg:ellipse\", ns).attrib['cy'] for u,v,attr in graph.edges(data=True)], \\\n",
    "                        'end_x_node'  : [svg_in.find(f\".//svg:title[.='{v}']/../svg:ellipse\", ns).attrib['cx'] for u,v,attr in graph.edges(data=True)], \\\n",
    "                        'end_y_node'  : [svg_in.find(f\".//svg:title[.='{v}']/../svg:ellipse\", ns).attrib['cy'] for u,v,attr in graph.edges(data=True)]\n",
    "                        }, \\\n",
    "                        index = [attr.get('id') for u,v,attr in graph.edges(data=True)] \\\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c492d442",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.stack((np.array([att.get('sub') for i,att in graph.nodes(data=True)]),np.array([self.occ_dict.get(k) for k in graph.nodes()])),axis=1)\n",
    "print (arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e63ca9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "        # recipe graph edges\n",
    "        for u,v,att in G.edges(data=True):\n",
    "            ed_id       = att.get('id')\n",
    "            #print (ed_id)\n",
    "            edge_attr   = {'class':'edge', 'id':ed_id, 'style':'cursor: pointer;'}\n",
    "            edge        = ET.SubElement(rcp_g, 'g', attrib=edge_attr)\n",
    "            title       = ET.SubElement(edge,'title')\n",
    "            title.text  = ed_id\n",
    "            #pt          = svg_in.find (f\".//svg:title[.='{ed_id}']/../svg:path\", ns)\n",
    "            #pt_coor     = pt.get('d')\n",
    "            start_x      = eds.at[ed_id,'start_x_node']\n",
    "            start_y      = eds.at[ed_id,'start_y_node']\n",
    "            end_x        = eds.at[ed_id,'end_x_node']\n",
    "            end_y        = eds.at[ed_id,'end_y_node']\n",
    "            pt_coor      = f\"M{start_x},{start_y}L{end_x},{end_y}\"\n",
    "            xx = wgt_growing.get(ed_id)\n",
    "            if xx == 1:\n",
    "                path_attr   = {'fill':'none', 'stroke': 'black', 'd':pt_coor}\n",
    "            elif xx == 2: \n",
    "                path_attr   = {'fill':'none', 'stroke': 'black', 'stroke-width':'2', 'd':pt_coor}\n",
    "            elif xx > 2: \n",
    "                path_attr   = {'fill':'none', 'stroke': 'red', 'stroke-width':'2', 'd':pt_coor}\n",
    "            else: \n",
    "                path_attr   = {'fill':'none', 'stroke': 'black', 'd':pt_coor}\n",
    "            path        = ET.SubElement(edge,'path',path_attr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "087eca2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for swapping rows in Pandas dataframe\n",
    "        def swap_rows(df, i1, i2):\n",
    "            a, b = df.iloc[i1, :].copy(), df.iloc[i2, :].copy()\n",
    "            df.iloc[i1, :], df.iloc[i2, :] = b, a\n",
    "            return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8566666",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first: recipe with max number of ingredients\n",
    "        collection_df.sort_values(by='count_igt', inplace=True, ascending=False, ignore_index=True)\n",
    "\n",
    "        # init dataframe before sorting\n",
    "        collection_df['union'] = [set() for i in range(len(recipes))]\n",
    "        collection_df['union_len'] = 0\n",
    "        collection_df.at[0,'union'] = collection_df.at[0,'rcp_ingredients']\n",
    "        collection_df.at[0,'union_len'] = len(collection_df.at[0,'union'])\n",
    "\n",
    "        # sort dataframe by union length\n",
    "        for ix in range(1,len(recipes)):   \n",
    "            for ix2 in range (ix,len(recipes)):\n",
    "                coll = collection_df.at[ix2,'rcp_ingredients'].union(collection_df.at[ix-1,'union'])\n",
    "                collection_df.at[ix2,'union']     = coll\n",
    "                collection_df.at[ix2,'union_len'] = len(coll)\n",
    "            sort_sub(collection_df,ix,len(recipes),'union_len')\n",
    "        #print (collection_df)\n",
    "\n",
    "        # sort recipes\n",
    "        rcp_order      = list(collection_df['rcp_names'])\n",
    "        ixx            = list(range(0, len(recipes)))\n",
    "        ixx_dict       = dict(zip(rcp_order, ixx))\n",
    "        def rcp_sort (e):\n",
    "            return ixx_dict.get(e.get('recipeName'))\n",
    "        recipes_sorted = sorted(recipes, key=rcp_sort)\n",
    "        return recipes_sorted"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
