{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0780449b",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95b3f49d-c07e-4b2e-be55-2c51791f7e55",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [],
   "source": [
    "import io\n",
    "import os\n",
    "import sys\n",
    "import re\n",
    "import math\n",
    "from xml.etree import ElementTree as ET\n",
    "import urllib.parse\n",
    "from urllib.parse import urlsplit\n",
    "from urllib.request import pathname2url\n",
    "#import urllib.pathname2url\n",
    "import json\n",
    "import codecs\n",
    "import subprocess\n",
    "import networkx as nx\n",
    "from networkx.algorithms import bipartite\n",
    "#!{sys.executable} -m pip install pyarrow\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "from scipy.stats import entropy\n",
    "from collections import Counter\n",
    "import locale\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import uuid\n",
    "from time import *\n",
    "locale.setlocale(locale.LC_ALL, 'de-DE.utf-8')\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "993a8267-8ece-40e3-82e7-a82c555df554",
   "metadata": {},
   "source": [
    "#### fruschtique CulinaryCollection class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d4387baa-4242-4832-80fd-f22a2a452adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CulinaryCollection:\n",
    "    \n",
    "    def __init__(self, graphLab_path=None, descript_fn=None, igdtCat_path=None, working_dir=None):\n",
    "        \n",
    "        def subcoll_rcp (f_names):\n",
    "            rcp_list = []\n",
    "            for fn_rcp in f_names:\n",
    "                with open(fn_rcp, 'r', encoding='utf-8') as f:\n",
    "                    rcp_in = ET.parse(f)\n",
    "                    rcp_root = rcp_in.getroot()\n",
    "                    rcp_name = rcp_root.find('fr:recipeName', self.ns).text\n",
    "                    rcp_list.append(rcp_name)\n",
    "            return rcp_list\n",
    "        \n",
    "        # check for missing parameters\n",
    "        if graphLab_path == None:\n",
    "            print ('Specify path to graphLab.')\n",
    "            return None\n",
    "        if descript_fn == None:\n",
    "            print ('Specify descriptor filename.')\n",
    "            return None\n",
    "        if igdtCat_path == None:\n",
    "            print ('Specify path to ingredients catalogue.')\n",
    "            return None\n",
    "        if working_dir == None:\n",
    "            print ('Specify working directory.')\n",
    "            return None\n",
    "        \n",
    "        # set namespaces\n",
    "        self.ns = {'fr': 'http://fruschtique.de/ns/recipe', 'fe': 'http://fruschtique.de/ns/fe', 'ns0': 'http://fruschtique.de/ns/recipe'}\n",
    "        # set object variables\n",
    "        self.graphLab_path = graphLab_path\n",
    "        self.descript_fn   = descript_fn\n",
    "        self.igdtCat_path  = igdtCat_path\n",
    "        self.working_dir   = working_dir\n",
    "\n",
    "        # read descriptor file\n",
    "        descriptor = graphLab_path + descript_fn\n",
    "        with open(descriptor, 'r', encoding='utf-8') as d:\n",
    "            descript = ET.parse(d)\n",
    "            self.d_root = descript.getroot()\n",
    "            self.exp_name = self.d_root.find('fe:experimentName', self.ns).text\n",
    "\n",
    "        # read ingredients catalogue   \n",
    "        with open(igdtCat_path, encoding='utf-8') as file:\n",
    "            self.cat            = json.load(file)\n",
    "            self.catIngredients = self.cat.get('ingredients')\n",
    "            self.catClasses     = self.cat.get('classes')\n",
    "            self.noRefIgts      = self.cat.get('noRefIgts')\n",
    "        \n",
    "        # read list of recipes in collection\n",
    "        file_in = graphLab_path + self.d_root.find('fe:experimentPath', self.ns).text + 'catalogue.xml'\n",
    "        with open(file_in, 'r', encoding='utf-8') as f:\n",
    "            list_in = ET.parse(f)\n",
    "            root_in = list_in.getroot()\n",
    "        self.in_files = [urllib.parse.unquote(doc.get(\"href\")[8:], encoding=\"utf-8\") for doc in root_in.findall('doc')]\n",
    "\n",
    "        # check for subcollection directories\n",
    "        common = os.path.commonpath(self.in_files)\n",
    "        os.chdir (common)\n",
    "        sub_paths = [p for p in os.listdir() if os.path.isdir(p)]\n",
    "        if len(sub_paths) == 2:\n",
    "            self.subCollLtrs = sub_paths\n",
    "        elif len(sub_paths) == 1 or len(sub_paths) > 2:\n",
    "            print ('Wrong number of subcollection dir_paths.')\n",
    "            return None\n",
    "        elif len(sub_paths) == 0:\n",
    "            self.subCollLtrs = []\n",
    "            \n",
    "        # check for subcollections\n",
    "        if self.d_root.find('fe:A-collection', self.ns) != None and self.d_root.find('fe:B-collection', self.ns) != None:\n",
    "            self.collType = 'double'\n",
    "            coll_A = self.d_root.find('fe:A-collection', self.ns)\n",
    "            author_A = coll_A.find('fe:A-author', self.ns).text\n",
    "            collName_A = coll_A.find('fe:A-name', self.ns).text\n",
    "            if self.subCollLtrs[0] != None:\n",
    "                collDir_A = self.subCollLtrs[0]\n",
    "            else:\n",
    "                print ('No directory for subcollection A.')\n",
    "                return None\n",
    "            coll_B = self.d_root.find('fe:B-collection', self.ns)\n",
    "            author_B = coll_B.find('fe:B-author', self.ns).text\n",
    "            collName_B = coll_B.find('fe:B-name', self.ns).text\n",
    "            if self.subCollLtrs[1] != None:\n",
    "                collDir_B = self.subCollLtrs[1]\n",
    "            else:\n",
    "                print ('No directory for subcollection B.')\n",
    "                return None\n",
    "        else:\n",
    "            self.collType = 'single'\n",
    "        \n",
    "        # get metadata from descriptor\n",
    "        title = self.d_root.find('fe:fullTitle', self.ns).text\n",
    "        # collect recipe names and related ingredients\n",
    "        self.full_rcp_list = []\n",
    "        for fn_rcp in self.in_files:\n",
    "            with open(fn_rcp, 'r', encoding='utf-8') as f:\n",
    "                rcp_in = ET.parse(f)\n",
    "                rcp_root = rcp_in.getroot()\n",
    "                rcp_name = rcp_root.find('fr:recipeName', self.ns).text\n",
    "                igdts = []\n",
    "                igdts_elem = rcp_root.findall('.//fr:igdtName',self.ns)\n",
    "                xx = [(igt.get(\"ref\"),igt.text.lower()) for igt in igdts_elem]\n",
    "                for (ref, igt_name) in xx:\n",
    "                    if ref == None:\n",
    "                        raise Exception(f\"Missing reference to ingredients catalogue for {igt_name.upper()} in recipe {rcp_name.upper()}\")\n",
    "                        return\n",
    "                    elif ref == '':\n",
    "                        found = False\n",
    "                        for noRef in self.noRefIgts:\n",
    "                            if noRef in igt_name:\n",
    "                                found = True\n",
    "                                break\n",
    "                        if found == False: \n",
    "                            raise Exception(f\"Null reference to ingredients catalogue for {igt_name.upper()} in recipe {rcp_name.upper()}\")\n",
    "                            return\n",
    "                    else:\n",
    "                        igdts.append(ref) \n",
    "                igdts = list(set(igdts))                                \n",
    "                rcp = {'recipeName' : rcp_name, 'ingredients' : igdts}\n",
    "                self.full_rcp_list.append(rcp)\n",
    "                    \n",
    "        # get subcollection files and prepare collection entry for coll_data.json\n",
    "        meta = dict(title=title,collType=self.collType)\n",
    "        if self.collType == 'double':\n",
    "            f_names_A = [fn for fn in self.in_files if os.path.basename(os.path.dirname(fn)) == self.subCollLtrs[0]]\n",
    "            f_names_B = [fn for fn in self.in_files if os.path.basename(os.path.dirname(fn)) == self.subCollLtrs[1]]        \n",
    "            # create recipe and subcollection lists\n",
    "            sub_coll_rcp_A = subcoll_rcp (f_names_A)\n",
    "            sub_coll_rcp_B = subcoll_rcp (f_names_B)       \n",
    "            rcp_dict = {'meta':meta, 'collections':{sub_paths[0]:{'name':collName_A, 'author':author_A,'recipes':sub_coll_rcp_A}, \\\n",
    "                                                    sub_paths[1]:{'name':collName_B, 'author':author_B,'recipes':sub_coll_rcp_B}}, \\\n",
    "                                                    'recipes': self.full_rcp_list}    \n",
    "        elif self.collType == 'single':\n",
    "            rcp_dict = dict(meta=meta, recipes=self.full_rcp_list)\n",
    "        else:\n",
    "            print ('Unknown error.')\n",
    "            return\n",
    "        \n",
    "        # write rcp_dict to json\n",
    "        outfile = f\"{os.path.join(self.working_dir,self.exp_name)} coll data.json\"\n",
    "        with open(outfile, 'w', encoding ='utf8') as f:\n",
    "            json.dump(rcp_dict, f, ensure_ascii=False)\n",
    "            \n",
    "        # read coll_data.json  \n",
    "        with open(outfile, 'r', encoding='utf-8') as file:\n",
    "            self.coll = json.load(file) \n",
    "        self.recipes     = [rcp for rcp in self.coll.get('recipes')]\n",
    "        self.ingredients = list(set(igt for rcp in self.recipes for igt in rcp.get('ingredients')))\n",
    "        \n",
    "        #create the inverted index as dict\n",
    "        self.index = dict()\n",
    "        for igt in self.catIngredients.items():\n",
    "            x = dict()\n",
    "            k = igt[0]\n",
    "            x = {k:k}\n",
    "            self.index.update(x)\n",
    "            y = dict()\n",
    "            for syn in igt[1].get('synonyms'):\n",
    "                y = {syn:k}\n",
    "                self.index.update(y)     \n",
    "        return\n",
    "            \n",
    "    def __str__(self):\n",
    "        exp = f\"Experiment name: {self.exp_name}\"\n",
    "        if self.collType == 'single':\n",
    "            print_str = f\"{exp}\\nCollection with {len(self.recipes)} recipes with {len(self.ingredients)} distinct ingredients\\nsupported by an ingredients catalog with {len(self.catIngredients)} entries in {len(self.catClasses)} classes\\n\"\n",
    "        elif self.collType == 'double':\n",
    "            print_str = f\"{exp}\\nCollection with {len(self.recipes)} recipes in {len(self.subCollLtrs)} subcollections with {len(self.ingredients)} distinct ingredients\\nsupported by an ingredients catalog with {len(self.catIngredients)} entries in {len(self.catClasses)} classes\\n\"\n",
    "        else:\n",
    "            print ('Unknown error.')\n",
    "            return None\n",
    "        return print_str\n",
    "    \n",
    "    def listSubcolls (self):\n",
    "        if self.collType == 'double':\n",
    "            xx = [{'letter':k, 'name':self.coll.get('collections').get(k,v).get('name'), \\\n",
    "                    'author':self.coll.get('collections').get(k,v).get('author'), \\\n",
    "                    'rcpCount':len(self.listRecipes(k)), \\\n",
    "                    'igtCount':len(self.listIngredients(k)) \\\n",
    "                    } \\\n",
    "                    for (k,v) in self.coll.get('collections').items()]\n",
    "            return xx\n",
    "        else:\n",
    "            print ('No subcollections in this collection.')\n",
    "            return None\n",
    "        \n",
    "    def listRecipes (self,coll=None):\n",
    "        if (self.collType == 'single') and (coll==None):\n",
    "            return self.recipes\n",
    "        elif (self.collType == 'double') and (coll in self.subCollLtrs):\n",
    "            return self.coll.get('collections').get(coll).get('recipes')\n",
    "        else:\n",
    "            return []\n",
    "        \n",
    "    def listIngredients (self,coll=None):\n",
    "        if (self.collType == 'single') and (coll==None):\n",
    "            return self.ingredients\n",
    "        elif self.collType == 'double' and coll in self.subCollLtrs:\n",
    "            xx = [rcp for rcp in self.coll.get('collections').get(coll).get('recipes')]\n",
    "            yy = [igt for rcp in self.coll.get(\"recipes\") if rcp.get('recipeName') in xx for igt in rcp.get('ingredients')]\n",
    "            zz = list(set(yy))\n",
    "            zz.sort(key=locale.strxfrm)\n",
    "            return zz\n",
    "        else:\n",
    "            return []\n",
    "                \n",
    "    def listIngredientsCatalog (self, select=None):\n",
    "        xx = list (self.catClasses.keys())\n",
    "        if select == None:\n",
    "            return [igt for igt in self.cat]\n",
    "        elif type(select) is str and select in xx:\n",
    "            return [igt for igt in self.cat.get('ingredients') if self.cat.get('ingredients').get(igt).get('i-class') == select]\n",
    "        elif type(select) is list:\n",
    "            return [self.catIngredients.get(s) for s in select]\n",
    "        \n",
    "    def cosine_sim (self):\n",
    "\n",
    "        def co_sim (a,b):\n",
    "            return dot(a, b)/(norm(a)*norm(b))\n",
    "        \n",
    "        def vec (occ_d=None):\n",
    "            d = {}\n",
    "            for i in self.ingredients:\n",
    "                d[i] = 0\n",
    "            for k,v in occ_d.items():\n",
    "                d[k] = v        \n",
    "            vector = dict(sorted(d.items()))\n",
    "            return list(vector.values())\n",
    "        \n",
    "        if self.collType != 'double':\n",
    "            print (\"Cosine similarity computation available only for collections with two subcollections.\")\n",
    "            return None\n",
    "        rcp_A  = self.listRecipes(self.subCollLtrs[0])\n",
    "        rcp_B  = self.listRecipes(self.subCollLtrs[1])\n",
    "        occ_dict_A = Counter([igt for rcp in self.recipes if rcp.get('recipeName') in rcp_A for igt in rcp.get('ingredients')])\n",
    "        occ_dict_B = Counter([igt for rcp in self.recipes if rcp.get('recipeName') in rcp_B for igt in rcp.get('ingredients')])\n",
    "        vec_A     = vec(occ_dict_A)\n",
    "        vec_B     = vec(occ_dict_B)\n",
    "        sim_total = co_sim(vec_A, vec_B)\n",
    "        res = {'total':sim_total}\n",
    "        for c in list(self.catClasses.keys()):\n",
    "            occ_dict_A_class = Counter([igt for rcp in self.coll.get(\"recipes\") if rcp.get('recipeName') in rcp_A for igt in rcp.get('ingredients') if self.catIngredients.get(igt).get('i-class') == c])\n",
    "            if sum(occ_dict_A_class.values()) != 0:\n",
    "                occ_dict_B_class = Counter([igt for rcp in self.coll.get(\"recipes\") if rcp.get('recipeName') in rcp_B for igt in rcp.get('ingredients') if self.catIngredients.get(igt).get('i-class') == c])\n",
    "                if sum(occ_dict_B_class.values()) != 0:\n",
    "                    vec_A_class = vec(occ_dict_A_class)\n",
    "                    vec_B_class = vec(occ_dict_B_class)\n",
    "                    sim_class   = co_sim(vec_A_class, vec_B_class)\n",
    "                    res.update({c:sim_class}) \n",
    "        return res\n",
    "    \n",
    "    def entropy(self):\n",
    "        if self.collType == 'single':\n",
    "            p = list(Counter([igt for rcp in self.coll.get(\"recipes\") for igt in rcp.get('ingredients')]).values())\n",
    "            return {'entropy':entropy(p, base=2)}\n",
    "        elif self.collType == 'double':\n",
    "            rcp_A  = self.listRecipes(self.subCollLtrs[0])\n",
    "            rcp_B  = self.listRecipes(self.subCollLtrs[1])\n",
    "            p_A = list(Counter([igt for rcp in self.coll.get(\"recipes\") if rcp.get('recipeName') in rcp_A for igt in rcp.get('ingredients')]).values())\n",
    "            p_B = list(Counter([igt for rcp in self.coll.get(\"recipes\") if rcp.get('recipeName') in rcp_B for igt in rcp.get('ingredients')]).values())\n",
    "            return {'entropy_A':entropy(p_A, base=2), 'entropy_B':entropy(p_B, base=2)}\n",
    "        else:\n",
    "            print ('Unknown error.')\n",
    "            return None\n",
    "        \n",
    "    def toGraph (self, coll=None):\n",
    "        \n",
    "        def igtGraph (i2r):\n",
    "            B = nx.Graph(from_coll=coll,created_by='fruschtique CulinaryCollection')\n",
    "            X = nx.Graph(from_coll=coll,created_by='fruschtique CulinaryCollection')\n",
    "            top = [rcp.get('recipeName') for rcp in i2r]\n",
    "            bottom = list(set([igt for rcp in i2r for igt in rcp.get('ingredients')]))\n",
    "            e_list = []\n",
    "            for rcp in i2r:\n",
    "                name = rcp.get('recipeName')\n",
    "                for igt in rcp.get('ingredients'):\n",
    "                    e_list.append((name,igt))\n",
    "            B.add_nodes_from(top, bipartite=0)\n",
    "            B.add_nodes_from(bottom, bipartite=1)\n",
    "            B.add_edges_from(e_list)\n",
    "            X = bipartite.weighted_projected_graph(B, bottom)\n",
    "            attr_dict = {igt: {'i-name':self.catIngredients[igt].get('i-name'),'i-class':self.catIngredients[igt].get('i-class')} for igt in bottom}\n",
    "            occ_list = [igt for rcp in i2r for igt in rcp.get('ingredients')]\n",
    "            self.occ_dict = Counter(occ_list)\n",
    "            occ_attr = {k:{'occ':self.occ_dict.get(k)} for k in self.occ_dict.keys()}\n",
    "            nx.set_node_attributes(X, attr_dict)\n",
    "            nx.set_node_attributes(X, occ_attr)\n",
    "            e_attr = {}\n",
    "            for e in list(X.edges(data=True)):\n",
    "                x = [e[0],e[1]]\n",
    "                x.sort(key=locale.strxfrm)\n",
    "                id = str(x[0]) + '--' + str(x[1])\n",
    "                xx = (e[0],e[1])\n",
    "                e_attr[xx] = {'id':id}\n",
    "            nx.set_edge_attributes(X, e_attr)\n",
    "            return X\n",
    "        \n",
    "        # create graph for collection with no subcollections\n",
    "        if self.collType == 'single':\n",
    "            if type(coll) != None:\n",
    "                print('Misplaced subcollection specification. Aborted.')\n",
    "                return None\n",
    "            else:\n",
    "                i2r = [rcp for rcp in self.coll.get('recipes')]\n",
    "                G1 = igtGraph(i2r)\n",
    "                # add sub attribute to nodes\n",
    "                sub_dict = {nd:{'sub':'A'} for nd in list(G1.nodes())}\n",
    "                nx.set_node_attributes(G1,sub_dict)\n",
    "                # add sub attribute to edges \n",
    "                sub_dict = {ed:{'sub':'A'} for ed in list(G1.edges())}\n",
    "                nx.set_edge_attributes(G1,sub_dict)\n",
    "                return G1\n",
    "        # create graph for collection with subcollections\n",
    "        elif self.collType == 'double':\n",
    "            if type(coll) is str:\n",
    "                if len(coll) != 1:\n",
    "                    print('Use a single character for subcollection specification.')\n",
    "                else:\n",
    "                    # create graph from single subcollection\n",
    "                    xx = [rcp for rcp in self.coll.get('collections').get(coll).get('recipes')]\n",
    "                    i2r = [rcp for rcp in self.coll.get(\"recipes\") if rcp.get('recipeName') in xx]\n",
    "                    G1 = igtGraph(i2r)\n",
    "                    # add sub attribute to nodes\n",
    "                    sub_dict = {nd:{'sub':coll} for nd in list(G1.nodes())}\n",
    "                    nx.set_node_attributes(G1,sub_dict)\n",
    "                    # add sub attribute to edges \n",
    "                    sub_dict = {ed:{'sub':coll} for ed in list(G1.edges())}\n",
    "                    nx.set_edge_attributes(G1,sub_dict)\n",
    "                    return G1\n",
    "            elif type(coll) is list:\n",
    "                if len(coll) > 2:\n",
    "                    print('Two subcollections is maximum for graph creation.')\n",
    "                    return None\n",
    "                elif not(coll[0] in self.subCollLtrs):\n",
    "                    print (f\"The subcollection {coll[0]} is not contained in this collection.\")\n",
    "                    return None\n",
    "                elif not(coll[1] in self.subCollLtrs):\n",
    "                    print (f\"The subcollection {coll[1]} is not contained in this collection.\")\n",
    "                    return None\n",
    "                else:\n",
    "                    i2r = [rcp for rcp in self.coll.get(\"recipes\")]\n",
    "                    GG = igtGraph(i2r)\n",
    "                    Aingredients = set(self.listIngredients('A'))\n",
    "                    Bingredients = set(self.listIngredients('B'))\n",
    "                    ABingredients = Aingredients.intersection(Bingredients)\n",
    "                    Aingredients_pure = Aingredients.difference(ABingredients)\n",
    "                    Bingredients_pure = Bingredients.difference(ABingredients)\n",
    "                    Asub_dict = {igt: {'sub':'A'} for igt in Aingredients_pure}\n",
    "                    Bsub_dict = {igt: {'sub':'B'} for igt in Bingredients_pure}\n",
    "                    ABsub_dict = {igt: {'sub':'AB'} for igt in ABingredients}\n",
    "                    sub_dict = {**Asub_dict, **Bsub_dict, **ABsub_dict}\n",
    "                    nx.set_node_attributes(GG, sub_dict)\n",
    "                    A_attr   = {(e[0],e[1]):{'sub': 'A'}   for e in list(GG.edges(data=True)) if (e[0] in Aingredients_pure and e[1] in Aingredients_pure)}\n",
    "                    AAB_attr = {(e[0],e[1]):{'sub': 'AAB'} for e in list(GG.edges(data=True)) if (e[0] in Aingredients_pure and e[1] in ABingredients) or (e[0] in ABingredients and e[1] in Aingredients_pure)}\n",
    "                    B_attr   = {(e[0],e[1]):{'sub': 'B'}   for e in list(GG.edges(data=True)) if (e[0] in Bingredients_pure and e[1] in Bingredients_pure)}\n",
    "                    BAB_attr = {(e[0],e[1]):{'sub': 'BAB'} for e in list(GG.edges(data=True)) if (e[0] in Bingredients_pure and e[1] in ABingredients) or (e[0] in ABingredients and e[1] in Bingredients_pure)}\n",
    "                    AB_attr  = {(e[0],e[1]):{'sub': 'AB'}  for e in list(GG.edges(data=True)) if e[0] in ABingredients and e[1] in ABingredients}\n",
    "                    e_attr = {**A_attr,**AAB_attr,**B_attr,**BAB_attr,**AB_attr}\n",
    "                    nx.set_edge_attributes(GG, e_attr)\n",
    "                    return GG        \n",
    "        else:\n",
    "            print ('Unknown error.')\n",
    "        \n",
    "    def nodeSets(self,graph=None,coll=None):\n",
    "        if graph == None:\n",
    "            print ('Specify graph.')\n",
    "            return None\n",
    "        elif coll == None:\n",
    "            return graph.nodes(data=True)\n",
    "        elif type(coll) is str:\n",
    "            if len(coll) != 1:\n",
    "                print('Use a single character for subcollection specification.')\n",
    "                return None\n",
    "            elif not(coll in self.subCollLtrs):\n",
    "                print(f\"Subcollection {coll} does not exist.\")\n",
    "                return None\n",
    "            else:\n",
    "                self.A_nodes = set ([n for n,attr in graph.nodes(data=True) if attr.get('sub') == coll])\n",
    "                return list(self.A_nodes)\n",
    "        elif type(coll) is list:\n",
    "            if len(coll) > 2:\n",
    "                print('Two subcollections is maximum for node set generation.')\n",
    "                return None\n",
    "            elif not(coll[0] in self.subCollLtrs):\n",
    "                print (f\"The subcollection {coll[0]} is not contained in this collection.\")\n",
    "                return None\n",
    "            elif not(coll[1] in self.subCollLtrs):\n",
    "                print (f\"The subcollection {coll[1]} is not contained in this collection.\")\n",
    "                return None\n",
    "            else:\n",
    "                xx = f\"{coll[0]}{coll[1]}\"\n",
    "                self.AB_nodes = [n for (n,attr) in graph.nodes(data=True) if attr.get('sub') == xx]\n",
    "                return self.AB_nodes\n",
    "        else:\n",
    "            return None\n",
    "    \n",
    "    def edgeSets(self,graph=None,coll=None):         \n",
    "        if graph == None:\n",
    "            print ('Specify graph.')\n",
    "            return None\n",
    "        elif coll == None:\n",
    "            return graph.edges(data=True)\n",
    "        if type(coll) is str:\n",
    "            if len(coll) != 1:\n",
    "                print('Use a single character for subcollection specification.')\n",
    "                return None\n",
    "            elif not(coll in self.subCollLtrs):\n",
    "                print(f\"Subcollection {coll} does not exist.\")\n",
    "                return None\n",
    "            else:\n",
    "                n_A  = [n for n,attr in graph.nodes(data=True) if attr.get('sub') == coll]\n",
    "                A_e_pure  = [e for e in graph.edges(data=True) if e[0] in n_A and e[1] in n_A]\n",
    "                return A_e_pure  \n",
    "        elif type(coll) is list:\n",
    "            if len(coll) > 2:\n",
    "                print('Two subcollections is maximum for edge set generation.')\n",
    "                return None\n",
    "            elif not(coll[0] in self.subCollLtrs):\n",
    "                print (f\"The subcollection {coll[0]} is not contained in this collection.\")\n",
    "                return None\n",
    "            elif not(coll[1] in self.subCollLtrs):\n",
    "                print (f\"The subcollection {coll[1]} is not contained in this collection.\")\n",
    "                return None\n",
    "            else:\n",
    "                n_A  = [n for n,attr in graph.nodes(data=True) if attr.get('sub') == coll[0]]\n",
    "                n_B  = [n for n,attr in graph.nodes(data=True) if attr.get('sub') == coll[1]]\n",
    "                n_AB = [n for n,attr in graph.nodes(data=True) if attr.get('sub') == f\"{coll[0]}{coll[1]}\"]\n",
    "                A_edges        = [e for e in graph.edges(data=True) if e[0] in n_A and e[1] in n_A]\n",
    "                B_edges        = [e for e in graph.edges(data=True) if e[0] in n_B and e[1] in n_B]\n",
    "                AAB_edges      = [e for e in graph.edges(data=True) if (e[0] in n_A and e[1] in n_AB) or (e[1] in n_A and e[0] in n_AB)]\n",
    "                BAB_edges      = [e for e in graph.edges(data=True) if (e[0] in n_B and e[1] in n_AB) or (e[1] in n_B and e[0] in n_AB)]\n",
    "                AB_edges = [e for e in graph.edges(data=True) if e[0] in n_AB and e[1] in n_AB]\n",
    "                return {'A_edges' : A_edges, 'B_edges' : B_edges, 'AAB_edges' : AAB_edges, 'BAB_edges' : BAB_edges, 'AB_edges' : AB_edges}\n",
    "        else:\n",
    "            return None\n",
    "    \n",
    "    def Krack(self,graph=None):\n",
    "\n",
    "        def Krack (EL,IL):\n",
    "            return (EL-IL)/(EL+IL)\n",
    "        \n",
    "        # parameter checking\n",
    "        if self.collType != 'double':\n",
    "            print ('Krackhardt index computation available only for collections with subcollections.')\n",
    "            return\n",
    "        elif graph == None:\n",
    "            print ('Missing graph specification.')\n",
    "            return\n",
    "        else:\n",
    "            nodes_A = self.listIngredients('A')\n",
    "            nodes_B = self.listIngredients('B')\n",
    "            IL_A    = len([attr.get(\"id\") for n1,n2,attr in graph.edges(data=True) \\\n",
    "                if (n1 in nodes_A) and (n2 in nodes_A)])\n",
    "            EL_A    = len([attr.get(\"id\") for n1,n2,attr in graph.edges(data=True) \\\n",
    "                if ((n1 in nodes_A) and not(n2 in nodes_A)) or ((not(n1 in nodes_A)) and (n2 in nodes_A))])\n",
    "            IL_B    = len([attr.get(\"id\") for n1,n2,attr in graph.edges(data=True) \\\n",
    "                if (n1 in nodes_B) and (n2 in nodes_B)])\n",
    "            EL_B    = len([attr.get(\"id\") for n1,n2,attr in graph.edges(data=True) \\\n",
    "                if ((n1 in nodes_B) and not(n2 in nodes_B)) or ((not(n1 in nodes_B)) and (n2 in nodes_B))])              \n",
    "            #print ('IL_A: ',IL_A)\n",
    "            #print ('EL_A: ',EL_A)\n",
    "            #print ('IL_B: ',IL_B)\n",
    "            #print ('EL_B: ',EL_B)\n",
    "            return {'Krack_A' : Krack(EL_A,IL_A), 'Krack_B' : Krack(EL_B,IL_B)}\n",
    "        \n",
    "    def graphToDot(self,graph=None):\n",
    "        if graph == None:\n",
    "            print ('Missing graph specification.')\n",
    "            return\n",
    "        dot = 'graph {\\ngraph[rankdir=\"LR\", outputorder=\"edgesfirst\"]\\nnode[fontname=\"Arial\", fontsize=120, shape=circle, style=filled, fixedsize=shape];\\n'\n",
    "        for u,v,att in graph.edges(data=True):\n",
    "            x = [u,v]\n",
    "            x.sort(key=locale.strxfrm)\n",
    "            u = x[0]\n",
    "            v = x[1]\n",
    "            dot += u+' -- '+v+' [penwidth='+str(att.get('weight'))\n",
    "            dot += ', id='+'\"'+u+\"--\"+v+'\"'\n",
    "            if att.get('weight') > 1:\n",
    "                dot += ', color=Red]\\n'\n",
    "            else:\n",
    "                dot += ']\\n'\n",
    "        for u,att in graph.nodes(data=True):\n",
    "            dot += u+' [width=' + str(1+3*math.sqrt(att.get('occ'))) + ', label=' + str(att.get('i-name')) + ', class=' + str(att.get('i-class')) + ']\\n'\n",
    "        dot += '}'\n",
    "        outfile = f\"{os.path.join(self.working_dir,self.exp_name)}.dot\"\n",
    "        with codecs.open(outfile, 'w', encoding = 'utf8') as file:\n",
    "            file.write(dot)\n",
    "        return\n",
    "    \n",
    "    def graphToGEXF(self,graph=None): \n",
    "        if graph == None:\n",
    "            print ('Missing graph specification.')\n",
    "            return\n",
    "        ns = {\"gr\": \"http://www.gexf.net/1.2draft\"}\n",
    "        root = ET.Element('gr:gexf', attrib={\"xmlns:gr\":\"http://www.gexf.net/1.2\", \"xmlns:viz\":\"http://www.gexf.net/1.2/viz\", \\\n",
    "        \"xmlns:xsi\":\"http://www.w3.org/2001/XMLSchema-instance\", \"xsi:schemaLocation\":\"http://www.gexf.net/1.2 https://gexf.net/1.2/gexf.xsd\", \\\n",
    "        \"version\":\"1.2\"})\n",
    "        meta = ET.SubElement(root,\"gr:meta\",attrib={\"lastmodifieddate\":\"2023-09-15\"})\n",
    "        creator = ET.SubElement(meta, \"gr:creator\")\n",
    "        creator.text = \"Norbert Luttenberger\"\n",
    "        description = ET.SubElement(meta, \"gr:description\")\n",
    "        description.text = \"fruschtique Ingredient Graph in gexf notation\"\n",
    "        g_graph = ET.SubElement(root,\"gr:graph\",attrib={\"defaultedgetype\":\"undirected\"})\n",
    "        attributes = ET.SubElement(g_graph, \"gr:attributes\", attrib={\"class\":\"node\"})\n",
    "        attribute_0 = ET.SubElement(attributes, \"gr:attribute\", attrib={\"id\":\"0\",\"title\":\"occ\",\"type\":\"float\"})\n",
    "        attribute_1 = ET.SubElement(attributes, \"gr:attribute\", attrib={\"id\":\"1\",\"title\":\"i-class\",\"type\":\"string\"})        \n",
    "        nodes = ET.SubElement(g_graph, \"gr:nodes\") \n",
    "        for n,attr in graph.nodes(data=True):\n",
    "            node = ET.SubElement(nodes, \"gr:node\", attrib={\"id\":n, \"label\":self.catIngredients.get(n).get(\"i-name\")})\n",
    "            att_values = ET.SubElement(node,\"gr:attvalues\")\n",
    "            att_value  = ET.SubElement(att_values,\"gr:attvalue\", attrib={\"for\":\"0\",\"value\":str(attr.get(\"occ\"))})\n",
    "            att_value  = ET.SubElement(att_values,\"gr:attvalue\", attrib={\"for\":\"1\",\"value\":str(attr.get(\"i-class\"))})\n",
    "        edges = ET.SubElement(g_graph, \"gr:edges\")\n",
    "        for n1,n2,attr in graph.edges(data=True):\n",
    "            edge = ET.SubElement(edges, \"gr:edge\", attrib={\"id\":attr.get(\"id\"), \"source\":n1, \"target\":n2, \"weight\":str(attr.get(\"weight\"))})\n",
    "        tree = ET.ElementTree(root)\n",
    "        ET.indent(tree)\n",
    "        outfile = f\"{os.path.join(self.working_dir,self.exp_name)}.gexf\"\n",
    "        tree.write(outfile, encoding='UTF-8', xml_declaration='<?xml version=\"1.0\" encoding=\"UTF-8\"?>')\n",
    "        return\n",
    "    \n",
    "    def graphToCSV(self,graph=None):\n",
    "        if graph == None:\n",
    "            print ('Missing graph specification.')\n",
    "            return\n",
    "        outfile = f\"{os.path.join(self.working_dir,self.exp_name)} nodes.csv\"\n",
    "        with codecs.open(outfile, 'w', encoding = 'utf8') as file:\n",
    "            file.write('n,i-name,i-class,occ,sub\\n')\n",
    "            for (n,attr) in graph.nodes(data=True):\n",
    "                file.write(f\"{n},{attr.get('i-name')},{attr.get('i-class')},{attr.get('occ')},{attr.get('sub')}\\n\")\n",
    "        # get edges dict\n",
    "        outfile = f\"{os.path.join(self.working_dir,self.exp_name)} edges.csv\"\n",
    "        if self.collType == 'single':\n",
    "            with codecs.open(outfile, 'w', encoding = 'utf8') as file:\n",
    "                file.write('id,n1,n2,weight,sub\\n')\n",
    "                [file.write(f\"{attr.get('id')},{n1},{n2},{attr.get('weight')},{attr.get('sub')}\\n\") \\\n",
    "                    for n1,n2,attr in (graph.edges(data=True))]\n",
    "            return\n",
    "        else:\n",
    "            A_nodes  = self.nodeSets(graph,self.subCollLtrs[0])\n",
    "            #print (len(A_nodes))\n",
    "            B_nodes  = self.nodeSets(graph,self.subCollLtrs[1])\n",
    "            #print (len(B_nodes))\n",
    "            AB_nodes = self.nodeSets(graph,[self.subCollLtrs[0],self.subCollLtrs[1]])\n",
    "            #print ('len AB', len(AB_nodes))\n",
    "            with codecs.open(outfile, 'w', encoding = 'utf8') as file:\n",
    "                file.write('id,n1,n2,weight,sub\\n')\n",
    "                [file.write(f\"{attr.get('id')},{n1},{n2},{attr.get('weight')},A\\n\") \\\n",
    "                    for n1,n2,attr in (graph.edges(data=True)) \\\n",
    "                    if (n1 in A_nodes) and (n2 in A_nodes)]\n",
    "                [file.write(f\"{attr.get('id')},{n1},{n2},{attr.get('weight')},B\\n\") \\\n",
    "                    for n1,n2,attr in (graph.edges(data=True)) \\\n",
    "                    if (n1 in B_nodes) and (n2 in B_nodes)]\n",
    "                [file.write(f\"{attr.get('id')},{n1},{n2},{attr.get('weight')},AB\\n\") \\\n",
    "                    for n1,n2,attr in (graph.edges(data=True)) \\\n",
    "                    if (n1 in AB_nodes) and (n2 in AB_nodes)]\n",
    "                [file.write(f\"{attr.get('id')},{n1},{n2},{attr.get('weight')},AAB\\n\") \\\n",
    "                    for n1,n2,attr in (graph.edges(data=True)) \\\n",
    "                    if ((n1 in A_nodes) and (n2 in AB_nodes)) or ((n1 in AB_nodes) and (n2 in A_nodes))]\n",
    "                [file.write(f\"{attr.get('id')},{n1},{n2},{attr.get('weight')},BAB\\n\") \\\n",
    "                    for n1,n2,attr in (graph.edges(data=True)) \\\n",
    "                    if ((n1 in B_nodes) and (n2 in AB_nodes)) or ((n1 in AB_nodes) and (n2 in B_nodes))]\n",
    "            return\n",
    "    \n",
    "    def SVGMakerInit(self,graph=None):\n",
    "        \"\"\"Initialize the SVG Maker of the fruschtique Culinary Collection Class.\n",
    "        Steps as follows:\n",
    "        1 -- Create dot file for collection from graph.\n",
    "        2 -- Call sfdp subprocess and create svg file for collection. \n",
    "        3 -- Create pandas representation for graph nodes and edges.\n",
    "        \"\"\"\n",
    "\n",
    "        # 1 -- dot file\n",
    "        infile  = f\"{os.path.join(self.working_dir,self.exp_name)}.dot\"\n",
    "        if not(os.path.isfile(infile)):\n",
    "            self.graphToDot(graph)\n",
    "\n",
    "        # 2 -- svg file\n",
    "        outfile = f\"{os.path.join(self.working_dir,self.exp_name)} poor graph.svg\"\n",
    "        if not(os.path.isfile(outfile)):\n",
    "            subprocess.run (['sfdp', infile, '-o', outfile, '-Goverlap=prism', '-Tsvg'])\n",
    "\n",
    "        # 3 -- pandas representation\n",
    "        # columns for nodes:\n",
    "        #   id               ingredient/node id\n",
    "        #   sub              subcollection indicator (A, B, AB, or None)\n",
    "        #   occ              ingredient occurrence in collection\n",
    "        #   class            ingrendient class\n",
    "        #   cx_fd            x coordinate for node center, fd stands for force-directed layout\n",
    "        #   cy_fd            y coordinate for node center, fd stands for force-directed layout\n",
    "        #   rx_fd            x radius, fd stands for force-directed layout\n",
    "        #   ry_fd            y radius, fd stands for force-directed layout\n",
    "        # columns for edges:\n",
    "        #   id               edge id, coded by <start-id>--<end-id>, where start-id alphabetically < end-id\n",
    "        #   sub\n",
    "        #   start_id         id of start node\n",
    "        #   end_id           id of end node\n",
    "        #   weight\n",
    "        #   start_x_fd       x coordinate for start point, fd stands for force-directed layout\n",
    "        #   start_y_fd       y coordinate for start point, fd stands for force-directed layout\n",
    "        #   end_x_fd         x coordinate for end point, fd stands for force-directed layout\n",
    "        #   end_y_fd         y coordinate for end point, fd stands for force-directed layout\n",
    "        #   start_x_node     x coordinate for start at node center\n",
    "        #   start_y_node     y coordinate for start at node center\n",
    "        #   end_x_node       x coordinate for end at node center\n",
    "        #   end_y_node       y coordinate for end at node center\n",
    "\n",
    "\n",
    "        # read graphics file just created\n",
    "        with open(outfile, 'r', encoding='utf-8') as s:\n",
    "            ss = ET.parse(s)\n",
    "        svg_in = ss.getroot()\n",
    "        ns = {'svg': 'http://www.w3.org/2000/svg'}\n",
    "        self.transform = svg_in.find('svg:g[@id=\"graph0\"]',ns).get('transform')\n",
    "        self.viewbox   = svg_in.get('viewBox')\n",
    "        \n",
    "        # nodes\n",
    "        t0 = process_time()\n",
    "        node_coords = {node.find(\"svg:title\", ns).text: (node.find(\"svg:ellipse\", ns).attrib['cx'], \\\n",
    "                                                         node.find(\"svg:ellipse\", ns).attrib['cy'], \\\n",
    "                                                         node.find(\"svg:ellipse\", ns).attrib['rx'], \\\n",
    "                                                         node.find(\"svg:ellipse\", ns).attrib['ry']  \\\n",
    "                                                        ) for node in svg_in.findall(\".//svg:g[@class='node']\", ns)}\n",
    "        text_coords = {node.find(\"svg:title\", ns).text: (node.find(\"svg:text\", ns).attrib['x'], \\\n",
    "                                                         node.find(\"svg:text\", ns).attrib['y']  \\\n",
    "                                                        ) for node in svg_in.findall(\".//svg:g[@class='node']\", ns)}\n",
    "        self.nds = pd.DataFrame({ \n",
    "                        'sub'  : [att.get('sub') for i,att in graph.nodes(data=True)], \\\n",
    "                        'occ'  : [self.occ_dict.get(k) for k in graph.nodes()], \\\n",
    "                        'name' : [att.get('i-name') for i,att in graph.nodes(data=True)], \\\n",
    "                        'class': [self.cat.get('ingredients').get(k).get('i-class') for k in graph.nodes()], \\\n",
    "                        'cx_fd': [node_coords.get(k)[0] for k in graph.nodes()], \\\n",
    "                        'cy_fd': [node_coords.get(k)[1] for k in graph.nodes()], \\\n",
    "                        'rx_fd': [node_coords.get(k)[2] for k in graph.nodes()], \\\n",
    "                        'ry_fd': [node_coords.get(k)[3] for k in graph.nodes()], \\\n",
    "                        'txt_x': [text_coords.get(k)[0] for k in graph.nodes()], \\\n",
    "                        'txt_y': [text_coords.get(k)[1] for k in graph.nodes()]  \\\n",
    "                        }, \\\n",
    "                        index = graph.nodes() \\\n",
    "                        )\n",
    "        t1 = process_time()\n",
    "        print ('runtime for generating svg nodes in pandas dataframe: ', t1-t0)\n",
    "\n",
    "        # compute initial font size\n",
    "        self.fontsize = math.ceil(float(max(self.nds['rx_fd']))/10)\n",
    "        print ('font size: ', self.fontsize)\n",
    "\n",
    "        # edges\n",
    "        t0 = process_time()\n",
    "        path_coords = [svg_in.find(f\".//svg:g[@id='{attr.get('id')}']/svg:path\", ns).attrib['d'] for u,v,attr in graph.edges(data=True)]\n",
    "        self.eds = pd.DataFrame({\n",
    "            'start_id'    : [u for u,v,attr in graph.edges(data=True)], \\\n",
    "            'end_id'      : [v for u,v,attr in graph.edges(data=True)], \\\n",
    "            'sub'         : [attr.get('sub')    for u,v,attr in graph.edges(data=True)], \\\n",
    "            'weight'      : [attr.get('weight') for u,v,attr in graph.edges(data=True)], \\\n",
    "            'start_x_fd'  : [coords.split(',')[0][1:]           for coords in path_coords], \\\n",
    "            'start_y_fd'  : [coords.split(',')[1].split('C')[0] for coords in path_coords], \\\n",
    "            'end_x_fd'    : [coords.split(' ')[2].split(',')[0] for coords in path_coords], \\\n",
    "            'end_y_fd'    : [coords.split(' ')[2].split(',')[1] for coords in path_coords], \\\n",
    "            'start_x_node': [node_coords[u][0]                  for u,v,attr in graph.edges(data=True)], \\\n",
    "            'start_y_node': [node_coords[u][1]                  for u,v,attr in graph.edges(data=True)], \\\n",
    "            'end_x_node'  : [node_coords[v][0]                  for u,v,attr in graph.edges(data=True)], \\\n",
    "            'end_y_node'  : [node_coords[v][1]                  for u,v,attr in graph.edges(data=True)]  \\\n",
    "        }, index = [attr.get('id') for u,v,attr in graph.edges(data=True)])\n",
    "        t1 = process_time()\n",
    "        print ('runtime for generating svg edges in pandas dataframe: ', t1-t0)\n",
    "        return\n",
    "    \n",
    "    def previewHTML(self,scale=1.0):\n",
    "        # read poor graph.svg\n",
    "        infile = f\"{os.path.join(self.working_dir,self.exp_name)} poor graph.svg\"\n",
    "        with open(infile, 'r', encoding='utf-8') as f:\n",
    "            svg_in = ET.parse(f)\n",
    "            root_in = svg_in.getroot()\n",
    "        ns = {'svg': 'http://www.w3.org/2000/svg'}\n",
    "        # compute font size and transform parameter        \n",
    "        font_size = self.fontsize * scale\n",
    "        transform = root_in.find('svg:g[@id=\"graph0\"]',ns).get('transform')\n",
    "        # create html head section\n",
    "        preview = ET.Element('html')\n",
    "        head  = ET.SubElement(preview, 'head')\n",
    "        # node styling css\n",
    "        style = ET.SubElement(head, 'style')\n",
    "        style.text = \\\n",
    "        ' .i-alc   {fill: #7087ED; stroke: #7087ED; background-color: #7087ED}' +\\\n",
    "        ' .i-carb  {fill: #C8A98B; stroke: #C8A98B; background-color: #C8A98B}' +\\\n",
    "        ' .i-condi {fill: #D58680; stroke: #D58680; background-color: #D58680}' +\\\n",
    "        ' .i-egg   {fill: #70A287; stroke: #70A287; background-color: #70A287}' +\\\n",
    "        ' .i-etc   {fill: #9AA6BF; stroke: #9AA6BF; background-color: #9AA6BF}' +\\\n",
    "        ' .i-fat   {fill: #81CDD8; stroke: #81CDD8; background-color: #81CDD8}' +\\\n",
    "        ' .i-fish  {fill: #ffdab9; stroke: #ffdab9; background-color: #ffdab9}' +\\\n",
    "        ' .i-fruit {fill: #7FDD46; stroke: #7FDD46; background-color: #7FDD46}' +\\\n",
    "        ' .i-herb  {fill: #95A84E; stroke: #95A84E; background-color: #95A84E}' +\\\n",
    "        ' .i-meat  {fill: #EE5874; stroke: #EE5874; background-color: #EE5874}' +\\\n",
    "        ' .i-milk  {fill: #6EA2DC; stroke: #6EA2DC; background-color: #6EA2DC}' +\\\n",
    "        ' .i-nuts  {fill: #D09E44; stroke: #D09E44; background-color: #D09E44}' +\\\n",
    "        ' .i-onion {fill: #60C667; stroke: #60C667; background-color: #60C667}' +\\\n",
    "        ' .i-spice {fill: #FF7F50; stroke: #FF7F50; background-color: #FF7F50}' +\\\n",
    "        ' .i-sweet {fill: #CDE1A6; stroke: #CDE1A6; background-color: #CDE1A6}' +\\\n",
    "        ' .i-veg   {fill: #65DDB7; stroke: #65DDB7; background-color: #65DDB7}'\n",
    "        # js functions for buttons\n",
    "        script = ET.SubElement(head, 'script')\n",
    "        script.text = \\\n",
    "        'function show_A()    {' +\\\n",
    "        'let g0 = document.getElementById(\"graph0\");' +\\\n",
    "        'let g1 = g0.cloneNode(false);' +\\\n",
    "        'g0.remove();' +\\\n",
    "        'const n = document.createElementNS(\"http://www.w3.org/2000/svg\",\"use\");' +\\\n",
    "        'n.setAttribute(\"href\",\"#A_nodes\");' +\\\n",
    "        'g1.appendChild (n);' +\\\n",
    "        'let svg = document.getElementsByTagName(\"svg\")[0];' +\\\n",
    "        'svg.appendChild(g1);' +\\\n",
    "        '};' +\\\n",
    "        'function show_B()    {' +\\\n",
    "        'let g0 = document.getElementById(\"graph0\");' +\\\n",
    "        'let g1 = g0.cloneNode(false);' +\\\n",
    "        'g0.remove();' +\\\n",
    "        'const n = document.createElementNS(\"http://www.w3.org/2000/svg\",\"use\");' +\\\n",
    "        'n.setAttribute(\"href\",\"#B_nodes\");' +\\\n",
    "        'g1.appendChild (n);' +\\\n",
    "        'let svg = document.getElementsByTagName(\"svg\")[0];' +\\\n",
    "        'svg.appendChild(g1);' +\\\n",
    "        '};' +\\\n",
    "        'function show_AB()   {' +\\\n",
    "        'let g0 = document.getElementById(\"graph0\");' +\\\n",
    "        'let g1 = g0.cloneNode(false);' +\\\n",
    "        'g0.remove();' +\\\n",
    "        'const n = document.createElementNS(\"http://www.w3.org/2000/svg\",\"use\");' +\\\n",
    "        'n.setAttribute(\"href\",\"#AB_nodes\");' +\\\n",
    "        'g1.appendChild (n);' +\\\n",
    "        'let svg = document.getElementsByTagName(\"svg\")[0];' +\\\n",
    "        'svg.appendChild(g1);' +\\\n",
    "        '};' +\\\n",
    "        'function show_full() {' +\\\n",
    "        'let g0 = document.getElementById(\"graph0\");' +\\\n",
    "        'let g1 = g0.cloneNode(false);' +\\\n",
    "        'g0.remove();' +\\\n",
    "        'const nA = document.createElementNS(\"http://www.w3.org/2000/svg\",\"use\");' +\\\n",
    "        'nA.setAttribute(\"href\",\"#A_nodes\");' +\\\n",
    "        'g1.appendChild (nA);' +\\\n",
    "        'const nB = document.createElementNS(\"http://www.w3.org/2000/svg\",\"use\");' +\\\n",
    "        'nB.setAttribute(\"href\",\"#B_nodes\");' +\\\n",
    "        'g1.appendChild (nB);' +\\\n",
    "        'const nAB = document.createElementNS(\"http://www.w3.org/2000/svg\",\"use\");' +\\\n",
    "        'nAB.setAttribute(\"href\",\"#AB_nodes\");' +\\\n",
    "        'g1.appendChild (nAB);' +\\\n",
    "        'let svg = document.getElementsByTagName(\"svg\")[0];' +\\\n",
    "        'svg.appendChild(g1);' +\\\n",
    "        '};' \n",
    "        # create button area in HTML body\n",
    "        body  = ET.SubElement(preview, 'body')\n",
    "        div_attr   = {'style':'width:auto;height:120px;'}\n",
    "        div_form   = ET.SubElement(body,'div', attrib=div_attr)\n",
    "        buttonA_attr = {'id':'btn_graph_A', 'type':'button','onclick':'show_A()', 'style':f\"cursor:pointer;font-size:24px; margin:24px; padding:12px\"}\n",
    "        buttonA      = ET.SubElement(div_form, 'button', attrib=buttonA_attr)\n",
    "        buttonA.text = 'subgraph A'\n",
    "        buttonB_attr = {'id':'btn_graph_B', 'type':'button','onclick':'show_B()', 'style':f\"cursor:pointer;font-size:24px; margin:24px; padding:12px\"}\n",
    "        buttonB      = ET.SubElement(div_form, 'button', attrib=buttonB_attr)\n",
    "        buttonB.text = 'subgraph B'\n",
    "        buttonAB_attr = {'id':'btn_graph_AB', 'type':'button','onclick':'show_AB()', 'style':f\"cursor:pointer;font-size:24px; margin:24px; padding:12px\"}\n",
    "        buttonAB      = ET.SubElement(div_form, 'button', attrib=buttonAB_attr)\n",
    "        buttonAB.text = 'subgraph A  B'\n",
    "        buttonfull_attr = {'id':'btn_graph_full', 'type':'button','onclick':'show_full()', 'style':f\"cursor:pointer;font-size:24px; margin:24px; padding:12px\"}\n",
    "        buttonAB      = ET.SubElement(div_form, 'button', attrib=buttonfull_attr)\n",
    "        buttonAB.text = 'full graph'\n",
    "        # create SVG div\n",
    "        div   = ET.SubElement(body,'div')\n",
    "        svg_out_attr = {'xmlns':'http://www.w3.org/2000/svg', 'xmlns:xlink':'http://www.w3.org/1999/xlink', 'version':'1.1', 'viewBox':root_in.get('viewBox')}\n",
    "        svg_out = ET.SubElement(div, 'svg', attrib=svg_out_attr)\n",
    "        # create SVG defs for graph nodes\n",
    "        defs = ET.SubElement(svg_out,'defs')\n",
    "        nodes_A = ET.SubElement(defs, 'g', id='A_nodes')\n",
    "        nodes_B = ET.SubElement(defs, 'g', id='B_nodes')\n",
    "        nodes_AB = ET.SubElement(defs, 'g', id='AB_nodes')\n",
    "        for n in self.nds.index:\n",
    "            sub = self.nds.at[n,'sub']\n",
    "            if   sub ==  'A' : def_el = nodes_A\n",
    "            elif sub ==  'B' : def_el = nodes_B\n",
    "            elif sub == 'AB' : def_el = nodes_AB\n",
    "            else: def_el = None\n",
    "            node_attr   = {'class':'node', 'id':n, 'data-sub':sub, 'style':'cursor: pointer;'}\n",
    "            node        = ET.SubElement(def_el, 'g', attrib=node_attr)\n",
    "            title       = ET.SubElement(node, 'title')\n",
    "            title.text  = f\"#occ: {self.nds.at[n,'occ']}\"\n",
    "            ellip_class = f\"i-{self.nds.at[n,'class']}\"            \n",
    "            ellip_attr  = {'class':ellip_class, 'cx':self.nds.at[n,'cx_fd'], 'cy':self.nds.at[n,'cy_fd'], 'rx':self.nds.at[n,'rx_fd'], 'ry':self.nds.at[n,'ry_fd']}\n",
    "            ET.SubElement(node, 'ellipse', attrib=ellip_attr)\n",
    "            text_attr   = {'x':self.nds.at[n,'txt_x'], 'y':self.nds.at[n,'txt_y'], 'style':f\"text-anchor: middle; font-family: Arial Narrow; font-size: {font_size}px;\"}\n",
    "            text        = ET.SubElement(node, 'text', attrib=text_attr)\n",
    "            text.text   = self.nds.at[n,'name'] \n",
    "        # create SVG main graph\n",
    "        graph0_attr = {'transform':transform, 'id':'graph0'}\n",
    "        graph0 = ET.SubElement(svg_out,'g', attrib=graph0_attr)\n",
    "        use_attr = {'href':'#A_nodes'}\n",
    "        ET.SubElement(graph0,'use', use_attr)\n",
    "        use_attr = {'href':'#B_nodes'}\n",
    "        ET.SubElement(graph0,'use', use_attr)\n",
    "        use_attr = {'href':'#AB_nodes'}\n",
    "        ET.SubElement(graph0,'use', use_attr)\n",
    "        # write HTML to file\n",
    "        tree = ET.ElementTree(preview)\n",
    "        ET.indent(tree)\n",
    "        outfile = f\"{os.path.join(self.working_dir,self.exp_name)} preview.html\"\n",
    "        tree.write(outfile)\n",
    "        return\n",
    "    \n",
    "    def makeSVG(self,graph=None,rcpName=None,occ_growing=None,wgt_growing=None,ix=None,scale=1.0):\n",
    "        \"\"\"\n",
    "        make SVG for partial graph, use occ_growing and wgt_growing\n",
    "        \"\"\"\n",
    "        #ns = {'fr': 'http://fruschtique.de/ns/recipe', 'fe': 'http://fruschtique.de/ns/fe', 'fc': 'http://fruschtique.de/ns/igt-catalog'}\n",
    "        # svg header\n",
    "        w  = self.viewbox.split()[2]\n",
    "        h  = self.viewbox.split()[3]\n",
    "        svg_out_attr = {'xmlns':'http://www.w3.org/2000/svg', 'xmlns:xlink':'http://www.w3.org/1999/xlink', 'version':'1.1', 'viewbox':self.viewbox, \\\n",
    "                        'preserveAspectRatio':'xMidYMid meet', 'zoomAndPan':'magnify', 'contentScriptType':'text/ecmascript', 'contentStyleType':'text/css', 'width':w, 'height':h}\n",
    "        svg_out = ET.Element('svg', attrib=svg_out_attr)\n",
    "        style = ET.SubElement(svg_out, 'style')\n",
    "        style.text = \\\n",
    "            ' .i-alc   {fill: #7087ED; stroke: #7087ED; background-color: #7087ED}' +\\\n",
    "            ' .i-carb  {fill: #C8A98B; stroke: #C8A98B; background-color: #C8A98B}' +\\\n",
    "            ' .i-condi {fill: #D58680; stroke: #D58680; background-color: #D58680}' +\\\n",
    "            ' .i-egg   {fill: #70A287; stroke: #70A287; background-color: #70A287}' +\\\n",
    "            ' .i-etc   {fill: #9AA6BF; stroke: #9AA6BF; background-color: #9AA6BF}' +\\\n",
    "            ' .i-fat   {fill: #81CDD8; stroke: #81CDD8; background-color: #81CDD8}' +\\\n",
    "            ' .i-fish  {fill: #ffdab9; stroke: #ffdab9; background-color: #ffdab9}' +\\\n",
    "            ' .i-fruit {fill: #7FDD46; stroke: #7FDD46; background-color: #7FDD46}' +\\\n",
    "            ' .i-herb  {fill: #95A84E; stroke: #95A84E; background-color: #95A84E}' +\\\n",
    "            ' .i-meat  {fill: #EE5874; stroke: #EE5874; background-color: #EE5874}' +\\\n",
    "            ' .i-milk  {fill: #6EA2DC; stroke: #6EA2DC; background-color: #6EA2DC}' +\\\n",
    "            ' .i-nuts  {fill: #D09E44; stroke: #D09E44; background-color: #D09E44}' +\\\n",
    "            ' .i-onion {fill: #60C667; stroke: #60C667; background-color: #60C667}' +\\\n",
    "            ' .i-spice {fill: #FF7F50; stroke: #FF7F50; background-color: #FF7F50}' +\\\n",
    "            ' .i-sweet {fill: #CDE1A6; stroke: #CDE1A6; background-color: #CDE1A6}' +\\\n",
    "            ' .i-veg   {fill: #65DDB7; stroke: #65DDB7; background-color: #65DDB7}'\n",
    "        # svg graph\n",
    "        g0_node_attr = {'id':'graph0', 'transform':self.transform}\n",
    "        g0_node = ET.SubElement(svg_out,'g',attrib=g0_node_attr)    \n",
    "        rcp_g_attr = {'id':f\"rr-{ix}\"}\n",
    "        rcp_g      = ET.SubElement(g0_node,'g',attrib=rcp_g_attr)\n",
    "        name_field = ET.SubElement(rcp_g,'g')\n",
    "        nf_back_attr = {'x':str(200.0), 'y':str(400.0 - float(h)), 'width':str(float(w)/2), 'height':str(float(h)/24), 'fill':'white', 'stroke':'white', 'stroke-width':'1', 'fill-opacity':'1', 'stroke-opacity':'1'}\n",
    "        nf_back      = ET.SubElement(name_field, 'rect', nf_back_attr) \n",
    "        nf_text_attr = {'x':str(240.0), 'y':str(600.0 - float(h)), 'style':f\"text-anchor: start; font-family: Arial Narrow; font-size: {2.3*fontsize}px;\"}\n",
    "        nf_text      = ET.SubElement(name_field, 'text', nf_text_attr)\n",
    "        nf_text.text = f\"{ix:02d} {rcpName}\"\n",
    "        #print (nf_text.text)\n",
    "        # recipe graph edges\n",
    "        for u,v,att in graph.edges(data=True):\n",
    "            ed_id       = att.get('id')\n",
    "            edge_attr   = {'class':'edge', 'id':ed_id, 'style':'cursor: pointer;'}\n",
    "            edge        = ET.SubElement(rcp_g, 'g', attrib=edge_attr)\n",
    "            start_x     = self.eds.at[ed_id,'start_x_node']\n",
    "            start_y     = self.eds.at[ed_id,'start_y_node']\n",
    "            end_x       = self.eds.at[ed_id,'end_x_node']\n",
    "            end_y       = self.eds.at[ed_id,'end_y_node']\n",
    "            pt_coor     = f\"M{start_x},{start_y}L{end_x},{end_y}\"\n",
    "            xx = wgt_growing.get(ed_id)\n",
    "            if xx == 1:\n",
    "                path_attr   = {'fill':'none', 'stroke': 'black', 'd':pt_coor}\n",
    "            elif xx == 2: \n",
    "                path_attr   = {'fill':'none', 'stroke': 'black', 'stroke-width':'2', 'd':pt_coor}\n",
    "            elif xx > 2: \n",
    "                path_attr   = {'fill':'none', 'stroke': 'red', 'stroke-width':'2', 'd':pt_coor}\n",
    "            else: \n",
    "                path_attr   = {'fill':'none', 'stroke': 'black', 'd':pt_coor}\n",
    "            path        = ET.SubElement(edge,'path',path_attr)\n",
    "        # recipe graph nodes\n",
    "        font_size = self.fontsize * scale\n",
    "        for n in graph.nodes():\n",
    "            node_attr   = {'class':'node', 'id':n, 'data-sub':self.nds.at[n,'sub'], 'style':'cursor: pointer;'}\n",
    "            node        = ET.SubElement(rcp_g, 'g', attrib=node_attr)\n",
    "            title       = ET.SubElement(node, 'title')\n",
    "            title.text  = f\"#occ: {occ_growing.get(n)}\"\n",
    "            ellip_class = f\"i-{self.nds.at[n,'class']}\" \n",
    "            x           = 36*(1 + 3*math.sqrt(occ_growing.get(n)))\n",
    "            rx          = str(round(x*2, 0)/2)\n",
    "            ry          = rx              \n",
    "            ellip_attr  = {'class':ellip_class, 'cx':self.nds.at[n,'cx_fd'], 'cy':self.nds.at[n,'cy_fd'], 'rx':rx, 'ry':ry}\n",
    "            ET.SubElement(node, 'ellipse', attrib=ellip_attr)\n",
    "            text_attr   = {'x':self.nds.at[n,'txt_x'], 'y':self.nds.at[n,'txt_y'], 'style':f\"text-anchor: middle; font-family: Arial Narrow; font-size: {font_size}px;\"}\n",
    "            text        = ET.SubElement(node, 'text', attrib=text_attr)\n",
    "            text.text   = self.nds.at[n,'name'] \n",
    "        # return svg\n",
    "        return svg_out\n",
    "    \n",
    "    def createSVGSequence(self,rcpNames=None,targetDir=None,scale=1.0):\n",
    "        \"\"\"\n",
    "        generate svg per recipe graph in order as given by rcpNames list\n",
    "        collect resulting svg files in directory\n",
    "        node coordinates to be taken from ingredient graph svg\n",
    "        edge coordinates to be taken from start and end node coordinates\n",
    "        provide occ_growing and weight_growing to SVGMaker\n",
    "        \"\"\"\n",
    "        # init\n",
    "        K  = nx.Graph()                                  # empty recipe graph (complete graph)\n",
    "        ix = 1                                           # sequence number\n",
    "        font_size = self.fontsize * scale\n",
    "        occ_growing = {idx:0 for idx in self.nds.index}  # init occ_growing\n",
    "        wgt_growing = {idx:0 for idx in self.eds.index}          \n",
    "        # loop over recipes in collection for creating recipe graphs\n",
    "        for rcpName in rcpNames:                         # collect ingredients for recipe graph\n",
    "            occ_list = []\n",
    "            rcp_igt_set = set()\n",
    "            xx = rcpName.get('ingredients')\n",
    "            for ingredient in xx:\n",
    "                rcp_igt_set.add(ingredient)\n",
    "            occ_list.extend(list(rcp_igt_set))\n",
    "            K = nx.complete_graph(rcp_igt_set)           # build recipe graph\n",
    "            for k in rcp_igt_set:\n",
    "                occ_growing[k] += 1              \n",
    "            # add attributes to edges of G\n",
    "                # edge id\n",
    "            e_attr = {}\n",
    "            for e in list(K.edges(data=True)):\n",
    "                x = [e[0],e[1]]\n",
    "                x.sort(key=locale.strxfrm)\n",
    "                id = str(x[0]) + '--' + str(x[1])\n",
    "                xx = (e[0],e[1])\n",
    "                e_attr[xx] = {'id':id}\n",
    "            nx.set_edge_attributes(K, e_attr)\n",
    "            for k in list(nx.get_edge_attributes(K,'id').values()):\n",
    "                wgt_growing[k] += 1\n",
    "            # save to file\n",
    "            #print(rcpName.get('recipeName'))\n",
    "            build = self.makeSVG(K,rcpName.get('recipeName'),occ_growing,wgt_growing,ix,font_size)\n",
    "            tree = ET.ElementTree(build)\n",
    "            ET.indent(tree)\n",
    "            fn = f\"{ix:03d} {rcpName.get('recipeName')}.svg\"\n",
    "            file_path = f\"{os.path.join(targetDir,fn)}\"\n",
    "            tree.write(file_path)\n",
    "            ix += 1\n",
    "        return\n",
    "\n",
    "    def sortByContrib2IG(self, rcpNames=None):\n",
    "        \"\"\"\n",
    "        sort recipes by contribution of distinct ingredients to full graph, descending\n",
    "        \"\"\"\n",
    "        # function for sorting subset of Pandas dataframe\n",
    "        def sort_sub(df, i1, i2, by_col):\n",
    "            a = df.iloc[i1:i2].copy()\n",
    "            a.sort_values(by=by_col, inplace=True, ascending=False, ignore_index=True)\n",
    "            df.iloc[i1:i2] = a\n",
    "            return df\n",
    "        \n",
    "        # collect ingredients lists\n",
    "        igt_sets = []\n",
    "        #print (rcpNames)\n",
    "        for rcp in rcpNames:    \n",
    "            igt_set = set(rcp.get('ingredients'))\n",
    "            igt_sets.append(igt_set)\n",
    "        count = [len(igt_set) for igt_set in igt_sets]\n",
    "\n",
    "        # create Pandas dataframe for recipes and their ingredients\n",
    "        #print(range(1,len(rcpNames)+1))\n",
    "        #print(len(rcpNames))\n",
    "        #print(len(igt_sets))\n",
    "        #print(count)\n",
    "        collection_df = pd.DataFrame({'number':range(1,len(rcpNames)+1), 'rcp_names': rcpNames, 'rcp_ingredients': igt_sets, 'count_igt': count})\n",
    "        \n",
    "        # first: recipe with max number of ingredients\n",
    "        collection_df.sort_values(by='count_igt', inplace=True, ascending=False, ignore_index=True)\n",
    "\n",
    "        # init dataframe before sorting\n",
    "        collection_df['union'] = [set() for i in range(len(rcpNames))]\n",
    "        collection_df['union_len'] = 0\n",
    "        collection_df.at[0,'union'] = collection_df.at[0,'rcp_ingredients']\n",
    "        collection_df.at[0,'union_len'] = len(collection_df.at[0,'union'])\n",
    "\n",
    "        # sort dataframe by union length\n",
    "        for ix in range(1,len(rcpNames)):   \n",
    "            for ix2 in range (ix,len(rcpNames)):\n",
    "                coll = collection_df.at[ix2,'rcp_ingredients'].union(collection_df.at[ix-1,'union'])\n",
    "                collection_df.at[ix2,'union']     = coll\n",
    "                collection_df.at[ix2,'union_len'] = len(coll)\n",
    "            sort_sub(collection_df,ix,len(rcpNames),'union_len')\n",
    "            #print (collection_df.at[ix-1,'union_len'], collection_df.at[ix-1,'rcp_names'].get('recipeName'))\n",
    "        #print (list(collection_df['rcp_names']))\n",
    "        return list(collection_df['rcp_names'])\n",
    "    \n",
    "    def graphToSVG (self, scale=1.0):\n",
    "        \"\"\" \n",
    "        Create svg file for graph\n",
    "        \"\"\"\n",
    "        def add_SVG_edge(id,sub,start_id,end_id,weight,start_x,start_y,end_x,end_y):\n",
    "            edge_attr   = {'class':'edge', 'id':id}\n",
    "            edge        = ET.SubElement(g0_node, 'g', attrib=edge_attr)\n",
    "            title       = ET.SubElement(edge,'title')\n",
    "            title.text  = f\"{start_id}--{end_id}\"\n",
    "            pt_coor     = f\"M{start_x},{start_y}L{end_x},{end_y}\"\n",
    "            if weight == 1:\n",
    "                path_attr   = {'fill':'none', 'stroke': 'black', 'd':pt_coor}\n",
    "            elif weight == 2: \n",
    "                path_attr   = {'fill':'none', 'stroke': 'black', 'stroke-width':'2', 'd':pt_coor}\n",
    "            elif weight > 2: \n",
    "                path_attr   = {'fill':'none', 'stroke': 'red', 'stroke-width':'2', 'd':pt_coor}\n",
    "            else: \n",
    "                path_attr   = {'fill':'none', 'stroke': 'black', 'd':pt_coor}\n",
    "            path        = ET.SubElement(edge,'path',path_attr)\n",
    "            \n",
    "        def add_SVG_node(id,sub,occ,name,i_class,cx_fd,cy_fd,rx_fd,ry_fd,txt_x,txt_y):\n",
    "            node_attr   = {'class':'node', 'id':id, 'data-sub':sub, 'style':'cursor: pointer;'}\n",
    "            node        = ET.SubElement(g0_node, 'g', attrib=node_attr)\n",
    "            title       = ET.SubElement(node, 'title')\n",
    "            title.text  = f\"#occ: {occ}\"\n",
    "            ellip_class = f\"i-{i_class}\"            \n",
    "            ellip_attr  = {'class':ellip_class, 'cx':cx_fd, 'cy':cy_fd, 'rx':rx_fd, 'ry':ry_fd}\n",
    "            ET.SubElement(node, 'ellipse', attrib=ellip_attr)\n",
    "            text_attr   = {'x':txt_x, 'y':txt_y, 'style':f\"text-anchor: middle; font-family: Arial Narrow; font-size: {font_size}px;\"}\n",
    "            text        = ET.SubElement(node, 'text', attrib=text_attr)\n",
    "            text.text   = name\n",
    "            \n",
    "        font_size = self.fontsize * scale\n",
    "        # svg header\n",
    "        w  = self.viewbox.split()[2]\n",
    "        h  = self.viewbox.split()[3]\n",
    "        svg_out_attr = {'xmlns':'http://www.w3.org/2000/svg', 'xmlns:xlink':'http://www.w3.org/1999/xlink', 'version':'1.1', 'viewbox':self.viewbox, \\\n",
    "                        'preserveAspectRatio':'xMidYMid meet', 'zoomAndPan':'magnify', 'contentScriptType':'text/ecmascript', 'contentStyleType':'text/css', 'width':w, 'height':h}\n",
    "        svg_out = ET.Element('svg', attrib=svg_out_attr)\n",
    "        style = ET.SubElement(svg_out, 'style')\n",
    "        style.text = \\\n",
    "            ' .i-alc   {fill: #7087ED; stroke: #7087ED; background-color: #7087ED}' +\\\n",
    "            ' .i-carb  {fill: #C8A98B; stroke: #C8A98B; background-color: #C8A98B}' +\\\n",
    "            ' .i-condi {fill: #D58680; stroke: #D58680; background-color: #D58680}' +\\\n",
    "            ' .i-egg   {fill: #70A287; stroke: #70A287; background-color: #70A287}' +\\\n",
    "            ' .i-etc   {fill: #9AA6BF; stroke: #9AA6BF; background-color: #9AA6BF}' +\\\n",
    "            ' .i-fat   {fill: #81CDD8; stroke: #81CDD8; background-color: #81CDD8}' +\\\n",
    "            ' .i-fish  {fill: #ffdab9; stroke: #ffdab9; background-color: #ffdab9}' +\\\n",
    "            ' .i-fruit {fill: #7FDD46; stroke: #7FDD46; background-color: #7FDD46}' +\\\n",
    "            ' .i-herb  {fill: #95A84E; stroke: #95A84E; background-color: #95A84E}' +\\\n",
    "            ' .i-meat  {fill: #EE5874; stroke: #EE5874; background-color: #EE5874}' +\\\n",
    "            ' .i-milk  {fill: #6EA2DC; stroke: #6EA2DC; background-color: #6EA2DC}' +\\\n",
    "            ' .i-nuts  {fill: #D09E44; stroke: #D09E44; background-color: #D09E44}' +\\\n",
    "            ' .i-onion {fill: #60C667; stroke: #60C667; background-color: #60C667}' +\\\n",
    "            ' .i-spice {fill: #FF7F50; stroke: #FF7F50; background-color: #FF7F50}' +\\\n",
    "            ' .i-sweet {fill: #CDE1A6; stroke: #CDE1A6; background-color: #CDE1A6}' +\\\n",
    "            ' .i-veg   {fill: #65DDB7; stroke: #65DDB7; background-color: #65DDB7}' \n",
    "            \n",
    "        # svg graph\n",
    "        g0_node_attr = {'id':'graph0', 'transform':self.transform}\n",
    "        g0_node = ET.SubElement(svg_out,'g',attrib=g0_node_attr) \n",
    "        # traversing the pandas dataframe for edges\n",
    "        #   id               edge id, coded by <start-id>--<end-id>, where start-id alphabetically < end-id\n",
    "        #   sub\n",
    "        #   start_id         id of start node\n",
    "        #   end_id           id of end node\n",
    "        #   weight\n",
    "        #   start_x_fd       x coordinate for start point, fd stands for force-directed layout\n",
    "        #   start_y_fd       y coordinate for start point, fd stands for force-directed layout\n",
    "        #   end_x_fd         x coordinate for end point, fd stands for force-directed layout\n",
    "        #   end_y_fd         y coordinate for end point, fd stands for force-directed layout\n",
    "        #   start_x_node     x coordinate for start at node center\n",
    "        #   start_y_node     y coordinate for start at node center\n",
    "        #   end_x_node       x coordinate for end at node center\n",
    "        #   end_y_node       y coordinate for end at node center\n",
    "        edges_frame = self.eds\n",
    "        [add_SVG_edge(row[0],row[1],row[2],row[3],row[4],row[5],row[6],row[7],row[8]) for row \\\n",
    "                in zip(edges_frame.index, edges_frame['sub'], edges_frame['start_id'], edges_frame['end_id'], edges_frame['weight'], \\\n",
    "                edges_frame['start_x_fd'], edges_frame['start_y_fd'], edges_frame['end_x_fd'], edges_frame['end_y_fd'])]\n",
    "        # traversing the pandas dataframe for nodes\n",
    "        nodes_frame = self.nds\n",
    "        [add_SVG_node(row[0],row[1],row[2],row[3],row[4],row[5],row[6],row[7],row[8],row[9],row[10]) for row \\\n",
    "                in zip(nodes_frame.index, nodes_frame['sub'], nodes_frame['occ'], nodes_frame['name'], nodes_frame['class'], \\\n",
    "                nodes_frame['cx_fd'], nodes_frame['cy_fd'], nodes_frame['rx_fd'], nodes_frame['ry_fd'], nodes_frame['txt_x'], nodes_frame['txt_y'] )]\n",
    "        # write created svg to file\n",
    "        tree = ET.ElementTree(svg_out)\n",
    "        ET.indent(tree)\n",
    "        outfile = f\"{os.path.join(self.working_dir,self.exp_name)}.svg\"\n",
    "        tree.write(outfile)              \n",
    "        return nodes_frame\n",
    "\n",
    "    def nodesByOcc(self, incl_lower=None, excl_upper=None, fn=None, cls=None, scale=1.0):\n",
    "        \"\"\" \n",
    "        Create svg file with nodes meeting occurrence constraint\n",
    "        \"\"\"\n",
    "        def add_SVG_node(id,sub,occ,name,i_class,cx_fd,cy_fd,rx_fd,ry_fd,txt_x,txt_y):\n",
    "            node_attr   = {'class':'node', 'id':id, 'data-sub':sub, 'style':'cursor: pointer;'}\n",
    "            node        = ET.SubElement(g0_node, 'g', attrib=node_attr)\n",
    "            title       = ET.SubElement(node, 'title')\n",
    "            title.text  = f\"#occ: {occ}\"\n",
    "            if cls != None:\n",
    "                ellip_class = cls\n",
    "            else:\n",
    "                ellip_class = f\"i-{i_class}\"            \n",
    "            ellip_attr  = {'class':ellip_class, 'cx':cx_fd, 'cy':cy_fd, 'rx':rx_fd, 'ry':ry_fd}\n",
    "            ET.SubElement(node, 'ellipse', attrib=ellip_attr)\n",
    "            text_attr   = {'x':txt_x, 'y':txt_y, 'style':f\"text-anchor: middle; font-family: Arial Narrow; font-size: {font_size}px;\"}\n",
    "            text        = ET.SubElement(node, 'text', attrib=text_attr)\n",
    "            text.text   = name\n",
    "        \n",
    "        font_size = self.fontsize * scale\n",
    "        # svg header\n",
    "        w  = self.viewbox.split()[2]\n",
    "        h  = self.viewbox.split()[3]\n",
    "        svg_out_attr = {'xmlns':'http://www.w3.org/2000/svg', 'xmlns:xlink':'http://www.w3.org/1999/xlink', 'version':'1.1', 'viewbox':self.viewbox, \\\n",
    "                        'preserveAspectRatio':'xMidYMid meet', 'zoomAndPan':'magnify', 'contentScriptType':'text/ecmascript', 'contentStyleType':'text/css', 'width':w, 'height':h}\n",
    "        svg_out = ET.Element('svg', attrib=svg_out_attr)\n",
    "        style = ET.SubElement(svg_out, 'style')\n",
    "        style.text = \\\n",
    "            ' .i-alc   {fill: #7087ED; stroke: #7087ED; background-color: #7087ED}' +\\\n",
    "            ' .i-carb  {fill: #C8A98B; stroke: #C8A98B; background-color: #C8A98B}' +\\\n",
    "            ' .i-condi {fill: #D58680; stroke: #D58680; background-color: #D58680}' +\\\n",
    "            ' .i-egg   {fill: #70A287; stroke: #70A287; background-color: #70A287}' +\\\n",
    "            ' .i-etc   {fill: #9AA6BF; stroke: #9AA6BF; background-color: #9AA6BF}' +\\\n",
    "            ' .i-fat   {fill: #81CDD8; stroke: #81CDD8; background-color: #81CDD8}' +\\\n",
    "            ' .i-fish  {fill: #ffdab9; stroke: #ffdab9; background-color: #ffdab9}' +\\\n",
    "            ' .i-fruit {fill: #7FDD46; stroke: #7FDD46; background-color: #7FDD46}' +\\\n",
    "            ' .i-herb  {fill: #95A84E; stroke: #95A84E; background-color: #95A84E}' +\\\n",
    "            ' .i-meat  {fill: #EE5874; stroke: #EE5874; background-color: #EE5874}' +\\\n",
    "            ' .i-milk  {fill: #6EA2DC; stroke: #6EA2DC; background-color: #6EA2DC}' +\\\n",
    "            ' .i-nuts  {fill: #D09E44; stroke: #D09E44; background-color: #D09E44}' +\\\n",
    "            ' .i-onion {fill: #60C667; stroke: #60C667; background-color: #60C667}' +\\\n",
    "            ' .i-spice {fill: #FF7F50; stroke: #FF7F50; background-color: #FF7F50}' +\\\n",
    "            ' .i-sweet {fill: #CDE1A6; stroke: #CDE1A6; background-color: #CDE1A6}' +\\\n",
    "            ' .i-veg   {fill: #65DDB7; stroke: #65DDB7; background-color: #65DDB7}' +\\\n",
    "            ' .occ_1   {fill: #E96F49; stroke: #E96F49; background-color: #E96F49}' +\\\n",
    "            ' .occ_2   {fill: #BEDF1B; stroke: #BEDF1B; background-color: #BEDF1B}' +\\\n",
    "            ' .occ_3   {fill: #1BDF32; stroke: #1BDF32; background-color: #1BDF32}' +\\\n",
    "            ' .occ_4   {fill: #1BD6DF; stroke: #1BD6DF; background-color: #1BD6DF}' +\\\n",
    "            ' .occ_5   {fill: #7D7DEF; stroke: #7D7DEF; background-color: #7D7DEF}' \n",
    "        # svg graph\n",
    "        g0_node_attr = {'id':'graph0', 'transform':self.transform}\n",
    "        g0_node = ET.SubElement(svg_out,'g',attrib=g0_node_attr) \n",
    "        # create pandas dataframe with nodes meeting the given occurrence constraint\n",
    "        nodes_frame = self.nds.loc[(self.nds['occ'] >= incl_lower) & (self.nds['occ'] < excl_upper)]\n",
    "        # loop comprehension for traversing the pandas dataframe\n",
    "        [add_SVG_node(row[0],row[1],row[2],row[3],row[4],row[5],row[6],row[7],row[8],row[9],row[10]) for row \\\n",
    "                in zip(nodes_frame.index, nodes_frame['sub'], nodes_frame['occ'], nodes_frame['name'], nodes_frame['class'], \\\n",
    "                nodes_frame['cx_fd'], nodes_frame['cy_fd'], nodes_frame['rx_fd'], nodes_frame['ry_fd'], nodes_frame['txt_x'], nodes_frame['txt_y'] )]\n",
    "        # write created svg to file\n",
    "        tree = ET.ElementTree(svg_out)\n",
    "        ET.indent(tree)\n",
    "        tree.write(self.working_dir + fn + '.svg')              \n",
    "        return nodes_frame\n",
    "\n",
    "    def checkColl(self, key_ref):\n",
    "        \"\"\"\n",
    "        some plausibility checks\n",
    "        1 key ingredient occurence\n",
    "        \"\"\"\n",
    "        # key ingredient occurence\n",
    "        for fn_rcp in self.in_files:\n",
    "            with open(fn_rcp, 'r', encoding='utf-8') as f:\n",
    "                rcp_in = ET.parse(f)\n",
    "                rcp_root = rcp_in.getroot()\n",
    "                rcp_name = rcp_root.find('fr:recipeName', self.ns).text\n",
    "                key_elements = []\n",
    "                key_elements = rcp_root.findall(f\".//ns0:igdtName[@ref='{key_ref}']\",self.ns)\n",
    "                if len(key_elements) == 0:\n",
    "                    print (f\"0    key ingredients for {rcp_name}\")  \n",
    "                elif len(key_elements) >= 2:\n",
    "                    print (f\"=> 2 key ingredients for {rcp_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62ac6f58",
   "metadata": {},
   "source": [
    "#### fruschtique API functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c15d00f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Helper functions\n",
    "\n",
    "index = dict()\n",
    "noRefIgts = []\n",
    "    \n",
    "# find longest matching ID for given ingredient name\n",
    "def getIgtID (given, index):\n",
    "    match = 0\n",
    "    xxid = None\n",
    "    for k,v in index.items():\n",
    "        if k in given.lower():\n",
    "            if len(k) > match:\n",
    "                match = len(k)\n",
    "                xxid = v\n",
    "    return xxid\n",
    "\n",
    "# write ingredient ID into recipe\n",
    "def write2XML(rcp,ns,igt,id):\n",
    "    el = rcp.findall(f'.//fr:igdtName[.=\"{igt}\"]', ns)\n",
    "    for x in el:\n",
    "        x.set('ref',id)\n",
    "        print\n",
    "    return el\n",
    "\n",
    "# read ingredients catalogue and create ingredients index\n",
    "def createIgdtIndex (igdtCat):\n",
    "    global index, noRefIgts\n",
    "    with open(igdtCat, encoding='utf-8') as file:\n",
    "        cat            = json.load(file)\n",
    "        catIngredients = cat.get('ingredients')\n",
    "        #catClasses     = cat.get('classes')\n",
    "        noRefIgts      = cat.get('noRefIgts')\n",
    "        index = dict()\n",
    "        for igt in catIngredients.items():\n",
    "            x = dict()\n",
    "            k = igt[0]\n",
    "            x = {k:k}\n",
    "            index.update(x)\n",
    "            y = dict()\n",
    "            for syn in igt[1].get('synonyms'):\n",
    "                y = {syn:k}\n",
    "                index.update(y)\n",
    "        return\n",
    "\n",
    "# create refs, write them into recipe, and return results list\n",
    "def writeRefs2rcp (loc,rcpName,ns):\n",
    "    global index, noRefIgts\n",
    "    fp = os.path.join(loc,rcpName)\n",
    "    with open(fp, 'r', encoding='utf-8') as f:\n",
    "        rcp_in = ET.parse(f)\n",
    "        rcp_root = rcp_in.getroot()\n",
    "    allGiven = [entry.text.replace('\"','') for entry in rcp_root.findall('.//fr:igdtName', ns)]\n",
    "    suc = 0\n",
    "    noSuc = []\n",
    "    for ig in allGiven:\n",
    "        match = getIgtID(ig, index)\n",
    "        if match == None:\n",
    "            noSuc.append(ig)\n",
    "        else:\n",
    "            suc += 1\n",
    "            write2XML(rcp_root,ns,ig,match) \n",
    "    for xx in noSuc:\n",
    "        for x in noRefIgts:\n",
    "            if x in xx:\n",
    "                suc += 1\n",
    "    tree = ET.ElementTree(rcp_root)\n",
    "    ET.indent(tree)\n",
    "    tree.write(fp)\n",
    "    return {'total':len(allGiven), 'success':suc, 'fail':noSuc, 'recipe name':rcpName}\n",
    "\n",
    "### API functions for creating references to ingredients catalogue\n",
    "\n",
    "def createRefs4Recipe(loc=None,rcpName=None,igdtCat=None):\n",
    "    global index, noRefIgts\n",
    "    createIgdtIndex(igdtCat)\n",
    "    ns = {'fr': 'http://fruschtique.de/ns/recipe'}\n",
    "    return \n",
    "\n",
    "def createRefs4Coll(loc=None,igdtCat=None):\n",
    "    # loop over recipes in loc directory\n",
    "    # call to createRefs4Recipe per recipe\n",
    "    # write modified recipes back to loc directory\n",
    "    global index, noRefIgts\n",
    "    createIgdtIndex(igdtCat)\n",
    "    ns = {'fr': 'http://fruschtique.de/ns/recipe'}\n",
    "    results = []\n",
    "    for rcp in os.listdir(loc):\n",
    "        result = writeRefs2rcp (loc,rcp,ns)\n",
    "        results.append (result)\n",
    "    return results\n",
    "\n",
    "### API scraper functions \n",
    "\n",
    "def scrapeCK (loc=None, url=None, extended_name=None, synList=None):\n",
    "\n",
    "    # when reading from file:\n",
    "    #with open(url, 'r') as f:\n",
    "    #    root = BeautifulSoup(f, 'html.parser')\n",
    "\n",
    "    # when reading from web\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200: \n",
    "        root = BeautifulSoup(response.text, 'html.parser')\n",
    "    else:\n",
    "        return -1\n",
    "    \n",
    "    name = extended_name \n",
    "    instruct = root.select(\"small+div.ds-box\")[0].get_text(separator = '\\n',strip=True)\n",
    "    # find ingredient tables\n",
    "    hidden = root.find('div', {'amp-access':'rolesMap.ROLE_ENTITLEMENT_PLUS_RECIPES'})\n",
    "    if hidden == None:\n",
    "        igdt_tables = root.select('.ingredients')\n",
    "    else:\n",
    "        igdt_tables = root.select('div[amp-access=\"rolesMap.ROLE_ENTITLEMENT_PLUS_RECIPES\"] > .ingredients')\n",
    "\n",
    "    igt_list_text = ''\n",
    "    for idx in range(0,len(igdt_tables)):\n",
    "        igt_list_text += igdt_tables[idx].get_text()\n",
    "    #print (f\"Found {len(igdt_tables)} ingredient tables.\")\n",
    "    for syn in synList:\n",
    "        if (syn in name.lower()) or (syn in igt_list_text.lower()) or (syn in instruct.lower()):\n",
    "            break\n",
    "        else:\n",
    "            return 0\n",
    "    _id  = f'ck-{uuid.uuid4()}'\n",
    "    \n",
    "    fr = 'http://fruschtique.de/ns/recipe'\n",
    "    ET.register_namespace('fr', fr)\n",
    "    xsi = 'http://www.w3.org/2001/XMLSchema-instance'\n",
    "    recipe = ET.Element('fr:recipe', attrib={'xmlns:fr' : fr, 'xmlns:xsi': xsi, 'xsi:schemaLocation': fr + ' file:///c:/Users/nlutt/Documents/Websites/tools/recipe.xsd', 'rcpID': _id})\n",
    "    meta = ET.SubElement(recipe, 'fr:meta')\n",
    "    ET.SubElement(meta, 'fr:book').text = ''\n",
    "    ET.SubElement(meta, 'fr:chapter').text = ''\n",
    "    ET.SubElement(recipe, 'fr:recipeName').text = extended_name\n",
    "    ET.SubElement(recipe, 'fr:recipeKeywords')\n",
    "    ET.SubElement(recipe, 'fr:recipeIntro')\n",
    "    recipe_ingredients = ET.SubElement(recipe, 'fr:recipeIngredients')\n",
    "    igdt_list = ET.SubElement(recipe_ingredients, 'fr:igdtList')\n",
    "    ET.SubElement(igdt_list, 'fr:igdtListName')\n",
    "    for idx in range(0, len(igdt_tables)):\n",
    "        #print (f\" table {idx}\")\n",
    "        igt_list_rows = igdt_tables[idx].select('tbody tr')\n",
    "        for i in range(0, len(igt_list_rows)):\n",
    "            #print (f\" row {i}\")\n",
    "            igdt_list_line = ET.SubElement(igdt_list, 'fr:igdtListLine')\n",
    "            x = igt_list_rows[i].select('td')[0].get_text().replace('\"','')\n",
    "            xx = \" \".join(x.split())\n",
    "            ET.SubElement(igdt_list_line, 'fr:igdtQuantity').text = xx\n",
    "            y = igt_list_rows[i].select('td')[1].get_text().replace('\"','')\n",
    "            yy = \" \".join(y.split())\n",
    "            #print (yy)\n",
    "            ET.SubElement(igdt_list_line, 'fr:igdtName', attrib={'ref':''}).text = yy\n",
    "\n",
    "    instructions = ET.SubElement(recipe, 'fr:recipeInstructions')\n",
    "    instruction = ET.SubElement (instructions,'fr:instruction')\n",
    "    ET.SubElement(instruction,'fr:instrStepName')\n",
    "    ET.SubElement(instruction,'fr:instrStepText').text = instruct\n",
    "    ET.SubElement(recipe, 'fr:recipeSideDish')\n",
    "    ET.SubElement(recipe, 'fr:recipeOrigin')\n",
    "    ET.SubElement(recipe, 'fr:recipeSeeAlso')\n",
    "    ET.SubElement(recipe, 'fr:recipeLicense')\n",
    "    xml_rcp = ET.ElementTree(recipe)\n",
    "    return xml_rcp\n",
    "\n",
    "def parse_search_result_page(url=None):\n",
    "    response = requests.get(url)\n",
    "    body = response.text\n",
    "    xx = response.status_code\n",
    "    #print (xx)\n",
    "    if xx != 200:\n",
    "        return -1\n",
    "    root = BeautifulSoup(body, 'html.parser')\n",
    "    rcpList = []\n",
    "    nameList = []\n",
    "    for el in root.select('.recipe-list>.ds-recipe-card'):\n",
    "        rcp_name = el.get('data-vars-recipe-title').replace('\"','').replace('/','').replace('  ',' ').replace(' - ','-')\n",
    "        #print (rcp_name)\n",
    "        x_url = el.find('a').get('href')\n",
    "        rcp_url = x_url.split('#')[0]\n",
    "        #print (rcp_url)\n",
    "        if rcp_name is not None:\n",
    "            rcpList.append((rcp_name,rcp_url))\n",
    "            nameList.append (rcp_name)\n",
    "    return rcpList, nameList\n",
    "\n",
    "def scrapeCKbyKey(loc=None, culinaryKey=None, igdtCat=None):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    # create complete recipe list\n",
    "    totalRcpList = []\n",
    "    ctrList = []\n",
    "    i1 = 0\n",
    "    while True:\n",
    "        url = f'https://www.chefkoch.de/rs/s{i1}/{culinaryKey}/Rezepte.html'\n",
    "        xx = parse_search_result_page(url)\n",
    "        if xx != -1:\n",
    "            totalRcpList.extend(xx[0])\n",
    "            ctrList.extend(xx[1])\n",
    "            i1 += 1\n",
    "        else:\n",
    "            break\n",
    "    print ('CK search results: ', len(totalRcpList))  \n",
    "\n",
    "    ctr = dict(Counter(ctrList))\n",
    "    #print (ctr)\n",
    "\n",
    "    # provide list of synonyms for culinary key\n",
    "    with open('C:/Users/nlutt/myPyPro/second/data/igt_cat.json', encoding='utf-8') as file:\n",
    "        cat            = json.load(file)\n",
    "        catIngredients = cat.get('ingredients')\n",
    "    _id = ''\n",
    "    for k,v in catIngredients.items():\n",
    "        #print (k)\n",
    "        if v.get('i-name') == culinaryKey:\n",
    "            _id = k\n",
    "            break\n",
    "    if _id == '':\n",
    "        print (f\"{culinaryKey} not in ingredients catalogue!\")\n",
    "        return\n",
    "            \n",
    "    synList = [catIngredients.get(_id).get('i-name').lower()]\n",
    "    for syn in catIngredients.get(_id).get('synonyms'):\n",
    "        synList.append(syn)\n",
    "    #print (synList)\n",
    "    # scrape CK recipes and write to XML files\n",
    "    i = 0\n",
    "    for rcp in totalRcpList:\n",
    "        rcpName = rcp[0].replace('\"','').replace('/','').replace('  ',' ').replace(' - ','-')\n",
    "        url = rcp[1]\n",
    "        name_counter = ctr.get(rcpName)\n",
    "        if name_counter > 1:\n",
    "            extension = str(name_counter).zfill(3)\n",
    "            extended_fn = f\"{rcpName} {extension}.xml\"\n",
    "            extended_rcpName = f\"{rcpName} {extension}\"\n",
    "            ctr.update({rcpName:name_counter - 1})\n",
    "        else:\n",
    "            extended_fn = f\"{rcpName}.xml\" \n",
    "            extended_rcpName = rcpName\n",
    "        xml_rcp = scrapeCK (loc,url,extended_rcpName,synList)\n",
    "        if xml_rcp == 0:\n",
    "            print (rcpName)\n",
    "        elif xml_rcp == -1: \n",
    "            print ('Done!')\n",
    "            break\n",
    "        else: \n",
    "            i += 1\n",
    "            print (i)  \n",
    "            file_path = f\"{os.path.join(loc,extended_fn)}\"\n",
    "            xml_rcp.write(file_path, xml_declaration=True, encoding='utf-8', method='xml') \n",
    "    print ('Done!')\n",
    "    return\n",
    "\n",
    "def makeSampleSpace(sourceDir=None, graphlabDir=None, sampleSpaceName=None, cb=None, meta=None):\n",
    "    \"\"\"\n",
    "    1 Create folder for new sample space\n",
    "    2 Create XML-coded catalog of recipes in sourcedir\n",
    "    3 create XML-coded descriptor for collection \n",
    "    \"\"\"\n",
    "    # new sample space\n",
    "    newSpace = os.path.join(graphlabDir,'sampleSpaces',sampleSpaceName)\n",
    "    if not os.path.exists(newSpace):\n",
    "        os.makedirs(newSpace)\n",
    "    newGraphsDir = os.path.join(newSpace,'graphs')\n",
    "    if not os.path.exists(newGraphsDir):   \n",
    "        os.makedirs(newGraphsDir)\n",
    "    # catalogue of files in collection\n",
    "    sourceFiles = [os.path.join(sourceDir,f) for f in os.listdir(sourceDir) if os.path.isfile(os.path.join(sourceDir, f))]\n",
    "    collection = ET.Element('collection')\n",
    "    for f in sourceFiles:\n",
    "        x = urllib.parse.urljoin('file:', pathname2url(f))\n",
    "        doc = ET.SubElement(collection,'doc',attrib={'href':x})\n",
    "    cata = ET.ElementTree(collection)\n",
    "    ET.indent(cata)\n",
    "    cata.write(os.path.join(newSpace,'catalogue.xml'), xml_declaration=True, encoding='utf-8', method='xml')\n",
    "    # create descriptor\n",
    "    fe = 'http://fruschtique.de/ns/fe'\n",
    "    ET.register_namespace('fe', fe)\n",
    "    xsi = 'http://www.w3.org/2001/XMLSchema-instance' \n",
    "    experiment = ET.Element('fe:experiment', attrib={'xmlns:fe' : fe, 'xmlns:xsi': xsi, 'xsi:schemaLocation': fe + ' file:///c:/users/nlutt/documents/websites/graphlab/tools/experiment.xsd'})\n",
    "    fullTitle = ET.SubElement(experiment,'fe:fullTitle')\n",
    "    fullTitle.text = f\"{sampleSpaceName}\"\n",
    "    cookbook = ET.SubElement(experiment,'fe:cookbook')\n",
    "    cookbook.text = cb\n",
    "    experimentPath = ET.SubElement(experiment,'fe:experimentPath')\n",
    "    experimentPath.text = f'sampleSpaces/{sampleSpaceName}/'\n",
    "    winExperimentPath = ET.SubElement(experiment,'fe:win-experimentPath')\n",
    "    winExperimentPath.text = f\"{os.path.join('sampleSpaces',sampleSpaceName)}\\\\\"\n",
    "    experimentName = ET.SubElement(experiment,'fe:experimentName')\n",
    "    experimentName.text = f\"{sampleSpaceName}\"\n",
    "    ET.SubElement(experiment,'fe:experimentDescription')\n",
    "    useIngredientReplacements = ET.SubElement(experiment,'fe:useIngredientReplacements')\n",
    "    useIngredientReplacements.text = 'no'\n",
    "    descriptor = ET.ElementTree(experiment)\n",
    "    ET.indent(descriptor)\n",
    "    descriptor.write(os.path.join(graphlabDir,f'currentDescriptor {sampleSpaceName}.xml'), xml_declaration=True, encoding='utf-8', method='xml')\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a3b9483-a847-4a39-9313-14bbb99e32c2",
   "metadata": {},
   "source": [
    "#### Sample application programm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "934a87d0-ca1e-46e5-8daf-2c760afbb281",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Collection creation ---\n",
      "Experiment name: compareHD_YO\n",
      "Collection with 187 recipes in 2 subcollections with 282 distinct ingredients\n",
      "supported by an ingredients catalog with 732 entries in 16 classes\n",
      "\n",
      "---\n",
      "Subcollections:\n",
      "A HD-Gemse Henriette Davidis 95 100\n",
      "B YO-Gemse Yotam Ottolenghi 92 223\n",
      "---\n",
      "Anz. Rezepte in subcoll A:  95\n",
      "Anz. Rezepte in subcoll B:  92\n",
      "Anz. Zutaten in subcoll A:  100\n",
      "Anz. Zutaten in subcoll B:  223\n",
      "---\n",
      "Cosine similarity values:\n",
      "total    0.20360876197458164\n",
      "alc      0.0            \n",
      "carb     0.653549202335885\n",
      "condi    0.021065215180516104\n",
      "egg      1.0            \n",
      "etc      0.8439653844474846\n",
      "fat      0.19734702367335125\n",
      "fish     0.15249857033260467\n",
      "fruit    0.5039677732588825\n",
      "herb     0.5348021880171072\n",
      "milk     0.32543236441717643\n",
      "nuts     0.39056673294247163\n",
      "onion    0.3050368689841128\n",
      "spice    0.05965468271397149\n",
      "sweet    0.7636311479506857\n",
      "veg      0.31529129729590955\n",
      "Entropy A: 5.3317073084685545\n",
      "Entropy B: 6.7191708684278755\n",
      "\n",
      "--- graph creation ---\n",
      "G Graph with 282 nodes and 4747 edges\n",
      "\n",
      "--- graph export ---\n",
      "\n",
      "--- SVG functions ---\n",
      "runtime for generating svg nodes in pandas dataframe:  0.0\n",
      "font size:  96\n",
      "runtime for generating svg edges in pandas dataframe:  6.59375\n",
      "\n",
      "--- scraper functions ---\n"
     ]
    }
   ],
   "source": [
    "#xx = createRefs4Coll  ('c:/Users/nlutt/Documents/Websites/ckCollections/recipes_xml/03 Mangold', \\\n",
    "#                         'C:/Users/nlutt/myPyPro/second/data/igt_cat.json')\n",
    "#for x in xx:\n",
    "#    print (str(x.get('total')).rjust(5), str(x.get('success')).rjust(5), str(x.get('fail')).rjust(100), x.get('recipe name'))\n",
    "#makeSampleSpace('C:/Users/nlutt/Documents/Websites/ckCollections/recipes_xml/03 Mangold', 'C:/Users/nlutt/Documents/Websites/graphLab', 'Mangold', 'C:/Users/nlutt/Documents/Websites/ckCollections/recipes_xml', 'any')\n",
    "print ('--- Collection creation ---')\n",
    "HD_YO = CulinaryCollection('C:/Users/nlutt/Documents/Websites/graphLab/',\n",
    "                           'currentDescriptor compareHD-YO.xml',\n",
    "                           'C:/Users/nlutt/myPyPro/second/data/igt_cat.json',\n",
    "                           'C:/Users/nlutt/myPyPro/second/data/')\n",
    "print (HD_YO)\n",
    "print ('---')\n",
    "scolls = HD_YO.listSubcolls()\n",
    "print (\"Subcollections:\")\n",
    "for sc in scolls:\n",
    "    print(sc.get('letter'),sc.get('name'),sc.get('author'),sc.get('rcpCount'),sc.get('igtCount'),)\n",
    "#print ('Anz. Rezepte: ', len(HD_YO.listRecipes()))\n",
    "#print (HD_YO.listRecipes())\n",
    "print ('---')\n",
    "print ('Anz. Rezepte in subcoll A: ', len(HD_YO.listRecipes('A')))\n",
    "print ('Anz. Rezepte in subcoll B: ', len(HD_YO.listRecipes('B')))\n",
    "print ('Anz. Zutaten in subcoll A: ', len(HD_YO.listIngredients('A')))\n",
    "print ('Anz. Zutaten in subcoll B: ', len(HD_YO.listIngredients('B')))\n",
    "print ('---')\n",
    "#print ('Anz. Zutaten in class veg: ', len(HD_YO.listIngredientsCatalog('veg')))\n",
    "#print ('ei, brot in ingredients cat: ', HD_YO.listIngredientsCatalog(['ei','brot']))\n",
    "sims = HD_YO.cosine_sim()\n",
    "print (\"Cosine similarity values:\")\n",
    "for k, v in sims.items():\n",
    "    print(\"{:<8} {:<15}\".format(k, v))\n",
    "print (f'Entropy A: {HD_YO.entropy().get(\"entropy_A\")}\\nEntropy B: {HD_YO.entropy().get(\"entropy_B\")}')\n",
    "\n",
    "print ('\\n--- graph creation ---')\n",
    "G = HD_YO.toGraph(['A','B'])\n",
    "print ('G', G)\n",
    "\"\"\"\n",
    "print (f\"Total number of nodes in graph   : {len(HD_YO.nodeSets(G))}\")\n",
    "print (f\"Number of nodes in node set A    : {len(HD_YO.nodeSets(G, 'A'))}\")\n",
    "print (f\"Number of nodes in node set B    : {len(HD_YO.nodeSets(G, 'B'))}\")\n",
    "print (f\"Number of nodes in node set AB   : {len(HD_YO.nodeSets(G, ['A','B']))}\")\n",
    "print (f\"Total number of edges in graph   : {len(HD_YO.edgeSets(G))}\")\n",
    "print (f\"Number of edges in edge set A    : {len(HD_YO.edgeSets(G,'A'))}\")\n",
    "print (f\"Number of edges in edge set B    : {len(HD_YO.edgeSets(G,'B'))}\")\n",
    "print (f\"Number of edges in edge set AB   : {len(HD_YO.edgeSets(G,['A','B']).get('AB_edges'))}\")\n",
    "print (f\"Number of edges in edge set AAB  : {len(HD_YO.edgeSets(G,['A','B']).get('AAB_edges'))}\")\n",
    "print (f\"Number of edges in edge set BAB  : {len(HD_YO.edgeSets(G,['A','B']).get('BAB_edges'))}\")\n",
    "print ('---')\n",
    "print ('Krackhardt indices: ', HD_YO.Krack(G))\n",
    "\"\"\"\n",
    "print ('\\n--- graph export ---')\n",
    "#HD_YO.graphToDot (G)\n",
    "#HD_YO.graphToCSV (G)\n",
    "#HD_YO.graphToGEXF(G)\n",
    "\n",
    "print ('\\n--- SVG functions ---')\n",
    "HD_YO.SVGMakerInit(G)\n",
    "HD_YO.previewHTML(2.0)\n",
    "HD_YO.graphToSVG(1.2)\n",
    "\n",
    "HD_YO.nodesByOcc(1,2,'occ 1_2', 'occ_1', 1.2)\n",
    "HD_YO.nodesByOcc(2,4,'occ 2_4', 'occ_2', 1.2)\n",
    "HD_YO.nodesByOcc(4,17,'occ 4_17', 'occ_3', 1.2)\n",
    "HD_YO.nodesByOcc(17,86,'occ 17_86', 'occ_4', 1.2)\n",
    "\n",
    "#rcp_list = HD_YO.sortByContrib2IG(HD_YO.recipesList())\n",
    "#HD_YO.createSVGSequence(rcp_list,'C:/Users/nlutt/myPyPro/second/data/rcp_seq_HD-Gemse')\n",
    "print ('\\n--- scraper functions ---')\n",
    "#print (createRefs4Recipe ('C:/Users/nlutt/Documents/Websites/kochbuch/recipes_xml/07 Vegetarisch/', \\\n",
    "#                          'Mung Dal mit Spinat.xml','C:/Users/nlutt/myPyPro/second/data/igt_cat.json'))\n",
    "#xx = createRefs4Coll  ('c:/Users/nlutt/Documents/Websites/ckCollections/recipes_xml/03 Mangold', \\\n",
    "#                         'C:/Users/nlutt/myPyPro/second/data/igt_cat.json')\n",
    "#for x in xx:\n",
    "#    print (str(x.get('total')).rjust(5), str(x.get('success')).rjust(5), str(x.get('fail')).rjust(100), x.get('recipe name'))\n",
    "\n",
    "#scrapeCKbyKey ('c:/Users/nlutt/Documents/Websites/ckCollections/recipes_xml/03 Mangold', 'Mangold', 'C:/Users/nlutt/myPyPro/second/data/igt_cat.json')\n",
    "#scrapeCK ('C:/Users/nlutt/myPyPro/second/data/Grnkohl', \"https://www.chefkoch.de/rezepte/4201661676632120/Wan-Tan-mit-Gruenkohl-und-Kochwurst.html?ck_source=search-recipe&ck_element=recipe_search_list\", \"Wan-Tan-mit-Grnkohl-und-Kochwurst\", 'Grhnkohl')\n",
    "#synList = ['grnkohl']\n",
    "#scrapeCK ('C:/Users/nlutt/myPyPro/second/data/Grnkohl', \"https://www.chefkoch.de/rezepte/4201661676632120/Wan-Tan-mit-Gruenkohl-und-Kochwurst.html\", \"Wan-Tan-mit-Grnkohl-und-Kochwurst\", synList)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f6995a4",
   "metadata": {},
   "source": [
    "#### Playground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e63ca9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "        # recipe graph edges\n",
    "        for u,v,att in G.edges(data=True):\n",
    "            ed_id       = att.get('id')\n",
    "            #print (ed_id)\n",
    "            edge_attr   = {'class':'edge', 'id':ed_id, 'style':'cursor: pointer;'}\n",
    "            edge        = ET.SubElement(rcp_g, 'g', attrib=edge_attr)\n",
    "            title       = ET.SubElement(edge,'title')\n",
    "            title.text  = ed_id\n",
    "            #pt          = svg_in.find (f\".//svg:title[.='{ed_id}']/../svg:path\", ns)\n",
    "            #pt_coor     = pt.get('d')\n",
    "            start_x      = eds.at[ed_id,'start_x_node']\n",
    "            start_y      = eds.at[ed_id,'start_y_node']\n",
    "            end_x        = eds.at[ed_id,'end_x_node']\n",
    "            end_y        = eds.at[ed_id,'end_y_node']\n",
    "            pt_coor      = f\"M{start_x},{start_y}L{end_x},{end_y}\"\n",
    "            xx = wgt_growing.get(ed_id)\n",
    "            if xx == 1:\n",
    "                path_attr   = {'fill':'none', 'stroke': 'black', 'd':pt_coor}\n",
    "            elif xx == 2: \n",
    "                path_attr   = {'fill':'none', 'stroke': 'black', 'stroke-width':'2', 'd':pt_coor}\n",
    "            elif xx > 2: \n",
    "                path_attr   = {'fill':'none', 'stroke': 'red', 'stroke-width':'2', 'd':pt_coor}\n",
    "            else: \n",
    "                path_attr   = {'fill':'none', 'stroke': 'black', 'd':pt_coor}\n",
    "            path        = ET.SubElement(edge,'path',path_attr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "087eca2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for swapping rows in Pandas dataframe\n",
    "        def swap_rows(df, i1, i2):\n",
    "            a, b = df.iloc[i1, :].copy(), df.iloc[i2, :].copy()\n",
    "            df.iloc[i1, :], df.iloc[i2, :] = b, a\n",
    "            return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8566666",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first: recipe with max number of ingredients\n",
    "        collection_df.sort_values(by='count_igt', inplace=True, ascending=False, ignore_index=True)\n",
    "\n",
    "        # init dataframe before sorting\n",
    "        collection_df['union'] = [set() for i in range(len(recipes))]\n",
    "        collection_df['union_len'] = 0\n",
    "        collection_df.at[0,'union'] = collection_df.at[0,'rcp_ingredients']\n",
    "        collection_df.at[0,'union_len'] = len(collection_df.at[0,'union'])\n",
    "\n",
    "        # sort dataframe by union length\n",
    "        for ix in range(1,len(recipes)):   \n",
    "            for ix2 in range (ix,len(recipes)):\n",
    "                coll = collection_df.at[ix2,'rcp_ingredients'].union(collection_df.at[ix-1,'union'])\n",
    "                collection_df.at[ix2,'union']     = coll\n",
    "                collection_df.at[ix2,'union_len'] = len(coll)\n",
    "            sort_sub(collection_df,ix,len(recipes),'union_len')\n",
    "        #print (collection_df)\n",
    "\n",
    "        # sort recipes\n",
    "        rcp_order      = list(collection_df['rcp_names'])\n",
    "        ixx            = list(range(0, len(recipes)))\n",
    "        ixx_dict       = dict(zip(rcp_order, ixx))\n",
    "        def rcp_sort (e):\n",
    "            return ixx_dict.get(e.get('recipeName'))\n",
    "        recipes_sorted = sorted(recipes, key=rcp_sort)\n",
    "        return recipes_sorted"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
